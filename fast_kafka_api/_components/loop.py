# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/999_ProcessingLoop_old.ipynb.

# %% auto 0
__all__ = ['logger', 'KafkaErrorMsg', 'consumers_async_loop']

# %% ../../nbs/999_ProcessingLoop_old.ipynb 1
from typing import Optional, List, Dict, Callable, Type, Any
from typing import get_type_hints

from os import environ
from datetime import datetime, timedelta
import logging

import asyncio
from asyncio import iscoroutinefunction  # do not use the version from inspect

import anyio
from pydantic import BaseModel
from pydantic import Field, HttpUrl, EmailStr, PositiveInt

# from confluent_kafka import Consumer
from aiokafka import AIOKafkaConsumer
from aiokafka.structs import ConsumerRecord
from confluent_kafka import KafkaError

import asyncer

import fast_kafka_api.logger

fast_kafka_api.logger.should_supress_timestamps = True

# import fast_kafka_api
from ..confluent_kafka import AIOProducer
from ..asyncapi import KafkaMessage
from ..logger import get_logger
from ..testing import true_after

# %% ../../nbs/999_ProcessingLoop_old.ipynb 2
logger = get_logger(__name__)

# %% ../../nbs/999_ProcessingLoop_old.ipynb 7
class KafkaErrorMsg(KafkaMessage):
    topic: str = Field(..., description="topic where exception occurred")
    raw_msg: Optional[bytes] = Field(None, description="raw message string")
    error: str = Field(..., description="exception triggered by the message")

# %% ../../nbs/999_ProcessingLoop_old.ipynb 11
async def _consumer_pooling_step_confluent(
    *,
    async_poll_f: Callable[None, Optional[ConsumerRecord]],
    on_event_callback: Callable[
        [KafkaMessage, Callable[[str, KafkaMessage], None]], None
    ],
    on_error_callback: Optional[Callable[[KafkaErrorMsg], None]] = None,
    produce: Callable[[KafkaMessage], None],
    msg_type: Type[KafkaMessage],
    timeout: float,
    topic: str,
) -> None:
    """Consumer pooling step

    Polls async polling function `async_poll_f` and then process it by calling `on_event_callback` or
    `on_error_callback`, depending on whether the message was successfully parsed.

    Params:
        async_poll_f: async polling function
        on_event_callback: async calling function to be called on JSON parsed message using `msg_type.parse_raw` function.
            The second parameter to the function is a produce function.
        on_error_callback: async calling function to be called in case of any kind of error.
        produce: produce function to be passed to on_event_callback
        msg_type: pydantic class used for parsing message JSON
        timeout: timeout parameter passed to polling functions
        topic: name of topic used for logging and calling `on_error_callback`
    """
    logger.debug("_consumer_pooling_step_confluent()")
    try:
        msg = await async_poll_f()  # type: ignore
        if msg is None:
            logger.debug(
                f"consumers_async_loop(topic={topic}): no messages for the topic {topic} due to no message available."
            )
        elif msg.error() is not None:
            logger.warning(
                f"consumers_async_loop(topic={topic}): no messages for the topic {topic} due to error: {msg.error()}"
            )
            if on_error_callback is not None:
                kafka_err_msg = KafkaErrorMsg(
                    topic=topic,
                    raw_msg=msg.value(),
                    error=msg.error(),
                )
                await on_error_callback(kafka_err_msg)

        else:
            logger.debug(
                f"consumers_async_loop(topic={topic}): message received for the topic {topic}: {msg.value()}, {on_event_callback}, msg_type={msg_type},"
            )
            msg_object = msg_type.parse_raw(msg.value().decode("utf-8"))
            logger.debug(
                f"consumers_async_loop(topic={topic}): calling {on_event_callback}({msg_object})"
            )
            await on_event_callback(msg_object, produce)

    except Exception as e:
        import traceback

        logger.warning(
            f"consumers_async_loop(topic={topic}): Exception in inner try raised: {e}"
            + "\n"
            + traceback.format_exc()
        )

        if on_error_callback is not None:
            kafka_err_msg = KafkaErrorMsg(
                topic=topic,
                raw_msg=msg.value() if msg is not None else None,
                error=str(e),
            )
            await on_error_callback(kafka_err_msg)

# %% ../../nbs/999_ProcessingLoop_old.ipynb 19
async def _consumers_async_loop(
    *,
    async_poll_f: Callable[None, Optional[ConsumerRecord]],
    on_event_callback: Callable[
        [KafkaMessage, Callable[[str, KafkaMessage], None]], None
    ],
    on_error_callback: Optional[Callable[[KafkaErrorMsg], None]] = None,
    is_shutting_down_f: Callable[[], bool],
    produce: Callable[[KafkaMessage], None],
    msg_type: Type[KafkaMessage],
    timeout: float,
    topic: str,
):
    logger.info(f"_consumers_async_loop(topic={topic}, timeout={timeout}) starting.")
    if not iscoroutinefunction(async_poll_f):
        raise ValueError(
            f"async_poll_f ({async_poll_f}) must be coroutine, but it isn't."
        )
    if not iscoroutinefunction(on_event_callback):
        raise ValueError(
            f"on_event_callback ({on_event_callback}) must be coroutine, but it isn't."
        )
    if on_error_callback and not iscoroutinefunction(on_error_callback):
        raise ValueError(
            f"on_event_callback ({on_error_callback}) must be coroutine, but it isn't."
        )

    try:
        while True:
            if is_shutting_down_f():
                logger.info(f"consumers_async_loop(topic={topic}) shutting down...")
                break

            await _consumer_pooling_step_confluent(
                async_poll_f=async_poll_f,
                timeout=timeout,
                topic=topic,
                on_event_callback=on_event_callback,
                on_error_callback=on_error_callback,
                produce=produce,
                msg_type=msg_type,
            )
    except Exception as e:
        logger.error(
            f"consumers_async_loop(topic={topic}): Exception in outer try raised: {e}"
        )
        if on_error_callback is not None:
            kafka_err_msg = KafkaErrorMsg(
                topic=topic,
                raw_msg=None,
                error=str(e),
            )
            await on_error_callback(kafka_err_msg)

    logger.info(f"_consumers_async_loop(topic={topic}) exiting.")

# %% ../../nbs/999_ProcessingLoop_old.ipynb 21
async def consumers_async_loop(
    *,
    consumer: AIOKafkaConsumer,
    ###producer: AIOProducer,
    ###topic: str,  Done when configuring AIOKafkaConsumer
    on_event_callback: List[
        Callable[[KafkaMessage, Callable[[str, KafkaMessage], None]], None]
    ],
    is_shutting_down_f: Callable[[], bool],
    config: Dict[str, str],
    timeout: float = 1.0,
):
    logger.info(
        f"consumers_async_loop(topic={topic}, config={config}, timeout={timeout}) starting."
    )
    await consumer.start()
    try:
        # we convert the blocking poll() function into asynchronous one (it executes poll() in a worker thread) --> consumer.getone

        # convert on_event_callback to coroutine if needed
        async_on_event_callback = on_event_callback
        if not iscoroutinefunction(async_on_event_callback):
            async_on_event_callback = asyncer.asyncify(async_on_event_callback)
        msg_type = _get_first_func_arg_type(on_event_callback)

        async def on_error_callback(error_msg: KafkaErrorMsg, app=app) -> None:
            asyncer.asyncify(app.produce)(topic=app._on_error_topic, msg=error_msg)

        await _consumers_async_loop(
            async_poll_f=consumer.getone,
            timeout=timeout,
            topic=topic,
            on_event_callback=async_on_event_callback,
            on_error_callback=on_error_callback,
            msg_type=msg_type,
        )
    finally:
        logger.info(f"consumers_async_loop(topic={topic}) exiting.")
        await consumer.stop()
