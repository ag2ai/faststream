# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/012_ProducerManager.ipynb.

# %% auto 0
__all__ = ['logger', 'AIOKafkaProducerManager']

# %% ../../nbs/012_ProducerManager.ipynb 1
import asyncio
from contextlib import asynccontextmanager
from typing import *
import time
import logging

import anyio
from aiokafka import AIOKafkaProducer
from anyio.streams.memory import MemoryObjectReceiveStream, MemoryObjectSendStream

from .logger import get_logger, cached_log

# %% ../../nbs/012_ProducerManager.ipynb 4
logger = get_logger(__name__)

# %% ../../nbs/012_ProducerManager.ipynb 6
@asynccontextmanager
async def _aiokafka_producer_manager(  # type: ignore # Argument 1 to "_aiokafka_producer_manager" becomes "Any" due to an unfollowed import  [no-any-unimported]
    producer: AIOKafkaProducer,
    *,
    max_buffer_size: int = 1_000_000,
) -> AsyncGenerator[MemoryObjectSendStream[Any], None]:
    """Write docs

    Todo: add batch size if needed

    """

    logger.info("_aiokafka_producer_manager(): Starting...")

    async def send_message(receive_stream: MemoryObjectReceiveStream) -> Any:
        async with receive_stream:
            async for topic, msg, key in receive_stream:
                fut = await producer.send(topic, msg, key=key)

                def release_callbalck(fut):
                    pass

                fut.add_done_callback(release_callbalck)

    send_stream, receive_stream = anyio.create_memory_object_stream(
        max_buffer_size=max_buffer_size
    )

    logger.info("_aiokafka_producer_manager(): Starting send_stream")
    asyncio.create_task(send_message(receive_stream))
    async with send_stream:
        yield send_stream
        logger.info("_aiokafka_producer_manager(): Exiting send_stream")

    logger.info("_aiokafka_producer_manager(): Finished.")

# %% ../../nbs/012_ProducerManager.ipynb 9
class AIOKafkaProducerManager:
    def __init__(self, producer: AIOKafkaProducer, *, max_buffer_size: int = 1_000):  # type: ignore
        self.producer = producer
        self.max_buffer_size = max_buffer_size
        self.shutting_down = False

    async def start(self) -> None:
        logger.info("AIOKafkaProducerManager.start(): Entering...")
        await self.producer.start()
        self.producer_manager_generator = _aiokafka_producer_manager(
            self.producer, max_buffer_size=self.max_buffer_size
        )
        self.send_stream = await self.producer_manager_generator.__aenter__()
        self.shutting_down = False
        logger.info("AIOKafkaProducerManager.start(): Finished.")

    async def stop(self) -> None:
        # todo: try to flush messages before you exit
        logger.info("AIOKafkaProducerManager.stop(): Entering...")
        self.shutting_down = True
        await self.producer_manager_generator.__aexit__(None, None, None)
        logger.info("AIOKafkaProducerManager.stop(): Stoping producer...")
        await self.producer.flush()
        await self.producer.stop()
        logger.info("AIOKafkaProducerManager.stop(): Finished")

    async def _send_with_throttle(self, *, topic, msg, key, stream):
        while not self.shutting_down:
            try:
                stream.send_nowait(data)
                break
            except anyio.WouldBlock:
                cached_log(
                    logger,
                    f"Send stream full and blocking for {topic=}, throttling...",
                    level=logging.WARNING,
                )
                await asyncio.sleep(0.01)

    def send(self, topic: str, msg: bytes, key: Optional[bytes] = None) -> None:
        if not self.shutting_down:
            asyncio.create_task(
                self._send_with_throttle(
                    topic=topic, msg=msg, key=key, stream=self.send_stream
                )
            )
