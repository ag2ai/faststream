# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/005_FastKafkaServer.ipynb.

# %% auto 0
__all__ = ['logger', 'ServerProcess', 'run_in_process_until_terminate', 'Server']

# %% ../nbs/005_FastKafkaServer.ipynb 1
import importlib
import sys
import asyncio
from typing import *
from contextlib import contextmanager
from pathlib import Path
import threading
import signal
from contextlib import ExitStack

import multiprocessing
from fastcore.meta import delegates
from fastcore.basics import patch

from .application import FastKafka
from .testing import change_dir

from ._components.logger import get_logger

# %% ../nbs/005_FastKafkaServer.ipynb 5
logger = get_logger(__name__)

# %% ../nbs/005_FastKafkaServer.ipynb 9
class ServerProcess:
    def __init__(self, app: FastKafka):
        if app._is_started:
            raise RuntimeError(f"FastKafka app was already started!")

        self.app = app
        self.should_exit = False

    def run(self) -> None:
        return asyncio.run(self._serve())

    async def _serve(self) -> None:
        self._install_signal_handlers()

        async with self.app:
            await self._main_loop()

    def _install_signal_handlers(self) -> None:
        if threading.current_thread() is not threading.main_thread():
            raise RuntimeError()

        loop = asyncio.get_event_loop()

        HANDLED_SIGNALS = (
            signal.SIGINT,  # Unix signal 2. Sent by Ctrl+C.
            signal.SIGTERM,  # Unix signal 15. Sent by `kill <pid>`.
        )

        def handle_exit(sig: int) -> None:
            self.should_exit = True

        for sig in HANDLED_SIGNALS:
            loop.add_signal_handler(sig, handle_exit, sig)

    async def _main_loop(self) -> None:
        while not self.should_exit:
            await asyncio.sleep(0.1)

    @contextmanager
    def run_in_process(self: ServerProcess) -> Generator[None, None, None]:
        def create_and_run(app=self.app):
            server = ServerProcess(app=app)
            server.run()

        with run_in_process_until_terminate(create_and_run):
            yield


@contextmanager
def run_in_process_until_terminate(
    target: Callable[..., Any]
) -> Generator[None, None, None]:
    p = multiprocessing.Process(target=target)
    try:
        p.start()
        yield
    except Exception as e:
        logger.warning(f"Exception raised {e=}")

    finally:
        for i in range(6):
            p.terminate()
            p.join(5)
            if p.exitcode is not None:
                break
            else:
                logger.warning("Process not terminated, retrying...")
        if p.exitcode is None:
            logger.warning("Killing the process...")
            p.kill()
            p.join()
            logger.warning("Process killed!")

        p.close()

# %% ../nbs/005_FastKafkaServer.ipynb 11
class Server(ServerProcess):
    def __init__(self, app: FastKafka, num_workers: Optional[int] = None):
        ServerProcess.__init__(self, app=app)
        self.num_workers: int = (
            num_workers if isinstance(num_workers, int) else multiprocessing.cpu_count()
        )

    async def _serve(self) -> None:
        self._install_signal_handlers()
        with ExitStack() as stack:
            server_processes = [
                ServerProcess(app=self.app) for _ in range(self.num_workers)
            ]
            for server_process in server_processes:
                stack.enter_context(server_process.run_in_process())
            await self._main_loop()

    @contextmanager
    def run_in_process(self) -> Generator[None, None, None]:
        def create_and_run(app=self.app, num_workers=self.num_workers):
            server = Server(app=app, num_workers=num_workers)
            server.run()

        with run_in_process_until_terminate(create_and_run):
            yield
