{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import *\n",
    "\n",
    "from os import environ\n",
    "import asyncio\n",
    "from unittest.mock import MagicMock, Mock, call\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from aiokafka.structs import TopicPartition, ConsumerRecord\n",
    "from pydantic import BaseModel, HttpUrl, NonNegativeInt, Field\n",
    "import asyncer\n",
    "import anyio\n",
    "\n",
    "from fast_kafka_api.logger import get_logger, supress_timestamps\n",
    "from fast_kafka_api.testing import true_after, create_and_fill_testing_topic, nb_safe_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = nb_safe_seed(\"_components.aiokafka_loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.debug(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a41c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "    \"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessage(BaseModel):\n",
    "    url: HttpUrl = Field(..., example=\"http://www.acme.com\", description=\"Url example\")\n",
    "    port: NonNegativeInt = Field(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178af400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_msgs(\n",
    "    *,\n",
    "    msgs: Dict[TopicPartition, List[ConsumerRecord]],\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[BaseModel], None]\n",
    "    ],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    process_f: Callable[[Callable[[BaseModel], None], BaseModel], None]\n",
    "):\n",
    "    for topic_partition, topic_msgs in msgs.items():\n",
    "        topic = topic_partition.topic\n",
    "        msg_type = msg_types[topic]\n",
    "        decoded_msgs = [\n",
    "            msg_type.parse_raw(msg.value.decode(\"utf-8\")) for msg in topic_msgs\n",
    "        ]\n",
    "        for msg in decoded_msgs:\n",
    "            await process_f((callbacks[topic], msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumer_record(topic: str, partition: int, msg: BaseModel):\n",
    "    record = ConsumerRecord(\n",
    "        topic= topic,\n",
    "        partition= partition,\n",
    "        offset= 0,\n",
    "        timestamp= 0,\n",
    "        timestamp_type= 0,\n",
    "        key= None,\n",
    "        value= msg.json().encode(\"utf-8\"),\n",
    "        checksum= 0,\n",
    "        serialized_key_size= 0,\n",
    "        serialized_value_size= 0,\n",
    "        headers= []\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# One msg, one topic, process_f called once with callback and decoded_msg\n",
    "\n",
    "topic=\"topic_0\"\n",
    "partition=0\n",
    "topic_part_0_0 = TopicPartition(topic, partition)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "process_f = Mock()\n",
    "callback_0 = Mock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [record]},\n",
    "    callbacks={topic: callback_0},\n",
    "    msg_types={topic: MyMessage},\n",
    "    process_f=asyncer.asyncify(process_f)\n",
    ")\n",
    "\n",
    "process_f.assert_called_with((callback_0, msg))\n",
    "assert process_f.call_count==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10589655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, process_f called twice with each callback called once\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "topic_part_1_0 = TopicPartition(\"topic_1\", 0)\n",
    "\n",
    "topic=\"topic_0\"\n",
    "partition=0\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "process_f = Mock()\n",
    "callback_0 = Mock()\n",
    "callback_1 = Mock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [record], topic_part_1_0: [record]},\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=asyncer.asyncify(process_f)\n",
    ")\n",
    "\n",
    "process_f.assert_has_calls([call((callback_0, msg)), call((callback_1, msg))], any_order=True)\n",
    "assert process_f.call_count==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple msgs in same topic\n",
    "# Check callback not called if there are no msgs for it in the queue\n",
    "\n",
    "# Two msg, one topic, one callback called twice, other called nonce, produce and process_f called twice\n",
    "\n",
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, process_f called twice with each callback called once and produce twice\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "\n",
    "topic=\"topic_0\"\n",
    "partition=0\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "process_f = Mock()\n",
    "callback_0 = Mock()\n",
    "callback_1 = Mock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [record, record]},\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=asyncer.asyncify(process_f)\n",
    ")\n",
    "\n",
    "process_f.assert_has_calls([call((callback_0, msg)), call((callback_0, msg))], any_order=True)\n",
    "assert process_f.call_count==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple partitions\n",
    "\n",
    "# Two msg, one topic, two partitions, one callback called twice, produce and process_f called twice\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "topic_part_0_1 = TopicPartition(\"topic_0\", 1)\n",
    "\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "process_f = Mock()\n",
    "callback_0 = Mock()\n",
    "callback_1 = Mock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [\n",
    "            create_consumer_record(topic=\"topic_0\", partition=0, msg=msg)],\n",
    "          topic_part_0_1: [\n",
    "            create_consumer_record(topic=\"topic_0\", partition=1, msg=msg)]\n",
    "         },\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=asyncer.asyncify(process_f)\n",
    ")\n",
    "\n",
    "process_f.assert_has_calls([call((callback_0, msg)), call((callback_0, msg))], any_order=True)\n",
    "assert process_f.call_count==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_message_callback(receive_stream):\n",
    "    async with receive_stream:\n",
    "        async for callback, msg in receive_stream:\n",
    "            await callback(msg)\n",
    "            \n",
    "\n",
    "async def _aiokafka_consumer_loop(\n",
    "    *,\n",
    "    consumer: AIOKafkaConsumer,\n",
    "    max_buffer_size: int,\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[BaseModel], None]\n",
    "    ],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "):\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream(max_buffer_size=max_buffer_size)\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(process_message_callback, receive_stream)\n",
    "        async with send_stream:\n",
    "            while True:\n",
    "                msgs = await consumer.getmany(timeout_ms=100)\n",
    "                await process_msgs(\n",
    "                    msgs=msgs,\n",
    "                    callbacks=callbacks,\n",
    "                    msg_types=msg_types,\n",
    "                    process_f=send_stream.send,\n",
    "                )\n",
    "                if is_shutting_down_f():\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77397e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=\"topic_0\"\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {\n",
    "    TopicPartition(topic, 0): [\n",
    "        record\n",
    "    ]\n",
    "}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "mock_consumer.configure_mock(**{'getmany.return_value': f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "def is_shutting_down_f(mock_func):\n",
    "    def _is_shutting_down_f():\n",
    "        return mock_func.called\n",
    "    return _is_shutting_down_f\n",
    "\n",
    "await _aiokafka_consumer_loop(\n",
    "    consumer= mock_consumer,\n",
    "    max_buffer_size= 100,\n",
    "    callbacks= {\n",
    "        topic: asyncer.asyncify(mock_callback)\n",
    "    },\n",
    "    msg_types={\n",
    "        topic: MyMessage\n",
    "    },\n",
    "    is_shutting_down_f = is_shutting_down_f(mock_consumer.getmany)\n",
    ")\n",
    "\n",
    "assert mock_consumer.getmany.call_count == 1\n",
    "mock_callback.assert_called_once_with(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def aiokafka_consumer_loop(\n",
    "    topics: List[str],\n",
    "    *,\n",
    "    bootstrap_servers: str,\n",
    "    auto_offset_reset: str,\n",
    "    max_poll_records: int,\n",
    "    max_buffer_size: int,\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[BaseModel], None]\n",
    "    ],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs,\n",
    "):\n",
    "    consumer = AIOKafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        auto_offset_reset=auto_offset_reset,\n",
    "        max_poll_records=max_poll_records,\n",
    "    )\n",
    "    logger.info(\"Consumer created.\")\n",
    "\n",
    "    await consumer.start()\n",
    "    logger.info(\"Consumer started.\")\n",
    "    consumer.subscribe(topics)\n",
    "    logger.info(\"Consumer subscribed.\")\n",
    "\n",
    "    try:\n",
    "        await _aiokafka_consumer_loop(\n",
    "            consumer=consumer,\n",
    "            max_buffer_size=max_buffer_size,\n",
    "            callbacks=callbacks,\n",
    "            msg_types=msg_types,\n",
    "            is_shutting_down_f=is_shutting_down_f,\n",
    "        )\n",
    "    finally:\n",
    "        await consumer.stop()\n",
    "        logger.info(f\"Consumer stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_928922829']): new_topics = [NewTopic(topic=my_topic_928922829,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=9178\n",
      "[INFO] __main__: Consumer created.\n",
      "[INFO] __main__: Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_928922829'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_928922829'}\n",
      "[INFO] __main__: Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_928922829': 3}. \n",
      "[INFO] __main__: Consumer stopped.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "\n",
    "async with create_and_fill_testing_topic(kafka_config=kafka_config, msgs=msgs, seed=seed(1)) as topic:\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics = [topic],\n",
    "        bootstrap_servers = kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        max_poll_records=100,\n",
    "        max_buffer_size= 100,\n",
    "        callbacks = {topic: count_msg},\n",
    "        msg_types= {topic: MyMessage},\n",
    "        is_shutting_down_f= true_after(5),\n",
    "    )\n",
    "\n",
    "assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_1849625992']): new_topics = [NewTopic(topic=my_topic_1849625992,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=100000\n",
      "[INFO] __main__: Consumer created.\n",
      "[INFO] __main__: Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_1849625992'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_1849625992'}\n",
      "[INFO] __main__: Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_1849625992': 3}. \n",
      "[INFO] __main__: Consumer stopped.\n",
      "Messages processed: 89,800\n",
      "Time              : 5.01 s\n",
      "Throughput.       : 17,937 msg/s\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "msgs_sent = 100000\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "\n",
    "async with create_and_fill_testing_topic(kafka_config=kafka_config, msgs=msgs, seed=seed(3)) as topic:\n",
    "    start = datetime.now()\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics = [topic],\n",
    "        bootstrap_servers = kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        max_poll_records=100,\n",
    "        max_buffer_size=100,\n",
    "        callbacks = {topic: count_msg},\n",
    "        msg_types= {topic: MyMessage},\n",
    "        is_shutting_down_f= true_after(5),\n",
    "    )\n",
    "    t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "    thrp = msgs_received / t\n",
    "    \n",
    "    print(f\"Messages processed: {msgs_received:,d}\")\n",
    "    print(f\"Time              : {t:.2f} s\")\n",
    "    print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d74c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
