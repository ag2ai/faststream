{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b22f68",
   "metadata": {},
   "source": [
    "# Batch consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import asyncio\n",
    "\n",
    "import asyncer\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from fastkafka._components._subprocess import terminate_asyncio_process\n",
    "from fastkafka._testing.apache_kafka_broker import run_and_match\n",
    "from fastkafka.testing import ApacheKafkaBroker, run_script_and_cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c655e4f",
   "metadata": {},
   "source": [
    "If you want to consume data in batches `@consumes` decorator makes that possible for you. By typing a consumed msg object as a `list` of messages the consumer will call your consuming function with a batch of messages consumed from a single partition. Let's demonstrate that now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18535f2f",
   "metadata": {},
   "source": [
    "## Consume function with batching\n",
    "\n",
    "To consume messages in batches, you need to wrap you message type into a list and the `@consumes` decorator will take care of the rest for you. Your consumes function will be called with batches grouped by partition now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09190cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "@app.consumes(auto_offset_reset=\"earliest\")\n",
       "async def on_hello_world(msg: List[HelloWorld]):\n",
       "    logger.info(f\"Got msg batch: {msg}\")\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "consumes_decorator_batch = \"\"\"@app.consumes(auto_offset_reset=\"earliest\")\n",
    "async def on_hello_world(msg: List[HelloWorld]):\n",
    "    logger.info(f\"Got msg batch: {msg}\")\n",
    "\"\"\"\n",
    "md(f\"```python\\n{consumes_decorator_batch}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b68d7",
   "metadata": {},
   "source": [
    "## App example\n",
    "\n",
    "We will modify the app example from [@consumes basics](/docs/guides/Guide_11_Consumes_Basics.md) guide to consume `HelloWorld` messages batch. The final app will look like this (make sure you replace the `<url_of_your_kafka_bootstrap_server>` and `<port_of_your_kafka_bootstrap_server>` with the actual values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "app = \"\"\"\n",
    "import asyncio\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from fastkafka import FastKafka\n",
    "from fastkafka._components.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "class HelloWorld(BaseModel):\n",
    "    msg: str = Field(\n",
    "        ...,\n",
    "        example=\"Hello\",\n",
    "        description=\"Demo hello world message\",\n",
    "    )\n",
    "\n",
    "kafka_brokers = {\n",
    "    \"demo_broker\": {\n",
    "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
    "        \"description\": \"local demo kafka broker\",\n",
    "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
    "    }\n",
    "}\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb4c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "import asyncio\n",
       "from typing import List\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "from fastkafka import FastKafka\n",
       "from fastkafka._components.logger import get_logger\n",
       "\n",
       "logger = get_logger(__name__)\n",
       "\n",
       "class HelloWorld(BaseModel):\n",
       "    msg: str = Field(\n",
       "        ...,\n",
       "        example=\"Hello\",\n",
       "        description=\"Demo hello world message\",\n",
       "    )\n",
       "\n",
       "kafka_brokers = {\n",
       "    \"demo_broker\": {\n",
       "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
       "        \"description\": \"local demo kafka broker\",\n",
       "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
       "    }\n",
       "}\n",
       "\n",
       "app = FastKafka(kafka_brokers=kafka_brokers)\n",
       "\n",
       "@app.consumes(auto_offset_reset=\"earliest\")\n",
       "async def on_hello_world(msg: List[HelloWorld]):\n",
       "    logger.info(f\"Got msg batch: {msg}\")\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "batch_example = app + consumes_decorator_batch\n",
    "\n",
    "md(f\"```python\\n{batch_example}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ec6dab",
   "metadata": {},
   "source": [
    "## Send the messages to kafka topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e65bc",
   "metadata": {},
   "source": [
    "Lets send a couple of `HelloWorld` messages to the *hello_world* topic and check if our consumer kafka application has logged the received messages batch. In your terminal, run the following command at least two times to create multiple messages in your kafka queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef181f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```shell\n",
       "echo {\\\"msg\\\": \\\"Hello world\\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producer_cmd = 'echo {\\\\\"msg\\\\\": \\\\\"Hello world\\\\\"} | kafka-console-producer.sh --topic=hello_world --bootstrap-server=<addr_of_your_kafka_bootstrap_server>'\n",
    "md(f\"```shell\\n{producer_cmd}\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01604778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Now we can run the app. Copy the code of the example app in consumer_example.py and run it by running\n",
       "```shell\n",
       "fastkafka run --num-workers=1 --kafka-broker=demo_broker consumer_example:app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "script_file = \"consumer_example.py\"\n",
    "filename = script_file.split(\".py\")[0]\n",
    "cmd = f\"fastkafka run --num-workers=1 --kafka-broker=demo_broker {filename}:app\"\n",
    "md(\n",
    "    f\"Now we can run the app. Copy the code of the example app in {script_file} and run it by running\\n```shell\\n{cmd}\\n```\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66904c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 60656...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 60656 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 60277...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 60277 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "with ApacheKafkaBroker(\n",
    "    topics=[\"hello_world\"], apply_nest_asyncio=True\n",
    ") as bootstrap_server:\n",
    "    async with asyncer.create_task_group() as task_group:\n",
    "        server_url = bootstrap_server.split(\":\")[0]\n",
    "        server_port = bootstrap_server.split(\":\")[1]\n",
    "\n",
    "        producer_tasks = [task_group.soonify(asyncio.create_subprocess_shell)(\n",
    "            cmd=producer_cmd.replace(\n",
    "                \"<addr_of_your_kafka_bootstrap_server>\", bootstrap_server\n",
    "            ),\n",
    "            stdout=asyncio.subprocess.PIPE,\n",
    "            stderr=asyncio.subprocess.PIPE,\n",
    "        ) for _ in range(2)]\n",
    "        \n",
    "        await asyncio.sleep(5)\n",
    "        \n",
    "        consumer_task = task_group.soonify(run_script_and_cancel)(\n",
    "            script=batch_example.replace(\n",
    "                \"<url_of_your_kafka_bootstrap_server>\", server_url\n",
    "            ).replace(\"<port_of_your_kafka_bootstrap_server>\", server_port),\n",
    "            script_file=script_file,\n",
    "            cmd=cmd,\n",
    "            cancel_after=20,\n",
    "        )\n",
    "\n",
    "assert \"Got msg batch: [HelloWorld(msg='Hello world'), HelloWorld(msg='Hello world')]\" in consumer_task.value[1].decode(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: False\n",
    "\n",
    "print(consumer_task.value[1].decode(\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292901c",
   "metadata": {},
   "source": [
    "You should see the your Kafka messages being logged in batches by your consumer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
