{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1ec46b",
   "metadata": {},
   "source": [
    "# Using multiple kafka clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfccd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import pytest\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from fastkafka import FastKafka\n",
    "from fastkafka.testing import Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61526c5c",
   "metadata": {},
   "source": [
    "Hey there! Are you ready to take your FastKafka application to the next level? In this guide, we'll show you how to connect your application to multiple Kafka clusters like a pro! :rocket:\n",
    "\n",
    "Imagine this: you have different Kafka clusters running, each with its own set of topics and messages. But what if you want to bring all those topics together into one, or mirror them across clusters? Or perhaps you want to produce messages to multiple clusters simultaneously? That's where this guide comes in handy!\n",
    "\n",
    "We'll walk you through the process of seamlessly integrating your FastKafka application with multiple Kafka clusters. You'll learn how to aggregate topics from different clusters into a single one, mirror topics across clusters, and even produce messages to multiple clusters all at once!\n",
    "\n",
    "So buckle up and get ready for an exciting journey into the world of multi-cluster connectivity with FastKafka. Let's dive right in and unlock the full potential of your Kafka-powered application! :muscle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c41ef",
   "metadata": {},
   "source": [
    "### Test message\n",
    "\n",
    "To showcase the functionalities of FastKafka and illustrate the concepts discussed, we can use a simple test message called `TestMsg`. This message serves as a basic representation of the data that can be processed and exchanged within your FastKafka application. Here's the definition of the `TestMsg` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4828bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d89a52",
   "metadata": {},
   "source": [
    "## Defining multiple broker configurations\n",
    "\n",
    "When building a FastKafka application, you may need to consume messages from multiple Kafka clusters, each with its own set of broker configurations. FastKafka provides the flexibility to define different broker clusters using the brokers argument in the consumes decorator. Let's explore an example code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers_1 = dict(localhost=dict(url=\"server_1\", port=9092))\n",
    "kafka_brokers_2 = dict(localhost=dict(url=\"server_2\", port=9092))\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers_1)\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\")\n",
    "async def on_preprocessed_signals_1(msg: TestMsg):\n",
    "    print(f\"Default: {msg=}\")\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers_2)\n",
    "async def on_preprocessed_signals_2(msg: TestMsg):\n",
    "    print(f\"Specified: {msg=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fed8cc",
   "metadata": {},
   "source": [
    "In this example, we have two broker configurations: **kafka_brokers_1** and **kafka_brokers_2**. The **kafka_brokers_1** configuration represents the default or primary cluster, while **kafka_brokers_2** is an alternative cluster that can be specified in the decorator.\n",
    "\n",
    "The app object is initialized with the primary broker configuration (kafka_brokers_1) using the FastKafka class.\n",
    "\n",
    "The first `@app.consumes` decorator without the brokers argument represents the default behavior. The `on_preprocessed_signals_1` function consumes messages from the \"preprocessed_signals\" topic using the primary broker configuration. Any messages received will be processed accordingly.\n",
    "\n",
    "The second `@app.consumes` decorator includes the `brokers=kafka_brokers_2` argument, allowing you to explicitly specify the broker cluster to consume messages from. The `on_preprocessed_signals_2` function consumes messages from the same \"preprocessed_signals\" topic but using the **kafka_brokers_2** configuration. This provides the flexibility to consume from different clusters based on your requirements.\n",
    "\n",
    "Similarly, you can use the brokers argument in the `@app.produces` decorator to define multiple broker clusters for producing messages.\n",
    "\n",
    "It's important to note that when defining multiple broker configurations, all configurations must have the same set of required configurations as the primary cluster. This ensures consistent behavior across clusters.\n",
    "\n",
    "\n",
    "Now let's go through some use cases on how to use the `brokers` decorator argument to enable your FastKafka app to work with multiple Kafka broker clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825a024",
   "metadata": {},
   "source": [
    "## Mirroring topics\n",
    "\n",
    "In this section, we'll explore how you can effectively mirror topics between different Kafka clusters, enabling seamless data synchronization for your applications.\n",
    "\n",
    "Imagine having two Kafka clusters, namely **kafka_brokers_1** and **kafka_brokers_2**, each hosting its own set of topics and messages. Now, if you want to mirror a specific topic (in this case: *preprocessed_signals*) from kafka_brokers_1 to kafka_brokers_2, ensuring data consistency across clusters, FastKafka provides a powerful solution.\n",
    "\n",
    "Let's examine the code snippet that configures our application for topic mirroring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b84d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers_1 = dict(localhost=dict(url=\"server_1\", port=9092))\n",
    "kafka_brokers_2 = dict(localhost=dict(url=\"server_2\", port=9092))\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers_1)\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\")\n",
    "async def on_preprocessed_signals_original(msg: TestMsg):\n",
    "    await to_preprocessed_signals_mirror(msg)\n",
    "\n",
    "\n",
    "@app.produces(topic=\"preprocessed_signals\", brokers=kafka_brokers_2)\n",
    "async def to_preprocessed_signals_mirror(data: TestMsg) -> TestMsg:\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ceaf23",
   "metadata": {},
   "source": [
    "Here's how it works: our FastKafka application is configured to consume messages from **kafka_brokers_1** and process them in the **on_preprocessed_signals_original** function. We want to mirror these messages to **kafka_brokers_2**. To achieve this, we define the **to_preprocessed_signals_mirror** function as a producer, seamlessly producing the processed messages to the preprocessed_signals topic within the kafka_brokers_2 cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71340e",
   "metadata": {},
   "source": [
    "### Testing the app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc619a",
   "metadata": {},
   "source": [
    "To test our FastKafka 'mirroring' application, we can use our testing framework. Let's take a look at the testing code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6868e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-05-29 11:12:20.203 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "23-05-29 11:12:20.204 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "23-05-29 11:12:20.205 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "23-05-29 11:12:20.206 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_2:9092'}'\n",
      "23-05-29 11:12:20.206 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:20.217 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_1:9092'}'\n",
      "23-05-29 11:12:20.217 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:20.218 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:20.219 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_1:9092'}\n",
      "23-05-29 11:12:20.219 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:20.220 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:20.220 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:20.220 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['preprocessed_signals']\n",
      "23-05-29 11:12:20.221 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:20.226 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:20.226 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_2:9092'}\n",
      "23-05-29 11:12:20.227 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:20.228 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:20.230 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:20.230 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['preprocessed_signals']\n",
      "23-05-29 11:12:20.231 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:24.218 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:24.219 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:24.219 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:24.220 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:24.221 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:24.222 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:24.222 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:24.223 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:24.223 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "23-05-29 11:12:24.224 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "async with Tester(app) as tester:\n",
    "    await tester.mirrors[app.on_preprocessed_signals_original](TestMsg(msg=\"signal\"))\n",
    "    await tester.mirrors[app.to_preprocessed_signals_mirror].assert_called(timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d38c7",
   "metadata": {},
   "source": [
    "With the help of the **Tester** object, we can simulate and verify the behavior of our FastKafka application. Here's how it works:\n",
    "\n",
    "1. We create an instance of the **Tester** by passing in our *app* object, which represents our FastKafka application.\n",
    "\n",
    "2. Using the **tester.mirrors** dictionary, we can send a message to a specific Kafka broker and topic combination. In this case, we use `tester.mirrors[app.on_preprocessed_signals_original]` to send a TestMsg message with the content \"signal\" to the appropriate Kafka broker and topic.\n",
    "\n",
    "3. After sending the message, we can perform assertions on the mirrored function using `tester.mirrors[app.to_preprocessed_signals_mirror].assert_called(timeout=5)`. This assertion ensures that the mirrored function has been called within a specified timeout period (in this case, 5 seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237efbe",
   "metadata": {},
   "source": [
    "## Agregate multiple clusters\n",
    "\n",
    "In this section, we'll explore how you can effortlessly consume data from multiple sources, process it, and aggregate the results into a single topic on a specific cluster.\n",
    "\n",
    "Imagine you have two Kafka clusters: **kafka_brokers_1** and **kafka_brokers_2**, each hosting its own set of topics and messages. Now, what if you want to consume data from both clusters, perform some processing, and produce the results to a single topic on **kafka_brokers_1**? FastKafka has got you covered!\n",
    "\n",
    "Let's take a look at the code snippet that configures our application for aggregating multiple clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers_1 = dict(localhost=dict(url=\"server_1\", port=9092))\n",
    "kafka_brokers_2 = dict(localhost=dict(url=\"server_2\", port=9092))\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers_1)\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\")\n",
    "async def on_preprocessed_signals_1(msg: TestMsg):\n",
    "    print(f\"Default: {msg=}\")\n",
    "    await to_predictions(msg)\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers_2)\n",
    "async def on_preprocessed_signals_2(msg: TestMsg):\n",
    "    print(f\"Specified: {msg=}\")\n",
    "    await to_predictions(msg)\n",
    "\n",
    "\n",
    "@app.produces(topic=\"predictions\")\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return [prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1642f",
   "metadata": {},
   "source": [
    "Here's the idea: our FastKafka application is set to consume messages from the topic \"preprocessed_signals\" on **kafka_brokers_1** cluster, as well as from the same topic on **kafka_brokers_2** cluster. We have two consuming functions, `on_preprocessed_signals_1` and `on_preprocessed_signals_2`, that handle the messages from their respective clusters. These functions perform any required processing, in this case, just calling the to_predictions function.\n",
    "\n",
    "The exciting part is that the to_predictions function acts as a producer, sending the processed results to the \"predictions\" topic on **kafka_brokers_1 cluster**. By doing so, we effectively aggregate the data from multiple sources into a single topic on a specific cluster.\n",
    "\n",
    "This approach enables you to consume data from multiple Kafka clusters, process it, and produce the aggregated results to a designated topic. Whether you're generating predictions, performing aggregations, or any other form of data processing, FastKafka empowers you to harness the full potential of multiple clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80755a2",
   "metadata": {},
   "source": [
    "### Testing the app\n",
    "\n",
    "Let's take a look at the testing code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbdd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-05-29 11:12:24.257 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "23-05-29 11:12:24.257 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "23-05-29 11:12:24.258 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "23-05-29 11:12:24.259 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_1:9092'}'\n",
      "23-05-29 11:12:24.260 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:24.273 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_1:9092'}'\n",
      "23-05-29 11:12:24.274 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:24.274 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_2:9092'}'\n",
      "23-05-29 11:12:24.275 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:24.276 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:24.277 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_1:9092'}\n",
      "23-05-29 11:12:24.278 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:24.279 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:24.279 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:24.280 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['preprocessed_signals']\n",
      "23-05-29 11:12:24.280 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:24.281 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:24.281 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_2:9092'}\n",
      "23-05-29 11:12:24.282 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:24.283 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:24.283 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:24.284 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['preprocessed_signals']\n",
      "23-05-29 11:12:24.285 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:24.285 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:24.286 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_1:9092'}\n",
      "23-05-29 11:12:24.287 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:24.288 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:24.288 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:24.289 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['predictions']\n",
      "23-05-29 11:12:24.289 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "Default: msg=TestMsg(msg='signal')\n",
      "Sending prediction: msg='signal'\n",
      "Specified: msg=TestMsg(msg='signal')\n",
      "Sending prediction: msg='signal'\n",
      "23-05-29 11:12:28.277 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:28.277 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:28.278 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:28.278 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:28.279 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:28.279 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:28.280 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:28.280 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:28.281 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:28.281 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:28.281 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:28.282 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:28.282 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "23-05-29 11:12:28.283 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "async with Tester(app) as tester:\n",
    "    await tester.mirrors[app.on_preprocessed_signals_1](TestMsg(msg=\"signal\"))\n",
    "    await tester.mirrors[app.on_preprocessed_signals_2](TestMsg(msg=\"signal\"))\n",
    "    await tester.on_predictions.assert_called(timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebba677",
   "metadata": {},
   "source": [
    "Here's how the code above works:\n",
    "\n",
    "1. Within an `async with` block, create an instance of the Tester by passing in your app object, representing your FastKafka application.\n",
    "\n",
    "2. Using the tester.mirrors dictionary, you can send messages to specific Kafka broker and topic combinations. In this case, we use `tester.mirrors[app.on_preprocessed_signals_1]` and `tester.mirrors[app.on_preprocessed_signals_2]` to send TestMsg messages with the content \"signal\" to the corresponding Kafka broker and topic combinations.\n",
    "\n",
    "3. After sending the messages, you can perform assertions on the **on_predictions** function using `tester.on_predictions.assert_called(timeout=5)`. This assertion ensures that the on_predictions function has been called within a specified timeout period (in this case, 5 seconds). \n",
    "\n",
    "\n",
    "!!! info \\\"Syntax sugar and topic ambiguity\\\"\n",
    "\n",
    "    Since the \"predictions\" topic exists only on kafka_brokers_1, there is no ambiguity to resolve, and you can directly use the tester.on_predictions syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf82425",
   "metadata": {},
   "source": [
    "## Producing to multiple clusters\n",
    "\n",
    "In some scenarios, you may need to produce messages to multiple Kafka clusters simultaneously. FastKafka simplifies this process by allowing you to configure your application to produce messages to multiple clusters effortlessly. Let's explore how you can achieve this:\n",
    "\n",
    "Consider the following code snippet that demonstrates producing messages to multiple clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e48106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers_1 = dict(localhost=dict(url=\"server_1\", port=9092))\n",
    "kafka_brokers_2 = dict(localhost=dict(url=\"server_2\", port=9092))\n",
    "\n",
    "app = FastKafka(kafka_brokers=kafka_brokers_1)\n",
    "\n",
    "\n",
    "@app.consumes(topic=\"preprocessed_signals\")\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions_1(TestMsg(msg=\"prediction\"))\n",
    "    await to_predictions_2(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@app.produces(topic=\"predictions\")\n",
    "async def to_predictions_1(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return [prediction]\n",
    "\n",
    "\n",
    "@app.produces(topic=\"predictions\", brokers=kafka_brokers_2)\n",
    "async def to_predictions_2(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return [prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc670be1",
   "metadata": {},
   "source": [
    "Here's what you need to know about producing to multiple clusters:\n",
    "\n",
    "1. We define two Kafka broker configurations: **kafka_brokers_1** and **kafka_brokers_2**, representing different clusters with their respective connection details.\n",
    "\n",
    "2. We create an instance of the FastKafka application, specifying **kafka_brokers_1** as the primary cluster for producing messages.\n",
    "\n",
    "3. The `on_preprocessed_signals` function serves as a consumer, handling incoming messages from the \"preprocessed_signals\" topic. Within this function, we invoke two producer functions: `to_predictions_1` and `to_predictions_2`.\n",
    "\n",
    "4. The `to_predictions_1` function sends predictions to the \"predictions\" topic on *kafka_brokers_1* cluster.\n",
    "\n",
    "5. Additionally, the `to_predictions_2` function sends the same predictions to the \"predictions\" topic on *kafka_brokers_2* cluster. This allows for producing the same data to multiple clusters simultaneously.\n",
    "\n",
    "By utilizing this approach, you can seamlessly produce messages to multiple Kafka clusters, enabling you to distribute data across different environments or leverage the strengths of various clusters.\n",
    "\n",
    "Feel free to customize the producer functions as per your requirements, performing any necessary data transformations or enrichment before sending the predictions.\n",
    "\n",
    "With FastKafka, producing to multiple clusters becomes a breeze, empowering you to harness the capabilities of multiple environments effortlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1caf66",
   "metadata": {},
   "source": [
    "### Testing the app\n",
    "\n",
    "Let's take a look at the testing code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fdc528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-05-29 11:12:28.309 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._start() called\n",
      "23-05-29 11:12:28.309 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "23-05-29 11:12:28.310 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker starting\n",
      "23-05-29 11:12:28.310 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_1:9092'}'\n",
      "23-05-29 11:12:28.311 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:28.311 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_2:9092'}'\n",
      "23-05-29 11:12:28.312 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:28.326 [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': 'server_1:9092'}'\n",
      "23-05-29 11:12:28.327 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched start() called()\n",
      "23-05-29 11:12:28.329 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:28.330 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_1:9092'}\n",
      "23-05-29 11:12:28.332 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:28.333 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:28.333 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:28.334 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['preprocessed_signals']\n",
      "23-05-29 11:12:28.334 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:28.335 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:28.335 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_1:9092'}\n",
      "23-05-29 11:12:28.336 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:28.336 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:28.337 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:28.337 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['predictions']\n",
      "23-05-29 11:12:28.338 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "23-05-29 11:12:28.338 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "23-05-29 11:12:28.339 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'max_poll_records': 100, 'bootstrap_servers': 'server_2:9092'}\n",
      "23-05-29 11:12:28.339 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched start() called()\n",
      "23-05-29 11:12:28.339 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "23-05-29 11:12:28.340 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched subscribe() called\n",
      "23-05-29 11:12:28.340 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer.subscribe(), subscribing to: ['predictions']\n",
      "23-05-29 11:12:28.341 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "msg=TestMsg(msg='signal')\n",
      "Sending prediction: msg='prediction'\n",
      "Sending prediction: msg='prediction'\n",
      "23-05-29 11:12:32.329 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:32.330 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:32.330 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:32.330 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:32.331 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:32.331 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:32.332 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:32.332 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaConsumer patched stop() called\n",
      "23-05-29 11:12:32.333 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "23-05-29 11:12:32.333 [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "23-05-29 11:12:32.335 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:32.335 [INFO] fastkafka._testing.in_memory_broker: AIOKafkaProducer patched stop() called\n",
      "23-05-29 11:12:32.336 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker._stop() called\n",
      "23-05-29 11:12:32.337 [INFO] fastkafka._testing.in_memory_broker: InMemoryBroker stopping\n"
     ]
    }
   ],
   "source": [
    "async with Tester(app) as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await tester.mirrors[to_predictions_1].assert_called(timeout=5)\n",
    "    await tester.mirrors[to_predictions_2].assert_called(timeout=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99617426",
   "metadata": {},
   "source": [
    "Here's how you can perform the necessary tests:\n",
    "\n",
    "1. Within an async with block, create an instance of the **Tester** by passing in your app object, representing your FastKafka application.\n",
    "\n",
    "2. Using the `tester.to_preprocessed_signals` method, you can send a TestMsg message with the content \"signal\".\n",
    "\n",
    "3. After sending the message, you can perform assertions on the to_predictions_1 and to_predictions_2 functions using `tester.mirrors[to_predictions_1].assert_called(timeout=5)` and `tester.mirrors[to_predictions_2].assert_called(timeout=5)`. These assertions ensure that the respective producer functions have produced data to their respective topic/broker combinations.\n",
    "\n",
    "By employing this testing approach, you can verify that the producing functions correctly send messages to their respective clusters. The testing framework provided by FastKafka enables you to ensure the accuracy and reliability of your application's producing logic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
