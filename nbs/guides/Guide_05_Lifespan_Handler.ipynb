{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b490915d",
   "metadata": {},
   "source": [
    "# Lifespan Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305342b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from fastkafka._components.helpers import _import_from_string, change_dir\n",
    "from fastkafka.testing import ApacheKafkaBroker, Tester, run_script_and_cancel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85b1d1",
   "metadata": {},
   "source": [
    "Did you know that you can define some special code that runs before and after your Kafka application? This code will be executed just once, but it covers the whole lifespan of your app! :rocket:\n",
    "\n",
    "Lets break it down:\n",
    "\n",
    "You can define logic (code) that should be executed before the application starts up. This is like a warm-up for your app, getting it ready to consume and produce messages.\n",
    "\n",
    "Similarly, you can define logic (code) that should be executed when the application is shutting down. This is like a cool-down for your app, making sure everything is properly closed and cleaned up.\n",
    "\n",
    "By executing code before consuming and after producing, you cover the entire lifecycle of your application :tada:\n",
    "\n",
    "This is super handy for setting up shared resources that are needed across consumers and producers, like a database connection pool or a machine learning model. And the best part? You can clean up these resources when the app is shutting down!\n",
    "\n",
    "So lets give it a try and see how it can make your Kafka app even more awesome! :muscle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acf3cf",
   "metadata": {},
   "source": [
    "## Lifespan example - Iris prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47606657",
   "metadata": {},
   "source": [
    "Let's dive into an example to see how you can leverage the lifecycle handler to solve a common use case. Imagine that you have some machine learning models that need to consume incoming messages and produce response/prediction messages. These models are shared among consumers and producers, which means you don't want to load them for every message.\n",
    "\n",
    "Here's where the lifecycle handler comes to the rescue! By loading the model before the messages are consumed and produced, but only right before the application starts receiving messages, you can ensure that the model is ready to use without compromising the performance of your tests. In the upcoming sections, we'll walk you through how to initialize an Iris species prediction model and use it in your developed application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7f3b7",
   "metadata": {},
   "source": [
    "### Lifespan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca909ff",
   "metadata": {},
   "source": [
    "You can define this startup and shutdown logic using the lifespan parameter of the FastKafka app, and an async context manager.\n",
    "\n",
    "Let's start with an example and then see it in detail.\n",
    "\n",
    "We create an async function lifespan() with yield like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from sklearn.datasets import load_iris\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from contextlib import asynccontextmanager\n",
       "\n",
       "from fastkafka import FastKafka\n",
       "\n",
       "ml_models = {}\n",
       "\n",
       "@asynccontextmanager\n",
       "async def lifespan(app: FastKafka):\n",
       "    # Load the ML model\n",
       "    print(\"Loading the model!\")\n",
       "    X, y = load_iris(return_X_y=True)\n",
       "    ml_models[\"iris_predictor\"] = LogisticRegression(random_state=0, max_iter=500).fit(X, y)\n",
       "    yield\n",
       "    # Clean up the ML models and release the resources\n",
       "    \n",
       "    print(\"Exiting, clearing model dict!\")\n",
       "    ml_models.clear()\n",
       "    \n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "import_lifespan = \"\"\"from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import_fastkafka = \"\"\"from fastkafka import FastKafka\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "lifespan = \"\"\"ml_models = {}\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastKafka):\n",
    "    # Load the ML model\n",
    "    print(\"Loading the model!\")\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    ml_models[\"iris_predictor\"] = LogisticRegression(random_state=0, max_iter=500).fit(X, y)\n",
    "    yield\n",
    "    # Clean up the ML models and release the resources\n",
    "    \n",
    "    print(\"Exiting, clearing model dict!\")\n",
    "    ml_models.clear()\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{import_lifespan + import_fastkafka + lifespan}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebc906",
   "metadata": {},
   "source": [
    "The first thing to notice, is that we are defining an async function with `yield`. This is very similar to Dependencies with `yield`.\n",
    "\n",
    "The first part of the function, before the `yield`, will be executed **before** the application starts.\n",
    "And the part after the `yield` will be executed **after** the application has finished.\n",
    "\n",
    "This lifespan will create an iris_prediction model on application startup and cleanup the references after the app is shutdown.\n",
    "\n",
    "The lifespan will be passed an KafkaApp reference on startup of your application, which you can use to reference your application on startup.\n",
    "\n",
    "For demonstration sake, we also added prints so that when running the app we can see that our lifespan was called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74c00f",
   "metadata": {},
   "source": [
    "### Async context manager\n",
    "\n",
    "Context managers can be used in `with` blocks, our lifespan, for example could be used like this:\n",
    "\n",
    "```python\n",
    "ml_models = {}\n",
    "async with lifespan(None):\n",
    "    print(ml_models)\n",
    "```\n",
    "\n",
    "When you create a context manager or an async context manager, what it does is that, before entering the `with` block, it will execute the code before the `yield`, and after exiting the `with` block, it will execute the code after the `yield`.\n",
    "\n",
    "If you want to learn more about context managers and contextlib decorators, please visit [Python official docs](https://docs.python.org/3/library/contextlib.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d3323",
   "metadata": {},
   "source": [
    "## App demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449101a",
   "metadata": {},
   "source": [
    "### FastKafka app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f4163",
   "metadata": {},
   "source": [
    "Lets now create our application using the created lifespan handler.\n",
    "\n",
    "Notice how we passed our lifespan handler to the app when constructing it trough the `lifespan` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ed2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from fastkafka import FastKafka\n",
       "\n",
       "kafka_brokers = {\n",
       "    \"localhost\": {\n",
       "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
       "        \"description\": \"local development kafka broker\",\n",
       "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
       "    },\n",
       "}\n",
       "\n",
       "kafka_app = FastKafka(\n",
       "    title=\"Iris predictions\",\n",
       "    kafka_brokers=kafka_brokers,\n",
       "    lifespan=lifespan,\n",
       ")\n",
       "\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "app = \"\"\"kafka_brokers = {\n",
    "    \"localhost\": {\n",
    "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
    "        \"description\": \"local development kafka broker\",\n",
    "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
    "    },\n",
    "}\n",
    "\n",
    "kafka_app = FastKafka(\n",
    "    title=\"Iris predictions\",\n",
    "    kafka_brokers=kafka_brokers,\n",
    "    lifespan=lifespan,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{import_fastkafka + app}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ebb39",
   "metadata": {},
   "source": [
    "### Data modeling\n",
    "\n",
    "Lets model the Iris data for our app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea24631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from pydantic import BaseModel, Field, NonNegativeFloat\n",
       "\n",
       "class IrisInputData(BaseModel):\n",
       "    sepal_length: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Sepal length in cm\"\n",
       "    )\n",
       "    sepal_width: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Sepal width in cm\"\n",
       "    )\n",
       "    petal_length: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Petal length in cm\"\n",
       "    )\n",
       "    petal_width: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Petal width in cm\"\n",
       "    )\n",
       "\n",
       "\n",
       "class IrisPrediction(BaseModel):\n",
       "    species: str = Field(..., example=\"setosa\", description=\"Predicted species\")\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "import_pydantic = \"\"\"from pydantic import BaseModel, Field, NonNegativeFloat\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_model = \"\"\"class IrisInputData(BaseModel):\n",
    "    sepal_length: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Sepal length in cm\"\n",
    "    )\n",
    "    sepal_width: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Sepal width in cm\"\n",
    "    )\n",
    "    petal_length: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Petal length in cm\"\n",
    "    )\n",
    "    petal_width: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Petal width in cm\"\n",
    "    )\n",
    "\n",
    "\n",
    "class IrisPrediction(BaseModel):\n",
    "    species: str = Field(..., example=\"setosa\", description=\"Predicted species\")\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{import_pydantic + data_model}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ab2c5c",
   "metadata": {},
   "source": [
    "### Consumers and producers\n",
    "\n",
    "Lets create a consumer and producer for our app that will generate predictions from input iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aee2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "@kafka_app.consumes(topic=\"input_data\", auto_offset_reset=\"latest\")\n",
       "async def on_input_data(msg: IrisInputData):\n",
       "    species_class = ml_models[\"iris_predictor\"].predict(\n",
       "        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]\n",
       "    )[0]\n",
       "\n",
       "    to_predictions(species_class)\n",
       "\n",
       "\n",
       "@kafka_app.produces(topic=\"predictions\")\n",
       "def to_predictions(species_class: int) -> IrisPrediction:\n",
       "    iris_species = [\"setosa\", \"versicolor\", \"virginica\"]\n",
       "\n",
       "    prediction = IrisPrediction(species=iris_species[species_class])\n",
       "    return prediction\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producers_and_consumers = \"\"\"@kafka_app.consumes(topic=\"input_data\", auto_offset_reset=\"latest\")\n",
    "async def on_input_data(msg: IrisInputData):\n",
    "    species_class = ml_models[\"iris_predictor\"].predict(\n",
    "        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]\n",
    "    )[0]\n",
    "\n",
    "    await to_predictions(species_class)\n",
    "\n",
    "\n",
    "@kafka_app.produces(topic=\"predictions\")\n",
    "async def to_predictions(species_class: int) -> IrisPrediction:\n",
    "    iris_species = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "    prediction = IrisPrediction(species=iris_species[species_class])\n",
    "    return prediction\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{producers_and_consumers}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47123e0",
   "metadata": {},
   "source": [
    "### Final app\n",
    "\n",
    "The final app looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5969a922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from sklearn.datasets import load_iris\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from contextlib import asynccontextmanager\n",
       "\n",
       "from pydantic import BaseModel, Field, NonNegativeFloat\n",
       "\n",
       "from fastkafka import FastKafka\n",
       "\n",
       "class IrisInputData(BaseModel):\n",
       "    sepal_length: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Sepal length in cm\"\n",
       "    )\n",
       "    sepal_width: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Sepal width in cm\"\n",
       "    )\n",
       "    petal_length: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Petal length in cm\"\n",
       "    )\n",
       "    petal_width: NonNegativeFloat = Field(\n",
       "        ..., example=0.5, description=\"Petal width in cm\"\n",
       "    )\n",
       "\n",
       "\n",
       "class IrisPrediction(BaseModel):\n",
       "    species: str = Field(..., example=\"setosa\", description=\"Predicted species\")\n",
       "ml_models = {}\n",
       "\n",
       "@asynccontextmanager\n",
       "async def lifespan(app: FastKafka):\n",
       "    # Load the ML model\n",
       "    print(\"Loading the model!\")\n",
       "    X, y = load_iris(return_X_y=True)\n",
       "    ml_models[\"iris_predictor\"] = LogisticRegression(random_state=0, max_iter=500).fit(X, y)\n",
       "    yield\n",
       "    # Clean up the ML models and release the resources\n",
       "    \n",
       "    print(\"Exiting, clearing model dict!\")\n",
       "    ml_models.clear()\n",
       "    \n",
       "kafka_brokers = {\n",
       "    \"localhost\": {\n",
       "        \"url\": \"<url_of_your_kafka_bootstrap_server>\",\n",
       "        \"description\": \"local development kafka broker\",\n",
       "        \"port\": \"<port_of_your_kafka_bootstrap_server>\",\n",
       "    },\n",
       "}\n",
       "\n",
       "kafka_app = FastKafka(\n",
       "    title=\"Iris predictions\",\n",
       "    kafka_brokers=kafka_brokers,\n",
       "    lifespan=lifespan,\n",
       ")\n",
       "\n",
       "@kafka_app.consumes(topic=\"input_data\", auto_offset_reset=\"latest\")\n",
       "async def on_input_data(msg: IrisInputData):\n",
       "    species_class = ml_models[\"iris_predictor\"].predict(\n",
       "        [[msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]]\n",
       "    )[0]\n",
       "\n",
       "    to_predictions(species_class)\n",
       "\n",
       "\n",
       "@kafka_app.produces(topic=\"predictions\")\n",
       "def to_predictions(species_class: int) -> IrisPrediction:\n",
       "    iris_species = [\"setosa\", \"versicolor\", \"virginica\"]\n",
       "\n",
       "    prediction = IrisPrediction(species=iris_species[species_class])\n",
       "    return prediction\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "complete_app = (\n",
    "    import_lifespan\n",
    "    + import_pydantic\n",
    "    + import_fastkafka\n",
    "    + data_model\n",
    "    + lifespan\n",
    "    + app\n",
    "    + producers_and_consumers\n",
    ")\n",
    "md(f\"```python\\n{complete_app}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a3a24c",
   "metadata": {},
   "source": [
    "### Running the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2509682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Now we can run the app with your custom lifespan handler. Copy the code above in lifespan_example.py and run it by running\n",
       "```shell\n",
       "fastkafka run --num-workers=1 --kafka-broker=localhost lifespan_example:kafka_app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "script_file = \"lifespan_example.py\"\n",
    "cmd = (\n",
    "    \"fastkafka run --num-workers=1 --kafka-broker=localhost lifespan_example:kafka_app\"\n",
    ")\n",
    "md(\n",
    "    f\"Now we can run the app with your custom lifespan handler. Copy the code above in lifespan_example.py and run it by running\\n```shell\\n{cmd}\\n```\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a53cc7",
   "metadata": {},
   "source": [
    "When you run the app, you should see a simmilar output to the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8952a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "\n",
    "async def _run_example_app(\n",
    "    *, app_example: str, bootstrap_server: str, script_file: str, cmd: str\n",
    ") -> Tuple[int, str]:\n",
    "    server_url = bootstrap_server.split(\":\")[0]\n",
    "    server_port = bootstrap_server.split(\":\")[1]\n",
    "    exit_code, output = await run_script_and_cancel(\n",
    "        script=app_example.replace(\n",
    "            \"<url_of_your_kafka_bootstrap_server>\", server_url\n",
    "        ).replace(\"<port_of_your_kafka_bootstrap_server>\", server_port),\n",
    "        script_file=script_file,\n",
    "        cmd=cmd,\n",
    "        cancel_after=5,\n",
    "    )\n",
    "    return exit_code, output.decode(\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 261872...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 261872 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 261511...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 261511 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "with ApacheKafkaBroker(\n",
    "    topicas=[\"hello_world\"], apply_nest_asyncio=True\n",
    ") as bootstrap_server:\n",
    "    exit_code, output = await _run_example_app(\n",
    "        app_example=complete_app,\n",
    "        bootstrap_server=bootstrap_server,\n",
    "        script_file=script_file,\n",
    "        cmd=cmd,\n",
    "    )\n",
    "    assert exit_code == 0, output\n",
    "    assert \"Loading the model!\" in output\n",
    "    assert \"Exiting, clearing model dict!\" in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e5eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262292]: [INFO] fastkafka._application.app: set_kafka_broker() : Setting bootstrap_servers value to '127.0.0.1:9092'\n",
      "[262292]: Loading the model!\n",
      "[262292]: [INFO] fastkafka._application.app: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100}\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[262292]: [INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})\n",
      "[262292]: [INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[262292]: [WARNING] aiokafka.cluster: Topic input_data is not available during auto-create initialization\n",
      "[262292]: [INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'input_data': 0}. \n",
      "Starting process cleanup, this may take a few seconds...\n",
      "[INFO] fastkafka._server: terminate_asyncio_process(): Terminating the process 262292...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[262292]: [INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "[262292]: Exiting, clearing model dict!\n",
      "[INFO] fastkafka._server: terminate_asyncio_process(): Process 262292 terminated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2192a4f5",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In this guide we have defined a lifespan handler and passed to our FastKafka app.\n",
    "\n",
    "Some important points are:\n",
    "\n",
    "1. Lifespan handler is implemented as [AsyncContextManager](https://docs.python.org/3/library/contextlib.html#contextlib.asynccontextmanager)\n",
    "2. Code **before** yield in lifespan will be executed **before** application **startup**\n",
    "3. Code **after** yield in lifespan will be executed **after** application **shutdown**\n",
    "4. You can pass your lifespan handler to FastKafka app on initialisation by passing a `lifespan` argument\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
