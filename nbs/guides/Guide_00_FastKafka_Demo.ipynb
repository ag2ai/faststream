{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastKafka\n",
    "\n",
    "This notebook will demonstrate the capabilities and developed functionalities in FastKafka project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/airtai/fastkafka/blob/64-colab-based-tutorial/nbs/guides/Guide_00_FastKafka_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing fastkafka library\n",
    "\n",
    "To install fastkafka, run: `pip install fastkafka` in your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import fastkafka\n",
    "except ImportError:\n",
    "    #!pip install fastkafka==0.1.0\n",
    "    !pip install \"fastkafka @ git+https://github.com/airtai/fastkafka@c082b8264819c11183cae89b2868f6bc51350371\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LocalKafkaBroker\n",
    "\n",
    "To be able to test and demonstrate the use of FastKafka, we have developed a python wrapper for Zookeeper and Kafka broker which is demonstrated here and used later in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkafka.testing import LocalKafkaBroker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start the LocalKafkaBroker\n",
    "\n",
    "When LocalKafkaBroker is started, it checks if there are Java and Kafka installed on the system, if not, it will install them and export them to path as it is necessary for it to function.\n",
    "\n",
    "Note: We use `apply_nest_asyncio=True` when creating the broker in the notebook to enable it to run in a nested async loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka.testing: Java is already installed.\n",
      "[INFO] fastkafka.testing: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka.testing: Kafka is already installed.\n",
      "[INFO] fastkafka.testing: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka.testing: Starting zookeeper...\n",
      "[INFO] fastkafka.testing: zookeeper started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Starting kafka...\n",
      "[INFO] fastkafka.testing: kafka started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: <class 'fastkafka.testing.LocalKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): exited.\n",
      "127.0.0.1:9092\n"
     ]
    }
   ],
   "source": [
    "local_broker = LocalKafkaBroker(apply_nest_asyncio=True)\n",
    "bootstrap_server = local_broker.start()\n",
    "print(bootstrap_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if there are any topics in our fresh Kafka broker. If everything is okay, there should be none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "! kafka-topics.sh --list --bootstrap-server {bootstrap_server}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now create a topic, list it, and describe it to see that our LocalKafkaBroker is really running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic quickstart-events.\r\n"
     ]
    }
   ],
   "source": [
    "! kafka-topics.sh --create --topic quickstart-events --bootstrap-server {bootstrap_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quickstart-events\r\n"
     ]
    }
   ],
   "source": [
    "! kafka-topics.sh --list --bootstrap-server {bootstrap_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: quickstart-events\tTopicId: 3vDYPDnKS36PEHf2o6im6A\tPartitionCount: 1\tReplicationFactor: 1\tConfigs: flush.ms=1000,segment.bytes=1073741824,flush.messages=10000,retention.bytes=1073741824\n",
      "\tTopic: quickstart-events\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n"
     ]
    }
   ],
   "source": [
    "! kafka-topics.sh --describe --topic quickstart-events --bootstrap-server {bootstrap_server}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can stop the broker as it is no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 41096...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 41096 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 40713...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 40713 terminated.\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "local_broker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LocalKafkaBroker can also be used as a context manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka.testing: Java is already installed.\n",
      "[INFO] fastkafka.testing: Kafka is already installed.\n",
      "[INFO] fastkafka.testing: Starting zookeeper...\n",
      "[INFO] fastkafka.testing: zookeeper started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Starting kafka...\n",
      "[INFO] fastkafka.testing: kafka started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: <class 'fastkafka.testing.LocalKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): exited.\n",
      "127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 43527...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 43527 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 43144...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 43144 terminated.\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "with LocalKafkaBroker(apply_nest_asyncio=True) as bootstrap_server:\n",
    "    print(bootstrap_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastKafka demo\n",
    "\n",
    "Now we will create a fastkafka application containing a Model that will ingest data samples from one Kafka topic (input_data) and produce predictions to another Kafka topic (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the demo model\n",
    "\n",
    "First we will prepare our model with the Iris dataset so that we can demonstrate the preditions using FastKafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = LogisticRegression(random_state=0, max_iter=500).fit(X, y)\n",
    "x = X[[0, 55, -1]]\n",
    "print(x)\n",
    "print(model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to model the input and prediction messages that will be sent to the Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, NonNegativeFloat, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisInputData(BaseModel):\n",
    "    sepal_length: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Sepal length in cm\"\n",
    "    )\n",
    "    sepal_width: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Sepal width in cm\"\n",
    "    )\n",
    "    petal_length: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Petal length in cm\"\n",
    "    )\n",
    "    petal_width: NonNegativeFloat = Field(\n",
    "        ..., example=0.5, description=\"Petal width in cm\"\n",
    "    )\n",
    "\n",
    "\n",
    "class IrisPredictionData(BaseModel):\n",
    "    species: str = Field(..., example=\"Iris-setosa\", description=\"Predicted species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets prepare our prediction FastKafka app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkafka.application import FastKafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_app = FastKafka()\n",
    "\n",
    "iris_species = [\"setosa\", \"versicolor\", \"Iris-virginica\"]\n",
    "\n",
    "@kafka_app.consumes(topic=\"input_data\", auto_offset_reset=\"latest\", group_id=\"my_group\")\n",
    "async def on_input_data(msg: IrisInputData):\n",
    "    global model\n",
    "    species_class = model.predict([\n",
    "          [msg.sepal_length, msg.sepal_width, msg.petal_length, msg.petal_width]\n",
    "        ])[0]\n",
    "\n",
    "    to_predictions(species_class)\n",
    "\n",
    "\n",
    "@kafka_app.produces(topic=\"predictions\")\n",
    "def to_predictions(species_class: int) -> IrisPredictionData:\n",
    "    prediction = IrisPredictionData(species=iris_species[species_class])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the test by sending a message to the running app that now encapsulates the Iris classification model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastkafka.application import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka.testing: LocalKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka.testing: Java is already installed.\n",
      "[INFO] fastkafka.testing: Kafka is already installed.\n",
      "[INFO] fastkafka.testing: Starting zookeeper...\n",
      "[INFO] fastkafka.testing: zookeeper started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Starting kafka...\n",
      "[INFO] fastkafka.testing: kafka started, sleeping for 5 seconds...\n",
      "[INFO] fastkafka.testing: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: <class 'fastkafka.testing.LocalKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Entering...\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': '127.0.0.1:9092'}'\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'latest', 'max_poll_records': 100, 'group_id': 'my_group'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'input_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'input_data'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': '127.0.0.1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'predictions'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'predictions'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'predictions': 1}. \n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[ERROR] aiokafka.consumer.group_coordinator: Group Coordinator Request failed: [Error 15] CoordinatorNotAvailableError\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 0 for group my_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group my_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group my_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'my_group' (generation 1) with member_id aiokafka-0.8.0-10db6372-34d8-48a7-90b5-4b3598e7b606\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group my_group with generation 1\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='input_data', partition=0)} for group my_group\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[INFO] fastkafka._components.aiokafka_producer_manager: AIOKafkaProducerManager.stop(): Finished\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 44641...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 44641 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 44261...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 44261 terminated.\n",
      "[INFO] fastkafka.testing: LocalKafkaBroker.stop(): exited.\n",
      "****************************************************************************************************\n",
      "Sent data: sepal_length=0.1 sepal_width=0.2 petal_length=0.3 petal_width=0.4\n",
      "Received prediction: call(IrisPredictionData(species='setosa'))\n"
     ]
    }
   ],
   "source": [
    "msg = IrisInputData(\n",
    "    sepal_length=0.1,\n",
    "    sepal_width=0.2,\n",
    "    petal_length=0.3,\n",
    "    petal_width=0.4,\n",
    ")\n",
    "\n",
    "with LocalKafkaBroker(\n",
    "    topics=[\"input_data\", \"predictions\"], apply_nest_asyncio=True\n",
    ") as bootstrap_servers:\n",
    "    kafka_app.set_bootstrap_servers(bootstrap_servers=bootstrap_servers)\n",
    "    async with Tester(kafka_app) as tester:\n",
    "        await tester.to_input_data(msg)\n",
    "        await tester.awaited_mocks.on_predictions.assert_awaited(timeout=2)\n",
    "        prediction = tester.mocks.on_predictions.call_args\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(f\"Sent data: {msg}\")\n",
    "print(f\"Received prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "\n",
    "We have created a Iris classification model and encapulated it into our fastkafka application.\n",
    "The app will consume the IrisInputData from the `input_data` topic and produce the predictions to `predictions` topic.\n",
    "\n",
    "To test the app we have:\n",
    "1. Created the app\n",
    "1. Started the LocalKafkaBroker\n",
    "2. Started our Tester class which mirrors the developed app topics for testing purpuoses\n",
    "3. Sent IrisInputData message to `input_data` topic\n",
    "4. Asserted and checked that the developed iris classification service has reacted to IrisInputData message "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "The kafka app comes with builtin documentation generation, let's demonstrate that.\n",
    "\n",
    "To generate the documentation programatically you just need to call `.generate_docs()` method of your app. This will generate the *asyncapi* folder in relative path where all your documentation will be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.asyncapi: Old async specifications at '/work/fastkafka/nbs/guides/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fastkafka._components.asyncapi: New async specifications generated at: '/work/fastkafka/nbs/guides/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fastkafka._components.asyncapi: Async docs generated at 'asyncapi/docs'\n",
      "[INFO] fastkafka._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'\u001b[32m\n",
      "\n",
      "Done! ✨\u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/work/fastkafka/nbs/guides/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_app.create_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs  spec\r\n"
     ]
    }
   ],
   "source": [
    "! ls asyncapi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In docs folder you will fint the serveable static html file of your documentation. This can also be served using our `fastkafka docs serve` CLI command (more on that in our guides).\n",
    "\n",
    "In spec folder you will find a asyncapi.yml file containing the async API specification of your application. We will now generate a link to AsyncAPI from the docs that will load your documentation for quick inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://studio.asyncapi.com/?base64=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\n"
     ]
    }
   ],
   "source": [
    "with open(\"asyncapi/spec/asyncapi.yml\", \"r\") as async_specs:\n",
    "    specs = async_specs.read()\n",
    "    base64_specs = base64.b64encode(specs.encode(\"UTF-8\")).decode(\"UTF-8\")\n",
    "    print(f\"https://studio.asyncapi.com/?base64={base64_specs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Start the broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"input_data\", \"predictions\"], apply_nest_asyncio=True)\n",
    "bootstrap_server = broker.start()\n",
    "app.set_bootstrap_servers(bootstrap_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Started our Tester class which mirrors the developed app topics for testing purpuoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Tester(app)\n",
    "await tester.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Send a message and see what we get at the predictions topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = IrisInputData(\n",
    "    sepal_length=X[0][0],\n",
    "    sepal_width=X[0][1],\n",
    "    petal_length=X[0][2],\n",
    "    petal_width=X[0][3],\n",
    ")\n",
    "\n",
    "await tester.to_input_data(msg)\n",
    "await tester.awaited_mocks.on_predictions.assert_awaited(timeout=2)\n",
    "print(f\"Sent data: {msg}\")\n",
    "print(f\"Received prediction: {tester.mocks.on_predictions.call_args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To keep everything clean, close the broker and tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await tester.__aexit__(None, None, None)\n",
    "broker.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When condensed into one cell, the test looks like this:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
