{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48d0afd",
   "metadata": {},
   "source": [
    "# First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd434418",
   "metadata": {},
   "source": [
    "## Creating a simple Kafka consumer app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from fastkafka.testing import run_script_and_cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | notest\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75545b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073bb3b",
   "metadata": {},
   "source": [
    "For our first demo we will create the simplest possible Kafka consumer and run it using uvicorn.\n",
    "\n",
    "The consumer will:\n",
    "\n",
    "1. Connect to the Kafka Broker we setup in the Intro guide\n",
    "\n",
    "2. Listen to the hello topic\n",
    "\n",
    "3. Write any message received from the hello topic to stdout\n",
    "    \n",
    "To create the consumer, first, create a file named <b>hello_kafka_consumer.py</b> and copy the following code to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "from os import environ\n",
       "\n",
       "from fastkafka.application import FastKafka\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
       "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
       "\n",
       "kafka_config = {\n",
       "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
       "    }\n",
       "\n",
       "class HelloKafkaMsg(BaseModel):\n",
       "    msg: str = Field(\n",
       "        ...,\n",
       "        example=\"Hello\",\n",
       "        description=\"Demo hello world message\",\n",
       "    )\n",
       "\n",
       "kafka_app = FastKafka(\n",
       "    **kafka_config,\n",
       ")\n",
       "    \n",
       "@kafka_app.consumes()\n",
       "async def on_hello(msg: HelloKafkaMsg):\n",
       "    print(f\"Got data, msg={msg.msg}\")\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "consumer_script = \"\"\"\n",
    "from os import environ\n",
    "\n",
    "from fastkafka.application import FastKafka\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    }\n",
    "\n",
    "class HelloKafkaMsg(BaseModel):\n",
    "    msg: str = Field(\n",
    "        ...,\n",
    "        example=\"Hello\",\n",
    "        description=\"Demo hello world message\",\n",
    "    )\n",
    "\n",
    "kafka_app = FastKafka(\n",
    "    **kafka_config,\n",
    ")\n",
    "    \n",
    "@kafka_app.consumes()\n",
    "async def on_hello(msg: HelloKafkaMsg):\n",
    "    print(f\"Got data, msg={msg.msg}\")\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{consumer_script}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845837e",
   "metadata": {},
   "source": [
    "!!! info \\\"Kafka configuration\\\"\n",
    "\n",
    "    This consumer script uses KAFKA_HOSTNAME and KAFKA_PORT environment vars, so make sure that you have exported them into your environment before running the following comand (e.g. in shell, for KAFKA_HOSTNAME, run: 'export KAFKA_HOSTNAME=kafka')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efde628",
   "metadata": {},
   "source": [
    "To run this consumer, in your terminal, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5100a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```shell\n",
       "fastkafka run hello_kafka_consumer:kafka_app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "consumer_cmd = \"fastkafka run hello_kafka_consumer:kafka_app\"\n",
    "\n",
    "md(f\"```shell\\n{consumer_cmd}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3770bc",
   "metadata": {},
   "source": [
    "After running the command, you should see something similar to the ouput below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ede31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._cli: Starting workers in process: 211\n",
      "[INFO] fastkafka.application: Started server process 211\n",
      "[INFO] fastkafka._components.asyncapi: Old async specifications at '/tmp/tmp0p4epc9l/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fastkafka._components.asyncapi: New async specifications generated at: '/tmp/tmp0p4epc9l/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'hello'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'hello'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'hello': 1}. \n",
      "[INFO] fastkafka._cli: Stopping workers....\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka.application: Finished server process 211\n",
      "[INFO] fastkafka._cli: Stopped workers in process: 211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "exit_code, output = await run_script_and_cancel(\n",
    "    script=consumer_script,\n",
    "    script_file=\"hello_kafka_consumer.py\",\n",
    "    cmd=consumer_cmd,\n",
    "    cancel_after=10,\n",
    ")\n",
    "\n",
    "assert exit_code == 0, output.decode(\"utf-8\")\n",
    "print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4df11",
   "metadata": {},
   "source": [
    "Now you can interact with your consumer, by sending the messages to the subscribed 'hello' topic, don't worry, we will cover this in the next step of this guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28903bc",
   "metadata": {},
   "source": [
    "## Sending first message to your consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de2731",
   "metadata": {},
   "source": [
    "After we have created and run our first consumer, we should send a message to it, to make sure it is working properly.\n",
    "\n",
    "If you are using the Kafka setup as described in the Intro guide, you can follow the steps listed here to send a message to the hello topic.\n",
    "\n",
    "First, connect to your running kafka broker by running:\n",
    "\n",
    "``` shell\n",
    "docker run -it kafka /bin/bash\n",
    "```\n",
    "\n",
    "Then, when connected to the container, run:\n",
    "\n",
    "``` shell\n",
    "kafka-console-producer.sh --bootstrap-server=localhost:9092 --topic=hello\n",
    "```\n",
    "\n",
    "This will open an interactive connection to the hello topic, now you can write your mesages to the topic and they will be consumed by our consumer.\n",
    "\n",
    "In the shell, type:\n",
    "``` shell\n",
    "{\"msg\":\"hello\"}\n",
    "```\n",
    "and press enter. This will send a hello message to the topic which will be read by our running consumer and outputed to stdout.\n",
    "\n",
    "Check the output of your consumer (terminal where you run the uvicorn command) and confirm that your consumer has read the Kafka message. You shoud see something like this:\n",
    "``` shell\n",
    "Got data, msg=hello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc013025",
   "metadata": {},
   "source": [
    "## Creating a hello Kafka producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e725f",
   "metadata": {},
   "source": [
    "Consuming messages is only a part of this Library functionality, the other big part is producing the messages. So, let's create our first kafka producer which will send it's greetings to our consumer periodically.\n",
    "\n",
    "The producer will:\n",
    "\n",
    "1. Connect to the Kafka Broker we setup in the Intro guide\n",
    "2. Connect to the hello topic\n",
    "3. Periodically send a message to the hello world topic\n",
    "    \n",
    "To create the producer, first, create a file named <b>hello_kafka_producer.py</b> and copy the following code to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c5876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "from os import environ\n",
       "\n",
       "import asyncio\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "from fastkafka.application import FastKafka\n",
       "from fastkafka._components.logger import get_logger\n",
       "\n",
       "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
       "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
       "\n",
       "kafka_config = {\n",
       "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
       "    }\n",
       "\n",
       "class HelloKafkaMsg(BaseModel):\n",
       "    msg: str = Field(\n",
       "        ...,\n",
       "        example=\"Hello\",\n",
       "        description=\"Demo hello world message\",\n",
       "    )\n",
       "\n",
       "kafka_app = FastKafka(\n",
       "    **kafka_config,\n",
       ")\n",
       "\n",
       "logger = get_logger(__name__)\n",
       "\n",
       "@kafka_app.produces()\n",
       "async def to_hello(msg: HelloKafkaMsg) -> HelloKafkaMsg:\n",
       "    logger.info(f\"Producing: {msg}\")\n",
       "    return msg\n",
       "\n",
       "@kafka_app.run_in_background()\n",
       "async def hello_every_second():\n",
       "    while(True):\n",
       "        await to_hello(HelloKafkaMsg(msg=\"hello\"))\n",
       "        await asyncio.sleep(1)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producer_script = \"\"\"\n",
    "from os import environ\n",
    "\n",
    "import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from fastkafka.application import FastKafka\n",
    "from fastkafka._components.logger import get_logger\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
    "    }\n",
    "\n",
    "class HelloKafkaMsg(BaseModel):\n",
    "    msg: str = Field(\n",
    "        ...,\n",
    "        example=\"Hello\",\n",
    "        description=\"Demo hello world message\",\n",
    "    )\n",
    "\n",
    "kafka_app = FastKafka(\n",
    "    **kafka_config,\n",
    ")\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "@kafka_app.produces()\n",
    "async def to_hello(msg: HelloKafkaMsg) -> HelloKafkaMsg:\n",
    "    logger.info(f\"Producing: {msg}\")\n",
    "    return msg\n",
    "\n",
    "@kafka_app.run_in_background()\n",
    "async def hello_every_second():\n",
    "    while(True):\n",
    "        await to_hello(HelloKafkaMsg(msg=\"hello\"))\n",
    "        await asyncio.sleep(1)\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{producer_script}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3eb5f",
   "metadata": {},
   "source": [
    "!!! info \\\"Kafka configuration\\\"\n",
    "\n",
    "    This producer script uses KAFKA_HOSTNAME and KAFKA_PORT environment vars, so make sure that you have exported them into your environment before running the following comand (e.g. in shell, for KAFKA_HOSTNAME, run: 'export KAFKA_HOSTNAME=kafka')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310d1cd",
   "metadata": {},
   "source": [
    "To run this producer, in your terminal, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cd807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```shell\n",
       "fastkafka run hello_kafka_producer:kafka_app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producer_cmd = \"fastkafka run hello_kafka_producer:kafka_app\"\n",
    "\n",
    "md(f\"```shell\\n{producer_cmd}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de248bc",
   "metadata": {},
   "source": [
    "After running the command, you should see something similar to the ouput below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf137c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "[INFO] fastkafka._cli: Starting workers in process: 215\n[INFO] fastkafka.application: Started server process 215\n[INFO] fastkafka._components.asyncapi: Old async specifications at '/tmp/tmpft5zdk8m/asyncapi/spec/asyncapi.yml' does not exist.\n[INFO] fastkafka._components.asyncapi: New async specifications generated at: '/tmp/tmpft5zdk8m/asyncapi/spec/asyncapi.yml'\n[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n[INFO] hello_kafka_producer: Producing: msg='hello'\n[ERROR] asyncio: Exception in callback CancelScope._deliver_cancellation()\nhandle: <Handle CancelScope._deliver_cancellation()>\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 424, in _deliver_cancellation\n    cancel_scope = _task_states[task].cancel_scope\n  File \"/usr/lib/python3.10/weakref.py\", line 416, in __getitem__\n    return self.data[ref(key)]\nKeyError: <weakref at 0x7fd9062904a0; to '_asyncio.Task' at 0x7fd90a636dc0>\nTraceback (most recent call last):\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 103, in serve\n    await self.main_loop()\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 132, in main_loop\n    await asyncio.sleep(0.1)\n  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 605, in sleep\n    return await future\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tvrtko/.local/bin/fastkafka\", line 33, in <module>\n    sys.exit(load_entry_point('fastkafka', 'console_scripts', 'fastkafka')())\n  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 778, in main\n    return _main(\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 151, in run\n    worker_handler.run()\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 89, in run\n    return asyncio.run(self.serve())\n  File \"/usr/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 646, in run_until_complete\n    return future.result()\nasyncio.exceptions.CancelledError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# | echo: false\u001b[39;00m\n\u001b[1;32m      3\u001b[0m exit_code, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_script_and_cancel(\n\u001b[1;32m      4\u001b[0m     script\u001b[38;5;241m=\u001b[39mproducer_script,\n\u001b[1;32m      5\u001b[0m     script_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello_kafka_producer.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     cmd\u001b[38;5;241m=\u001b[39mproducer_cmd,\n\u001b[1;32m      7\u001b[0m     cancel_after\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m exit_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: [INFO] fastkafka._cli: Starting workers in process: 215\n[INFO] fastkafka.application: Started server process 215\n[INFO] fastkafka._components.asyncapi: Old async specifications at '/tmp/tmpft5zdk8m/asyncapi/spec/asyncapi.yml' does not exist.\n[INFO] fastkafka._components.asyncapi: New async specifications generated at: '/tmp/tmpft5zdk8m/asyncapi/spec/asyncapi.yml'\n[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n[INFO] hello_kafka_producer: Producing: msg='hello'\n[ERROR] asyncio: Exception in callback CancelScope._deliver_cancellation()\nhandle: <Handle CancelScope._deliver_cancellation()>\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 424, in _deliver_cancellation\n    cancel_scope = _task_states[task].cancel_scope\n  File \"/usr/lib/python3.10/weakref.py\", line 416, in __getitem__\n    return self.data[ref(key)]\nKeyError: <weakref at 0x7fd9062904a0; to '_asyncio.Task' at 0x7fd90a636dc0>\nTraceback (most recent call last):\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 103, in serve\n    await self.main_loop()\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 132, in main_loop\n    await asyncio.sleep(0.1)\n  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 605, in sleep\n    return await future\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tvrtko/.local/bin/fastkafka\", line 33, in <module>\n    sys.exit(load_entry_point('fastkafka', 'console_scripts', 'fastkafka')())\n  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 778, in main\n    return _main(\n  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 151, in run\n    worker_handler.run()\n  File \"/work/fastkafka/fastkafka/_cli.py\", line 89, in run\n    return asyncio.run(self.serve())\n  File \"/usr/lib/python3.10/asyncio/runners.py\", line 44, in run\n    return loop.run_until_complete(main)\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 646, in run_until_complete\n    return future.result()\nasyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "exit_code, output = await run_script_and_cancel(\n",
    "    script=producer_script,\n",
    "    script_file=\"hello_kafka_producer.py\",\n",
    "    cmd=producer_cmd,\n",
    "    cancel_after=10,\n",
    ")\n",
    "\n",
    "assert exit_code == 0, output.decode(\"utf-8\")\n",
    "print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b869e2b",
   "metadata": {},
   "source": [
    "Now, while the producer is running, it will send a HelloKafkaMsg every second to the hello kafka topic.\n",
    "If your consumer is still running, you should see the messages appear in its log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286a108",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3409cc2",
   "metadata": {},
   "source": [
    "In this guide we have:\n",
    "    \n",
    "1. Created a simple Kafka consumer using FastKafka\n",
    "2. Sent a message to our consumer trough Kafka\n",
    "3. Created a simple Kafka producer using FastKafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0235a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
