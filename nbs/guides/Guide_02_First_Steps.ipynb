{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48d0afd",
   "metadata": {},
   "source": [
    "# First Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd434418",
   "metadata": {},
   "source": [
    "## Creating a simple Kafka consumer app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from fastkafka.testing import run_script_and_cancel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | notest\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75545b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# | notest\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073bb3b",
   "metadata": {},
   "source": [
    "For our first demo we will create the simplest possible Kafka consumer and run it using uvicorn.\n",
    "\n",
    "The consumer will:\n",
    "\n",
    "1. Connect to the Kafka Broker we setup in the Intro guide\n",
    "\n",
    "2. Listen to the hello topic\n",
    "\n",
    "3. Write any message received from the hello topic to stdout\n",
    "    \n",
    "To create the consumer, first, create a file named <b>hello_kafka_consumer.py</b> and copy the following code to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "from os import environ\n",
       "\n",
       "from fastkafka.application import FastKafka\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
       "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
       "\n",
       "kafka_config = {\n",
       "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
       "    }\n",
       "\n",
       "class HelloKafkaMsg(BaseModel):\n",
       "    msg: str = Field(\n",
       "        ...,\n",
       "        example=\"Hello\",\n",
       "        description=\"Demo hello world message\",\n",
       "    )\n",
       "\n",
       "kafka_app = FastKafka(\n",
       "    **kafka_config,\n",
       ")\n",
       "    \n",
       "@kafka_app.consumes()\n",
       "async def on_hello(msg: HelloKafkaMsg):\n",
       "    print(f\"Got data, msg={msg.msg}\")\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "consumer_script = \"\"\"\n",
    "from os import environ\n",
    "\n",
    "from fastkafka.application import FastKafka\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    }\n",
    "\n",
    "class HelloKafkaMsg(BaseModel):\n",
    "    msg: str = Field(\n",
    "        ...,\n",
    "        example=\"Hello\",\n",
    "        description=\"Demo hello world message\",\n",
    "    )\n",
    "\n",
    "kafka_app = FastKafka(\n",
    "    **kafka_config,\n",
    ")\n",
    "    \n",
    "@kafka_app.consumes()\n",
    "async def on_hello(msg: HelloKafkaMsg):\n",
    "    print(f\"Got data, msg={msg.msg}\")\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{consumer_script}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845837e",
   "metadata": {},
   "source": [
    "!!! info \\\"Kafka configuration\\\"\n",
    "\n",
    "    This consumer script uses KAFKA_HOSTNAME and KAFKA_PORT environment vars, so make sure that you have exported them into your environment before running the following comand (e.g. in shell, for KAFKA_HOSTNAME, run: 'export KAFKA_HOSTNAME=kafka')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efde628",
   "metadata": {},
   "source": [
    "To run this consumer, in your terminal, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5100a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```shell\n",
       "fastkafka run hello_kafka_consumer:app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "consumer_cmd = \"python3 -m fastkafka run hello_kafka_consumer:app\"\n",
    "\n",
    "md(f\"```shell\\n{consumer_cmd}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3770bc",
   "metadata": {},
   "source": [
    "After running the command, you should see something similar to the ouput below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ede31",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fastkafka'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# | echo: false\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m exit_code, output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_script_and_cancel(\n\u001b[1;32m      4\u001b[0m     script\u001b[38;5;241m=\u001b[39mconsumer_script,\n\u001b[1;32m      5\u001b[0m     script_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello_kafka_consumer.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     cmd\u001b[38;5;241m=\u001b[39mconsumer_cmd,\n\u001b[1;32m      7\u001b[0m     cancel_after\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m exit_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/work/fastkafka/fastkafka/testing.py:408\u001b[0m, in \u001b[0;36mrun_script_and_cancel\u001b[0;34m(script, script_file, cmd, cancel_after, app_name, kafka_app_name, generate_docs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    404\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    405\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating docs failed for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(script_file)\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkafka_app_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ignoring it for now.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m         )\n\u001b[0;32m--> 408\u001b[0m proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# nosec: [B603:subprocess_without_shell_equals_true] subprocess call - check for execution of untrusted input.\u001b[39;49;00m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshlex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(cancel_after)\n\u001b[1;32m    412\u001b[0m proc\u001b[38;5;241m.\u001b[39mterminate()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    966\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    967\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1845\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1844\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'fastkafka'"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "exit_code, output = await run_script_and_cancel(\n",
    "    script=consumer_script,\n",
    "    script_file=\"hello_kafka_consumer.py\",\n",
    "    cmd=consumer_cmd,\n",
    "    cancel_after=30,\n",
    ")\n",
    "\n",
    "assert exit_code == 0, output.decode(\"utf-8\")\n",
    "print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4df11",
   "metadata": {},
   "source": [
    "Now you can interact with your consumer, by sending the messages to the subscribed 'hello' topic, don't worry, we will cover this in the next step of this guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28903bc",
   "metadata": {},
   "source": [
    "## Sending first message to your consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de2731",
   "metadata": {},
   "source": [
    "After we have created and run our first consumer, we should send a message to it, to make sure it is working properly.\n",
    "\n",
    "If you are using the Kafka setup as described in the Intro guide, you can follow the steps listed here to send a message to the hello topic.\n",
    "\n",
    "First, connect to your running kafka broker by running:\n",
    "\n",
    "``` shell\n",
    "docker run -it kafka /bin/bash\n",
    "```\n",
    "\n",
    "Then, when connected to the container, run:\n",
    "\n",
    "``` shell\n",
    "kafka-console-producer.sh --bootstrap-server=localhost:9092 --topic=hello\n",
    "```\n",
    "\n",
    "This will open an interactive connection to the hello topic, now you can write your mesages to the topic and they will be consumed by our consumer.\n",
    "\n",
    "In the shell, type:\n",
    "``` shell\n",
    "{\"msg\":\"hello\"}\n",
    "```\n",
    "and press enter. This will send a hello message to the topic which will be read by our running consumer and outputed to stdout.\n",
    "\n",
    "Check the output of your consumer (terminal where you run the uvicorn command) and confirm that your consumer has read the Kafka message. You shoud see something like this:\n",
    "``` shell\n",
    "Got data, msg=hello\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc013025",
   "metadata": {},
   "source": [
    "## Creating a hello Kafka producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e725f",
   "metadata": {},
   "source": [
    "Consuming messages is only a part of this Library functionality, the other big part is producing the messages. So, let's create our first kafka producer which will send it's greetings to our consumer periodically.\n",
    "\n",
    "The producer will:\n",
    "\n",
    "1. Connect to the Kafka Broker we setup in the Intro guide\n",
    "2. Connect to the hello topic\n",
    "3. Periodically send a message to the hello world topic\n",
    "    \n",
    "To create the producer, first, create a file named <b>hello_kafka_producer.py</b> and copy the following code to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c5876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "from os import environ\n",
       "\n",
       "from fastapi import FastAPI\n",
       "\n",
       "import asyncio\n",
       "from pydantic import BaseModel, Field\n",
       "\n",
       "from fast_kafka_api.application import FastKafka\n",
       "from fast_kafka_api._components.logger import get_logger\n",
       "\n",
       "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
       "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
       "\n",
       "kafka_config = {\n",
       "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
       "    }\n",
       "\n",
       "class HelloKafkaMsg(BaseModel):\n",
       "    msg: str = Field(\n",
       "        ...,\n",
       "        example=\"Hello\",\n",
       "        description=\"Demo hello world message\",\n",
       "    )\n",
       "\n",
       "app = FastAPI()\n",
       "kafka_app = FastKafka(\n",
       "    fast_api_app=app,\n",
       "    **kafka_config,\n",
       ")\n",
       "\n",
       "@app.get(\"/hello\")\n",
       "async def hello() -> str:\n",
       "    return \"hello\"\n",
       "\n",
       "logger = get_logger(__name__)\n",
       "\n",
       "@kafka_app.produces()\n",
       "async def to_hello(msg: HelloKafkaMsg) -> HelloKafkaMsg:\n",
       "    logger.info(f\"Producing: {msg}\")\n",
       "    return msg\n",
       "\n",
       "@kafka_app.run_in_background()\n",
       "async def hello_every_second():\n",
       "    while(True):\n",
       "        await to_hello(HelloKafkaMsg(msg=\"hello\"))\n",
       "        await asyncio.sleep(1)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producer_script = \"\"\"\n",
    "from os import environ\n",
    "\n",
    "import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from fastkafka.application import FastKafka\n",
    "from fastkafka._components.logger import get_logger\n",
    "\n",
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "        \"bootstrap_servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
    "    }\n",
    "\n",
    "class HelloKafkaMsg(BaseModel):\n",
    "    msg: str = Field(\n",
    "        ...,\n",
    "        example=\"Hello\",\n",
    "        description=\"Demo hello world message\",\n",
    "    )\n",
    "\n",
    "kafka_app = FastKafka(\n",
    "    **kafka_config,\n",
    ")\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "@kafka_app.produces()\n",
    "async def to_hello(msg: HelloKafkaMsg) -> HelloKafkaMsg:\n",
    "    logger.info(f\"Producing: {msg}\")\n",
    "    return msg\n",
    "\n",
    "@kafka_app.run_in_background()\n",
    "async def hello_every_second():\n",
    "    while(True):\n",
    "        await to_hello(HelloKafkaMsg(msg=\"hello\"))\n",
    "        await asyncio.sleep(1)\n",
    "\"\"\"\n",
    "\n",
    "md(f\"```python\\n{producer_script}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3eb5f",
   "metadata": {},
   "source": [
    "!!! info \\\"Kafka configuration\\\"\n",
    "\n",
    "    This producer script uses KAFKA_HOSTNAME and KAFKA_PORT environment vars, so make sure that you have exported them into your environment before running the following comand (e.g. in shell, for KAFKA_HOSTNAME, run: 'export KAFKA_HOSTNAME=kafka')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310d1cd",
   "metadata": {},
   "source": [
    "To run this producer, in your terminal, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070cd807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```shell\n",
       "python3 -m uvicorn hello_kafka_producer:app --host 0.0.0.0 --port 6006\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "producer_cmd = \"python3 -m uvicorn hello_kafka_producer:app --host 0.0.0.0 --port 6006\"\n",
    "\n",
    "md(f\"```shell\\n{producer_cmd}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de248bc",
   "metadata": {},
   "source": [
    "After running the command, you should see something similar to the ouput below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf137c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [11116]\n",
      "INFO:     Waiting for application startup.\n",
      "[INFO] fast_kafka_api._components.asyncapi: Old async specifications at '/tmp/tmpshq9xpb9/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fast_kafka_api._components.asyncapi: New async specifications generated at: 'asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Async docs generated at 'asyncapi/docs'\n",
      "[INFO] fast_kafka_api._components.asyncapi: Output of '$ npx -y -p @asyncapi/generator ag asyncapi/spec/asyncapi.yml @asyncapi/html-template -o asyncapi/docs --force-write'\u001b[32m\n",
      "\n",
      "Done! ✨\u001b[0m\n",
      "\u001b[33mCheck out your shiny new generated files at \u001b[0m\u001b[35m/tmp/tmpshq9xpb9/asyncapi/docs\u001b[0m\u001b[33m.\u001b[0m\n",
      "\n",
      "\n",
      "[INFO] fast_kafka_api.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'davor-fast-kafka-api-kafka-1:9092'}'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:6006 (Press CTRL+C to quit)\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "[INFO] hello_kafka_producer: Producing: msg='hello'\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [11116]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "\n",
    "exit_code, output = await run_script_and_cancel(\n",
    "    script=producer_script,\n",
    "    script_file=\"hello_kafka_producer.py\",\n",
    "    cmd=producer_cmd,\n",
    "    cancel_after=30,\n",
    ")\n",
    "\n",
    "assert exit_code == 0, output.decode(\"utf-8\")\n",
    "print(output.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b869e2b",
   "metadata": {},
   "source": [
    "Now, while the producer is running, it will send a HelloKafkaMsg every second to the hello kafka topic.\n",
    "If your consumer is still running, you should see the messages appear in its log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286a108",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3409cc2",
   "metadata": {},
   "source": [
    "In this guide we have:\n",
    "    \n",
    "1. Created a simple Kafka consumer using FastKafka\n",
    "2. Sent a message to our consumer trough Kafka\n",
    "3. Created a simple Kafka producer using FastKafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0235a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
