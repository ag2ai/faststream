{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e3e7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _testing.local_kafka_broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dd1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import uuid\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "import asyncio\n",
    "\n",
    "from typing import *\n",
    "import fastkafka._application.app\n",
    "from aiokafka import AIOKafkaConsumer, AIOKafkaProducer\n",
    "from aiokafka.structs import ConsumerRecord, TopicPartition\n",
    "\n",
    "import fastkafka._application.app\n",
    "from fastkafka._components.meta import copy_func, patch, delegates, classcontextmanager\n",
    "from fastkafka._components.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df56c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e65cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8c6f7",
   "metadata": {},
   "source": [
    "# Local Kafka broker\n",
    "> In-memory mockup of Kafka broker protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7596402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_consumer_record(topic: str, msg: bytes) -> ConsumerRecord: # type: ignore\n",
    "    record = ConsumerRecord(\n",
    "        topic=topic,\n",
    "        partition=0,\n",
    "        offset=0,\n",
    "        timestamp=0,\n",
    "        timestamp_type=0,\n",
    "        key=None,\n",
    "        value=msg,\n",
    "        checksum=0,\n",
    "        serialized_key_size=0,\n",
    "        serialized_value_size=0,\n",
    "        headers=[],\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5791221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConsumerRecord(topic='my_topic', partition=1, offset=0, timestamp=0, timestamp_type=0, key=None, value=b'my_msg', checksum=0, serialized_key_size=0, serialized_value_size=0, headers=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = create_consumer_record(\"my_topic\", b\"my_msg\")\n",
    "record.partition = 1\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727d487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ConsumerMetadata:\n",
    "    topic: str\n",
    "    offset: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6ec35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_meta = ConsumerMetadata(\"my_topic\", 0)\n",
    "assert consumer_meta.topic == \"my_topic\"\n",
    "assert consumer_meta.offset == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5737f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls=<class '__main__.LocalKafkaBroker'>\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "\n",
    "@classcontextmanager()\n",
    "class LocalKafkaBroker:\n",
    "    def __init__(self, topics: List[str]):\n",
    "        self.data: Dict[str, List[ConsumerRecord]] = {topic: list() for topic in topics} # type: ignore\n",
    "        self.consumers_metadata: Dict[str, List[ConsumerMetadata]] = {}\n",
    "        self.is_started: bool = False\n",
    "\n",
    "    def connect(self) -> uuid.UUID:\n",
    "        return uuid.uuid4()\n",
    "\n",
    "    def subscribe(self, actor_id: str, *, auto_offest_reset: str, topic: str) -> None:\n",
    "        consumer_metadata = self.consumers_metadata.get(actor_id, list())\n",
    "        consumer_metadata.append(\n",
    "            ConsumerMetadata(\n",
    "                topic, len(self.data[topic]) if auto_offest_reset == \"latest\" else 0\n",
    "            )\n",
    "        )\n",
    "        self.consumers_metadata[actor_id] = consumer_metadata\n",
    "\n",
    "    def unsubscribe(self, actor_id: str) -> None:\n",
    "        try:\n",
    "            del self.consumers_metadata[actor_id]\n",
    "        except KeyError:\n",
    "            logger.warning(f\"No subscription with {actor_id=} found!\")\n",
    "\n",
    "    def produce(\n",
    "        self, actor_id: str, *, topic: str, msg: bytes, key: Optional[bytes]\n",
    "    ) -> ConsumerRecord: # type: ignore\n",
    "        record = create_consumer_record(topic, msg)\n",
    "        self.data[topic].append(record)\n",
    "        return record\n",
    "\n",
    "    def consume( # type: ignore\n",
    "        self, actor_id: str\n",
    "    ) -> Dict[TopicPartition, List[ConsumerRecord]]:\n",
    "        msgs: Dict[TopicPartition, List[ConsumerRecord]] = {} # type: ignore\n",
    "\n",
    "        try:\n",
    "            consumer_metadata = self.consumers_metadata[actor_id]\n",
    "        except KeyError:\n",
    "            logger.warning(f\"No subscription with {actor_id=} found!\")\n",
    "            return msgs\n",
    "\n",
    "        for metadata in consumer_metadata:\n",
    "            try:\n",
    "                msgs[TopicPartition(metadata.topic, 0)] = self.data[metadata.topic][\n",
    "                    metadata.offset :\n",
    "                ]\n",
    "                metadata.offset = len(self.data[metadata.topic])\n",
    "            except KeyError:\n",
    "                raise RuntimeError(\n",
    "                    f\"{metadata.topic=} not found, did you pass it to LocalKafkaBroker on init to be created?\"\n",
    "                )\n",
    "        return msgs\n",
    "    \n",
    "    def lifecycle(self) -> \"LocalKafkaBroker\":\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    async def _start(self) -> str:\n",
    "        logger.info(\"LocalKafkaBroker._start() called\")\n",
    "        self.__enter__()\n",
    "        return \"localbroker:0\"\n",
    "    \n",
    "    async def _stop(self) -> None:\n",
    "        logger.info(\"LocalKafkaBroker._stop() called\")\n",
    "        self.__exit__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ea19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b3a9",
   "metadata": {},
   "source": [
    "## Consumer patching\n",
    "\n",
    "We need to patch AIOKafkaConsumer methods so that we can redirect the consumer to our local kafka broker.\n",
    "\n",
    "Patched methods:\n",
    "\n",
    "- [x] \\_\\_init\\_\\_\n",
    "- [x] start\n",
    "- [x] subscribe\n",
    "- [x] stop\n",
    "- [x] getmany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85ca42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsumerMock:\n",
    "    def __init__(\n",
    "        self,\n",
    "        broker: LocalKafkaBroker,\n",
    "    ) -> None:\n",
    "        logger.info(\"AIOKafkaConsumer patched __init__() called()\")\n",
    "        self.broker = broker\n",
    "        self.id = None\n",
    "\n",
    "    @delegates(AIOKafkaConsumer)\n",
    "    def __call__(\n",
    "        self, auto_offset_reset: str = \"latest\", **kwargs: Any\n",
    "    ) -> \"ConsumerMock\":\n",
    "        self.auto_offset_reset = auto_offset_reset\n",
    "        return self\n",
    "\n",
    "    @delegates(AIOKafkaConsumer.start)\n",
    "    async def start(self, **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @delegates(AIOKafkaConsumer.subscribe)\n",
    "    def subscribe(self, topics: List[str], **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4df06",
   "metadata": {},
   "source": [
    "Patching start so that we don't try to start the real AIOKafkaConsumer instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f53f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.start)\n",
    "async def start(self: ConsumerMock, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaConsumer patched start() called()\")\n",
    "    if self.id is not None:\n",
    "        raise RuntimeError(\n",
    "            \"Consumer start() already called! Run consumer stop() before running start() again\"\n",
    "        )\n",
    "    self.id = self.broker.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072dd1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n"
     ]
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "consumer = ConsumerMock(broker)\n",
    "consumer = consumer()\n",
    "await consumer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c11cd3",
   "metadata": {},
   "source": [
    "Patching subscribe so that we can connect to our Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1de72311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.subscribe)\n",
    "def subscribe(self: ConsumerMock, topics: List[str], **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaConsumer patched subscribe() called\")\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\"Consumer start() not called! Run consumer start() first\")\n",
    "    logger.info(f\"AIOKafkaConsumer.subscribe(), subscribing to: {topics}\")\n",
    "    [\n",
    "        self.broker.subscribe(\n",
    "            self.id, topic=topic, auto_offest_reset=self.auto_offset_reset\n",
    "        )\n",
    "        for topic in topics\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945e08d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']\n"
     ]
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "consumer = ConsumerMock(broker)\n",
    "consumer = consumer()\n",
    "\n",
    "await consumer.start()\n",
    "consumer.subscribe([\"my_topic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80a4d5",
   "metadata": {},
   "source": [
    "Patching stop so that be dont break anything by calling the real AIOKafkaConsumer stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc82405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.stop)\n",
    "async def stop(self: ConsumerMock, **kwargs: Any) -> None: # type: ignore\n",
    "    logger.info(\"AIOKafkaConsumer patched stop() called\")\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Consumer start() not called! Run consumer start() first\"\n",
    "        )\n",
    "    self.broker.unsubscribe(self.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc667214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['my_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n"
     ]
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "    \n",
    "consumer = ConsumerMock(broker)\n",
    "consumer = consumer()\n",
    "\n",
    "await consumer.start()\n",
    "consumer.subscribe([\"my_topic\"])\n",
    "await consumer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c733b4",
   "metadata": {},
   "source": [
    "Patching getmany so that the messages are pulled from our Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0663c9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaConsumer.getmany)\n",
    "async def getmany(\n",
    "    self: ConsumerMock, **kwargs: Any\n",
    ") -> Dict[TopicPartition, List[ConsumerRecord]]:\n",
    "    return self.broker.consume(self.id) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4940bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[WARNING] __main__: No subscription with actor_id=None found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "consumer = ConsumerMock(broker)\n",
    "consumer = consumer()\n",
    "await consumer.getmany()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723468f0",
   "metadata": {},
   "source": [
    "## Producer patching\n",
    "\n",
    "We need to patch AIOKafkaProducer methods so that we can redirect the producer to our local kafka broker\n",
    "\n",
    "- [x] \\_\\_init\\_\\_\n",
    "- [x] start\n",
    "- [x] stop\n",
    "- [x] send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad3d6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProducerMock:\n",
    "    def __init__(self, broker: LocalKafkaBroker, **kwargs: Any) -> None:\n",
    "        logger.info(\"AIOKafkaProducer patched __init__() called()\")\n",
    "        self.broker = broker\n",
    "        self.id = None\n",
    "        \n",
    "    @delegates(AIOKafkaProducer)\n",
    "    def __call__(self, **kwargs: Any) -> \"ProducerMock\":\n",
    "        return self\n",
    "    \n",
    "    @delegates(AIOKafkaProducer.start)\n",
    "    async def start(self, **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @delegates(AIOKafkaProducer.stop)\n",
    "    async def stop(self, **kwargs: Any) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @delegates(AIOKafkaProducer.send)\n",
    "    async def send(  # type: ignore\n",
    "        self: AIOKafkaProducer,\n",
    "        topic: str,\n",
    "        msg: bytes,\n",
    "        key: Optional[bytes] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf322a",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducer start so that we mock the startup procedure of AIOKafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "488ac5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaProducer.start)\n",
    "async def start(self: ProducerMock, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaProducer patched start() called()\")\n",
    "    if self.id is not None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() already called! Run producer stop() before running start() again\"\n",
    "        )\n",
    "    self.id = self.broker.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f250c614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n"
     ]
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "producer = ProducerMock(broker)\n",
    "producer = producer()\n",
    "\n",
    "await producer.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e9be9",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducerStop so that we don't uniintentionally try to stop a real instance of AIOKafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32412969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaProducer.stop)\n",
    "async def stop(self: ProducerMock, **kwargs: Any) -> None:\n",
    "    logger.info(\"AIOKafkaProducer patched stop() called\")\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() not called! Run producer start() first\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f4a1fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n"
     ]
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "producer = ProducerMock(broker)\n",
    "producer = producer()\n",
    "\n",
    "await producer.start()\n",
    "await producer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c77a56",
   "metadata": {},
   "source": [
    "Patching AIOKafkaProducer send so that we redirect sent messages to Local, in-memory, Kafka broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f42a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@delegates(AIOKafkaProducer.send)\n",
    "async def send(\n",
    "    self: ProducerMock,\n",
    "    topic: str,\n",
    "    msg: bytes,\n",
    "    key: Optional[bytes] = None,\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    if self.id is None:\n",
    "        raise RuntimeError(\n",
    "            \"Producer start() not called! Run producer start() first\"\n",
    "        )\n",
    "    record = self.broker.produce(self.id, topic=topic, msg=msg, key=key)\n",
    "\n",
    "    async def _f(record: ConsumerRecord = record) -> ConsumerRecord:\n",
    "        return record\n",
    "\n",
    "    return asyncio.create_task(_f())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fda1d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConsumerRecord(topic='my_topic', partition=0, offset=0, timestamp=0, timestamp_type=0, key=None, value=b'some_msg', checksum=0, serialized_key_size=0, serialized_value_size=0, headers=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broker = LocalKafkaBroker(topics=[\"my_topic\"])\n",
    "\n",
    "producer = ProducerMock(broker)\n",
    "producer = producer()\n",
    "\n",
    "await producer.start()\n",
    "msg_fut = await producer.send(\"my_topic\", b\"some_msg\")\n",
    "await msg_fut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4d12b",
   "metadata": {},
   "source": [
    "## Add patching to LocalKafkaBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "446e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "@contextmanager\n",
    "def lifecycle(self: LocalKafkaBroker) -> None:\n",
    "    logger.info(\n",
    "        \"LocalKafkaProducer._patch_consumers_and_producers(): Patching consumers and producers!\"\n",
    "    )\n",
    "    try:\n",
    "        logger.info(\"Local kafka broker starting\")\n",
    "        old_consumer = fastkafka._application.app.AIOKafkaConsumer\n",
    "        old_producer = fastkafka._application.app.AIOKafkaProducer\n",
    "        fastkafka._application.app.AIOKafkaConsumer = ConsumerMock(self)\n",
    "        fastkafka._application.app.AIOKafkaProducer = ProducerMock(self)\n",
    "        self.is_started = True\n",
    "        yield self\n",
    "    finally:\n",
    "        logger.info(\"Local kafka broker stopping\")\n",
    "        fastkafka._application.app.AIOKafkaConsumer = old_consumer\n",
    "        fastkafka._application.app.AIOKafkaProducer = old_producer\n",
    "        self.is_started = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc55ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] asyncio: Unclosed AIOKafkaConsumer\n",
      "consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object at 0x7f4fecd51090>\n",
      "[ERROR] asyncio: Unclosed AIOKafkaProducer\n",
      "producer: <aiokafka.producer.producer.AIOKafkaProducer object at 0x7f4fecd52090>\n",
      "<class '__main__.LocalKafkaBroker'>.__enter__\n",
      "[INFO] __main__: LocalKafkaProducer._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: Local kafka broker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "<class '__main__.LocalKafkaBroker'>.__exit__\n",
      "[INFO] __main__: Local kafka broker stopping\n",
      "[ERROR] asyncio: Unclosed AIOKafkaConsumer\n",
      "consumer: <aiokafka.consumer.consumer.AIOKafkaConsumer object at 0x7f4fecd52510>\n",
      "[ERROR] asyncio: Unclosed AIOKafkaProducer\n",
      "producer: <aiokafka.producer.producer.AIOKafkaProducer object at 0x7f4fed251d10>\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(fastkafka._application.app.AIOKafkaConsumer(), AIOKafkaConsumer)\n",
    "assert isinstance(fastkafka._application.app.AIOKafkaProducer(), AIOKafkaProducer)\n",
    "with LocalKafkaBroker([\"topic\"]) as broker:\n",
    "    assert isinstance(fastkafka._application.app.AIOKafkaConsumer(), ConsumerMock)\n",
    "    assert isinstance(fastkafka._application.app.AIOKafkaProducer(), ProducerMock)\n",
    "    assert fastkafka._application.app.AIOKafkaConsumer().broker == broker\n",
    "    assert fastkafka._application.app.AIOKafkaProducer().broker == broker\n",
    "assert isinstance(fastkafka._application.app.AIOKafkaConsumer(), AIOKafkaConsumer)\n",
    "assert isinstance(fastkafka._application.app.AIOKafkaProducer(), AIOKafkaProducer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335aea0",
   "metadata": {},
   "source": [
    "## Broker, consumer and producer integration tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4275bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def create_consumer_and_producer(\n",
    "    auto_offset_reset: str = \"latest\",\n",
    ") -> AsyncIterator[Tuple[AIOKafkaConsumer, AIOKafkaProducer]]:\n",
    "    consumer = fastkafka._application.app.AIOKafkaConsumer(auto_offset_reset=auto_offset_reset)\n",
    "    producer = fastkafka._application.app.AIOKafkaProducer()\n",
    "\n",
    "    await consumer.start()\n",
    "    await producer.start()\n",
    "\n",
    "    yield (consumer, producer)\n",
    "\n",
    "    await consumer.stop()\n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a7688d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkEqual(L1, L2):\n",
    "    return len(L1) == len(L2) and sorted(L1) == sorted(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "800d6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert checkEqual([1, 2], [3]) == False\n",
    "assert checkEqual([1, 2, 3], [3, 2, 1]) == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc21a6e",
   "metadata": {},
   "source": [
    "Sanity check, let's see if the messages are sent to broker and received by the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f90249e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LocalKafkaBroker'>.__enter__\n",
      "[INFO] __main__: LocalKafkaProducer._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: Local kafka broker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.LocalKafkaBroker'>.__exit__\n",
      "[INFO] __main__: Local kafka broker stopping\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "sent_msgs = [f\"msg{i}\".encode(\"UTF-8\") for i in range(320)]\n",
    "\n",
    "with LocalKafkaBroker([topic]) as broker:\n",
    "    async with create_consumer_and_producer(auto_offset_reset=\"earliest\") as (\n",
    "        consumer,\n",
    "        producer,\n",
    "    ):\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs]\n",
    "        consumer.subscribe([topic])\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "        data = [msg.value for msg in broker.data[topic]]\n",
    "    assert checkEqual(\n",
    "        received_msgs, sent_msgs\n",
    "    ), f\"{sent_msgs=}\\n{received_msgs=}\\n{data=}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40fa9ed",
   "metadata": {},
   "source": [
    "Check if only subscribed topic messages are received by the consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "839a6755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LocalKafkaBroker'>.__enter__\n",
      "[INFO] __main__: LocalKafkaProducer._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: Local kafka broker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic1']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.LocalKafkaBroker'>.__exit__\n",
      "[INFO] __main__: Local kafka broker stopping\n"
     ]
    }
   ],
   "source": [
    "topic1 = \"test_topic1\"\n",
    "topic2 = \"test_topic2\"\n",
    "sent_msgs_1 = [(f\"msg{i}\" + topic1).encode(\"UTF-8\") for i in range(32)]\n",
    "sent_msgs_2 = [(f\"msg{i}\" + topic2).encode(\"UTF-8\") for i in range(32)]\n",
    "\n",
    "with LocalKafkaBroker([topic1, topic2]) as broker:\n",
    "    async with create_consumer_and_producer(auto_offset_reset=\"earliest\") as (\n",
    "        consumer,\n",
    "        producer,\n",
    "    ):\n",
    "        [await producer.send(topic1, msg) for msg in sent_msgs_1]\n",
    "        [await producer.send(topic2, msg) for msg in sent_msgs_2]\n",
    "\n",
    "        consumer.subscribe([topic1])\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "\n",
    "    assert checkEqual(sent_msgs_1, received_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1c5c5",
   "metadata": {},
   "source": [
    "Check if msgs are received only after subscribing when auto_offset_reset is set to \"latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed6bba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LocalKafkaBroker'>.__enter__\n",
      "[INFO] __main__: LocalKafkaProducer._patch_consumers_and_producers(): Patching consumers and producers!\n",
      "[INFO] __main__: Local kafka broker starting\n",
      "[INFO] __main__: AIOKafkaConsumer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched __init__() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched start() called()\n",
      "[INFO] __main__: AIOKafkaProducer patched start() called()\n",
      "[INFO] __main__: AIOKafkaConsumer patched subscribe() called\n",
      "[INFO] __main__: AIOKafkaConsumer.subscribe(), subscribing to: ['test_topic']\n",
      "[INFO] __main__: AIOKafkaConsumer patched stop() called\n",
      "[INFO] __main__: AIOKafkaProducer patched stop() called\n",
      "<class '__main__.LocalKafkaBroker'>.__exit__\n",
      "[INFO] __main__: Local kafka broker stopping\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "sent_msgs_before = [f\"msg{i}\".encode(\"UTF-8\") for i in range(32)]\n",
    "sent_msgs_after = [f\"msg{i}\".encode(\"UTF-8\") for i in range(32, 64)]\n",
    "\n",
    "with LocalKafkaBroker([topic]) as broker:\n",
    "    async with create_consumer_and_producer() as (consumer, producer):\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs_before]\n",
    "\n",
    "        consumer.subscribe([topic])\n",
    "        [await producer.send(topic, msg) for msg in sent_msgs_after]\n",
    "        received = await consumer.getmany()\n",
    "        received_msgs = [msg.value for _, msgs in received.items() for msg in msgs]\n",
    "\n",
    "    assert checkEqual(sent_msgs_after, received_msgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
