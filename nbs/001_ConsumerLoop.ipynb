{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_consumer_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from datetime import datetime, timedelta\n",
    "from os import environ\n",
    "from typing import *\n",
    "\n",
    "import anyio\n",
    "from anyio.streams.memory import MemoryObjectReceiveStream\n",
    "import asyncer\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from aiokafka.structs import ConsumerRecord, TopicPartition\n",
    "from pydantic import BaseModel, Field, HttpUrl, NonNegativeInt\n",
    "\n",
    "from fast_kafka_api._components.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import AsyncMock, MagicMock, Mock, call\n",
    "\n",
    "from fast_kafka_api._components.logger import supress_timestamps\n",
    "from fast_kafka_api.testing import (\n",
    "    create_and_fill_testing_topic,\n",
    "    nb_safe_seed,\n",
    "    true_after,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = nb_safe_seed(\"_components.aiokafka_consumer_loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53542175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a41c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessage(BaseModel):\n",
    "    url: HttpUrl = Field(..., example=\"http://www.acme.com\", description=\"Url example\")\n",
    "    port: NonNegativeInt = Field(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178af400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_msgs(  # type: ignore\n",
    "    *,\n",
    "    msgs: Dict[TopicPartition, List[ConsumerRecord]],\n",
    "    callbacks: Dict[str, Callable[[BaseModel], Union[None, Awaitable[None]]]],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    process_f: Callable[\n",
    "        [Tuple[Callable[[BaseModel], Awaitable[None]], BaseModel]], Awaitable[None]\n",
    "    ],\n",
    ") -> None:\n",
    "    \"\"\"For each messages **msg** in **msgs**, calls process_f with callbacks[topic] and **msgs**.\n",
    "\n",
    "    Params:\n",
    "        msgs: a dictionary mapping topic partition to a list of messages, returned by `AIOKafkaConsumer.getmany`.\n",
    "        callbacks: a dictionary mapping topics into a callback functions.\n",
    "        msg_types: a dictionary mapping topics into a message type of a message.\n",
    "        process_f: a stream processing function registrated by `anyio.create_memory_object_stream`\n",
    "\n",
    "    Todo:\n",
    "        remove it :)\n",
    "    \"\"\"\n",
    "    for topic_partition, topic_msgs in msgs.items():\n",
    "        topic = topic_partition.topic\n",
    "        msg_type = msg_types[topic]\n",
    "        try:\n",
    "            decoded_msgs = [\n",
    "                msg_type.parse_raw(msg.value.decode(\"utf-8\")) for msg in topic_msgs\n",
    "            ]\n",
    "            for msg in decoded_msgs:\n",
    "                callback_raw = callbacks[topic]\n",
    "                if not iscoroutinefunction(callback_raw):\n",
    "                    c: Callable[[BaseModel], None] = callback_raw  # type: ignore\n",
    "                    callback: Callable[[BaseModel], Awaitable[None]] = asyncer.asyncify(\n",
    "                        c\n",
    "                    )\n",
    "                else:\n",
    "                    callback = callback_raw\n",
    "\n",
    "                async def safe_callback(\n",
    "                    msg: BaseModel,\n",
    "                    callback: Callable[[BaseModel], Awaitable[None]] = callback,\n",
    "                ) -> None:\n",
    "                    try:\n",
    "                        #                         logger.debug(f\"process_msgs(): awaiting '{callback}({msg})'\")\n",
    "                        await callback(msg)\n",
    "                    except Exception as e:\n",
    "                        logger.warning(\n",
    "                            f\"process_msgs(): exception caugth {e.__repr__()} while awaiting '{callback}({msg})'\"\n",
    "                        )\n",
    "\n",
    "                await process_f((safe_callback, msg))\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"process_msgs(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic_partition.topic}', partition='{topic_partition.partition}' and messages: {topic_msgs}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumer_record(topic: str, partition: int, msg: BaseModel):\n",
    "    record = ConsumerRecord(\n",
    "        topic=topic,\n",
    "        partition=partition,\n",
    "        offset=0,\n",
    "        timestamp=0,\n",
    "        timestamp_type=0,\n",
    "        key=None,\n",
    "        value=msg.json().encode(\"utf-8\"),\n",
    "        checksum=0,\n",
    "        serialized_key_size=0,\n",
    "        serialized_value_size=0,\n",
    "        headers=[],\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_async=False\n",
      "is_async=True\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# One msg, one topic, process_f called once with callback and decoded_msg\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "topic_part_0_0 = TopicPartition(topic, partition)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "\n",
    "async def process_f(arg):\n",
    "    callback, msg = arg\n",
    "    await callback(msg)\n",
    "\n",
    "\n",
    "for is_async in [False, True]:\n",
    "    print(f\"is_async={is_async}\")\n",
    "    callback_0 = Mock()\n",
    "    await process_msgs(\n",
    "        msgs={topic_part_0_0: [record]},\n",
    "        callbacks={topic: (asyncer.asyncify(callback_0) if is_async else callback_0)},\n",
    "        msg_types={topic: MyMessage},\n",
    "        process_f=process_f,\n",
    "    )\n",
    "\n",
    "    #     process_f.assert_called_with((callback_0, msg))\n",
    "    callback_0.assert_called_with(msg)\n",
    "    assert callback_0.call_count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b3808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_async=False\n",
      "[WARNING] __main__: process_msgs(): exception caugth Exception('Test') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n",
      "is_async=True\n",
      "[WARNING] __main__: process_msgs(): exception caugth Exception('Test') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: exception in callback\n",
    "# One msg, one topic, process_f called once with callback and decoded_msg\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "topic_part_0_0 = TopicPartition(topic, partition)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "\n",
    "async def process_f(arg):\n",
    "    callback, msg = arg\n",
    "    await callback(msg)\n",
    "\n",
    "\n",
    "for is_async in [False, True]:\n",
    "    print(f\"is_async={is_async}\")\n",
    "    callback_0 = Mock()\n",
    "    callback_0.side_effect = Mock(side_effect=Exception(\"Test\"))\n",
    "    await process_msgs(\n",
    "        msgs={topic_part_0_0: [record]},\n",
    "        callbacks={topic: (asyncer.asyncify(callback_0) if is_async else callback_0)},\n",
    "        msg_types={topic: MyMessage},\n",
    "        process_f=process_f,\n",
    "    )\n",
    "\n",
    "    #     process_f.assert_called_with((callback_0, msg))\n",
    "    callback_0.assert_called_with(msg)\n",
    "    assert callback_0.call_count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10589655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, process_f called twice with each callback called once\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "topic_part_1_0 = TopicPartition(\"topic_1\", 0)\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "callback_0 = Mock()\n",
    "callback_1 = AsyncMock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [record], topic_part_1_0: [record]},\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=process_f,\n",
    ")\n",
    "\n",
    "callback_0.assert_called_once_with(msg)\n",
    "callback_1.assert_awaited_once_with(msg)\n",
    "callback_0.assert_called_once_with(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple msgs in same topic\n",
    "# Check callback not called if there are no msgs for it in the queue\n",
    "\n",
    "# Two msg, one topic, one callback called twice, other called nonce, produce and process_f called twice\n",
    "\n",
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, process_f called twice with each callback called once and produce twice\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "callback_0 = Mock()\n",
    "callback_1 = AsyncMock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={topic_part_0_0: [record, record]},\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=process_f,\n",
    ")\n",
    "\n",
    "callback_0.assert_has_calls([call(msg)] * 2)\n",
    "callback_1.assert_not_awaited()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple partitions\n",
    "\n",
    "# Two msg, one topic, two partitions, one callback called twice, produce and process_f called twice\n",
    "\n",
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "topic_part_0_1 = TopicPartition(\"topic_0\", 1)\n",
    "\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "callback_0 = AsyncMock()\n",
    "callback_1 = Mock()\n",
    "\n",
    "await process_msgs(\n",
    "    msgs={\n",
    "        topic_part_0_0: [create_consumer_record(topic=\"topic_0\", partition=0, msg=msg)],\n",
    "        topic_part_0_1: [create_consumer_record(topic=\"topic_0\", partition=1, msg=msg)],\n",
    "    },\n",
    "    callbacks={\"topic_0\": callback_0, \"topic_1\": callback_1},\n",
    "    msg_types={\"topic_0\": MyMessage, \"topic_1\": MyMessage},\n",
    "    process_f=process_f,\n",
    ")\n",
    "\n",
    "callback_0.assert_has_awaits([call(msg)] * 2)\n",
    "callback_1.assert_not_called()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_message_callback(\n",
    "    receive_stream: MemoryObjectReceiveStream[Any],\n",
    ") -> None:\n",
    "    async with receive_stream:\n",
    "        async for callback, msg in receive_stream:\n",
    "            await callback(msg)\n",
    "\n",
    "\n",
    "async def _aiokafka_consumer_loop(  # type: ignore\n",
    "    consumer: AIOKafkaConsumer,\n",
    "    *,\n",
    "    callbacks: Dict[str, Callable[[BaseModel], Union[None, Awaitable[None]]]],\n",
    "    timeout_ms: int = 100,\n",
    "    max_buffer_size: int = 10_000,\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    ") -> None:\n",
    "    \"\"\"Write docs\n",
    "\n",
    "    Todo: add batch size if needed\n",
    "    \"\"\"\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "        max_buffer_size=max_buffer_size\n",
    "    )\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(process_message_callback, receive_stream)\n",
    "        async with send_stream:\n",
    "            while not is_shutting_down_f():\n",
    "                msgs = await consumer.getmany(timeout_ms=timeout_ms)\n",
    "                try:\n",
    "                    await process_msgs(\n",
    "                        msgs=msgs,\n",
    "                        callbacks=callbacks,\n",
    "                        msg_types=msg_types,\n",
    "                        process_f=send_stream.send,\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    logger.warning(\n",
    "                        f\"_aiokafka_consumer_loop(): Unexpected exception '{e}' caught and ignored for messages: {msgs}\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77397e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"topic_0\"\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [record]}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "\n",
    "def is_shutting_down_f(mock_func):\n",
    "    def _is_shutting_down_f():\n",
    "        return mock_func.called\n",
    "\n",
    "    return _is_shutting_down_f\n",
    "\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        max_buffer_size=100,\n",
    "        callbacks={\n",
    "            topic: asyncer.asyncify(mock_callback) if is_async else mock_callback\n",
    "        },\n",
    "        msg_types={topic: MyMessage},\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),\n",
    "    )\n",
    "\n",
    "    assert mock_consumer.getmany.call_count == 1\n",
    "    mock_callback.assert_called_once_with(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def aiokafka_consumer_loop(  # type: ignore\n",
    "    topics: List[str],\n",
    "    *,\n",
    "    bootstrap_servers: str,\n",
    "    auto_offset_reset: str,\n",
    "    max_poll_records: int = 1_000,\n",
    "    timeout_ms: int = 100,\n",
    "    max_buffer_size: int = 10_000,\n",
    "    callbacks: Dict[str, Callable[[BaseModel], Union[None, Awaitable[None]]]],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs,\n",
    ") -> None:\n",
    "    \"\"\"todo: write docs\"\"\"\n",
    "    logger.info(f\"aiokafka_consumer_loop() starting..\")\n",
    "    consumer = AIOKafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        auto_offset_reset=auto_offset_reset,\n",
    "        max_poll_records=max_poll_records,\n",
    "    )\n",
    "    logger.info(\"aiokafka_consumer_loop(): Consumer created.\")\n",
    "\n",
    "    await consumer.start()\n",
    "    logger.info(\"aiokafka_consumer_loop(): Consumer started.\")\n",
    "    consumer.subscribe(topics)\n",
    "    logger.info(\"aiokafka_consumer_loop(): Consumer subscribed.\")\n",
    "\n",
    "    try:\n",
    "        await _aiokafka_consumer_loop(\n",
    "            consumer=consumer,\n",
    "            max_buffer_size=max_buffer_size,\n",
    "            timeout_ms=timeout_ms,\n",
    "            callbacks=callbacks,\n",
    "            msg_types=msg_types,\n",
    "            is_shutting_down_f=is_shutting_down_f,\n",
    "        )\n",
    "    finally:\n",
    "        await consumer.stop()\n",
    "        logger.info(f\"aiokafka_consumer_loop(): Consumer stopped.\")\n",
    "        logger.info(f\"aiokafka_consumer_loop() finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_5696213874']): new_topics = [NewTopic(topic=my_topic_5696213874,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=9178\n",
      "[INFO] __main__: aiokafka_consumer_loop() starting..\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created.\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_5696213874'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_5696213874'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_5696213874': 3}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "async with create_and_fill_testing_topic(\n",
    "    kafka_config=kafka_config, msgs=msgs, seed=seed(1)\n",
    ") as topic:\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics=[topic],\n",
    "        bootstrap_servers=kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callbacks={topic: count_msg},\n",
    "        msg_types={topic: MyMessage},\n",
    "        is_shutting_down_f=true_after(2),\n",
    "    )\n",
    "\n",
    "assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_5168585847']): new_topics = [NewTopic(topic=my_topic_5168585847,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=100000\n",
      "[INFO] __main__: aiokafka_consumer_loop() starting..\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created.\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_5168585847'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_5168585847'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_5168585847': 3}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: msgs_received=10000\n",
      "[INFO] __main__: msgs_received=11000\n",
      "[INFO] __main__: msgs_received=12000\n",
      "[INFO] __main__: msgs_received=13000\n",
      "[INFO] __main__: msgs_received=14000\n",
      "[INFO] __main__: msgs_received=15000\n",
      "[INFO] __main__: msgs_received=16000\n",
      "[INFO] __main__: msgs_received=17000\n",
      "[INFO] __main__: msgs_received=18000\n",
      "[INFO] __main__: msgs_received=19000\n",
      "[INFO] __main__: msgs_received=20000\n",
      "[INFO] __main__: msgs_received=21000\n",
      "[INFO] __main__: msgs_received=22000\n",
      "[INFO] __main__: msgs_received=23000\n",
      "[INFO] __main__: msgs_received=24000\n",
      "[INFO] __main__: msgs_received=25000\n",
      "[INFO] __main__: msgs_received=26000\n",
      "[INFO] __main__: msgs_received=27000\n",
      "[INFO] __main__: msgs_received=28000\n",
      "[INFO] __main__: msgs_received=29000\n",
      "[INFO] __main__: msgs_received=30000\n",
      "[INFO] __main__: msgs_received=31000\n",
      "[INFO] __main__: msgs_received=32000\n",
      "[INFO] __main__: msgs_received=33000\n",
      "[INFO] __main__: msgs_received=34000\n",
      "[INFO] __main__: msgs_received=35000\n",
      "[INFO] __main__: msgs_received=36000\n",
      "[INFO] __main__: msgs_received=37000\n",
      "[INFO] __main__: msgs_received=38000\n",
      "[INFO] __main__: msgs_received=39000\n",
      "[INFO] __main__: msgs_received=40000\n",
      "[INFO] __main__: msgs_received=41000\n",
      "[INFO] __main__: msgs_received=42000\n",
      "[INFO] __main__: msgs_received=43000\n",
      "[INFO] __main__: msgs_received=44000\n",
      "[INFO] __main__: msgs_received=45000\n",
      "[INFO] __main__: msgs_received=46000\n",
      "[INFO] __main__: msgs_received=47000\n",
      "[INFO] __main__: msgs_received=48000\n",
      "[INFO] __main__: msgs_received=49000\n",
      "[INFO] __main__: msgs_received=50000\n",
      "[INFO] __main__: msgs_received=51000\n",
      "[INFO] __main__: msgs_received=52000\n",
      "[INFO] __main__: msgs_received=53000\n",
      "[INFO] __main__: msgs_received=54000\n",
      "[INFO] __main__: msgs_received=55000\n",
      "[INFO] __main__: msgs_received=56000\n",
      "[INFO] __main__: msgs_received=57000\n",
      "[INFO] __main__: msgs_received=58000\n",
      "[INFO] __main__: msgs_received=59000\n",
      "[INFO] __main__: msgs_received=60000\n",
      "[INFO] __main__: msgs_received=61000\n",
      "[INFO] __main__: msgs_received=62000\n",
      "[INFO] __main__: msgs_received=63000\n",
      "[INFO] __main__: msgs_received=64000\n",
      "[INFO] __main__: msgs_received=65000\n",
      "[INFO] __main__: msgs_received=66000\n",
      "[INFO] __main__: msgs_received=67000\n",
      "[INFO] __main__: msgs_received=68000\n",
      "[INFO] __main__: msgs_received=69000\n",
      "[INFO] __main__: msgs_received=70000\n",
      "[INFO] __main__: msgs_received=71000\n",
      "[INFO] __main__: msgs_received=72000\n",
      "[INFO] __main__: msgs_received=73000\n",
      "[INFO] __main__: msgs_received=74000\n",
      "[INFO] __main__: msgs_received=75000\n",
      "[INFO] __main__: msgs_received=76000\n",
      "[INFO] __main__: msgs_received=77000\n",
      "[INFO] __main__: msgs_received=78000\n",
      "[INFO] __main__: msgs_received=79000\n",
      "[INFO] __main__: msgs_received=80000\n",
      "[INFO] __main__: msgs_received=81000\n",
      "[INFO] __main__: msgs_received=82000\n",
      "[INFO] __main__: msgs_received=83000\n",
      "[INFO] __main__: msgs_received=84000\n",
      "[INFO] __main__: msgs_received=85000\n",
      "[INFO] __main__: msgs_received=86000\n",
      "[INFO] __main__: msgs_received=87000\n",
      "[INFO] __main__: msgs_received=88000\n",
      "[INFO] __main__: msgs_received=89000\n",
      "[INFO] __main__: msgs_received=90000\n",
      "[INFO] __main__: msgs_received=91000\n",
      "[INFO] __main__: msgs_received=92000\n",
      "[INFO] __main__: msgs_received=93000\n",
      "[INFO] __main__: msgs_received=94000\n",
      "[INFO] __main__: msgs_received=95000\n",
      "[INFO] __main__: msgs_received=96000\n",
      "[INFO] __main__: msgs_received=97000\n",
      "[INFO] __main__: msgs_received=98000\n",
      "[INFO] __main__: msgs_received=99000\n",
      "[INFO] __main__: msgs_received=100000\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "Messages processed: 100,000\n",
      "Time              : 3.85 s\n",
      "Throughput.       : 26,003 msg/s\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "msgs_sent = 100_000\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "def _is_shutting_down_f():\n",
    "    return msgs_received == msgs_sent\n",
    "\n",
    "\n",
    "async with create_and_fill_testing_topic(\n",
    "    kafka_config=kafka_config, msgs=msgs, seed=seed(3)\n",
    ") as topic:\n",
    "    start = datetime.now()\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics=[topic],\n",
    "        bootstrap_servers=kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callbacks={topic: count_msg},\n",
    "        msg_types={topic: MyMessage},\n",
    "        is_shutting_down_f=_is_shutting_down_f,\n",
    "    )\n",
    "    t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "    thrp = msgs_received / t\n",
    "\n",
    "    print(f\"Messages processed: {msgs_received:,d}\")\n",
    "    print(f\"Time              : {t:.2f} s\")\n",
    "    print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d74c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
