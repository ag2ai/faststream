{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff734a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *\n",
    "from typing import get_type_hints\n",
    "\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "from os import environ\n",
    "from datetime import datetime, timedelta\n",
    "import tempfile\n",
    "from contextlib import contextmanager, asynccontextmanager\n",
    "import time\n",
    "from inspect import signature\n",
    "\n",
    "from fastcore.foundation import patch\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "import anyio\n",
    "import asyncio\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "import httpx\n",
    "from fastapi import FastAPI\n",
    "from fastapi import status, Depends, HTTPException, Request, Response\n",
    "from fastapi.openapi.docs import get_swagger_ui_html, get_redoc_html\n",
    "from fastapi.openapi.utils import get_openapi\n",
    "from fastapi.responses import FileResponse, RedirectResponse\n",
    "from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field, HttpUrl, EmailStr, PositiveInt\n",
    "from pydantic.schema import schema\n",
    "from pydantic.json import timedelta_isoformat\n",
    "from aiokafka import AIOKafkaProducer\n",
    "\n",
    "import confluent_kafka\n",
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "from confluent_kafka import Message, KafkaError\n",
    "import asyncer\n",
    "\n",
    "import fast_kafka_api.logger\n",
    "fast_kafka_api.logger.should_supress_timestamps = True\n",
    "\n",
    "import fast_kafka_api\n",
    "from fast_kafka_api._components.aiokafka_loop import aiokafka_consumer_loop\n",
    "from fast_kafka_api.confluent_kafka import AIOProducer\n",
    "from fast_kafka_api.confluent_kafka import create_missing_topics\n",
    "from fast_kafka_api.asyncapi import (\n",
    "    KafkaMessage,\n",
    "    export_async_spec,\n",
    "    _get_msg_cls_for_method,\n",
    ")\n",
    "from fast_kafka_api.asyncapi import (\n",
    "    KafkaBroker,\n",
    "    ContactInfo,\n",
    "    KafkaServiceInfo,\n",
    "    KafkaBrokers,\n",
    ")\n",
    "from fast_kafka_api.logger import get_logger\n",
    "from fast_kafka_api.testing import true_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33a28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf16b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "logger = get_logger(__name__, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cb95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.debug(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import yaml\n",
    "import unittest.mock\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "import uvicorn\n",
    "from fastapi.testclient import TestClient\n",
    "from starlette.datastructures import Headers\n",
    "\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from fast_kafka_api.confluent_kafka import create_testing_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9177ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# allows async calls in notebooks\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class KafkaErrorMsg(KafkaMessage):\n",
    "    topic: str = Field(..., description=\"topic where exception occurred\")\n",
    "    raw_msg: Optional[bytes] = Field(None, description=\"raw message string\")\n",
    "    error: str = Field(..., description=\"exception triggered by the message\")\n",
    "        \n",
    "ProduceCallable = Callable[[str, KafkaMessage], None]\n",
    "TopicCallable = Callable[[KafkaMessage, ProduceCallable], None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27465483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_topic_name(\n",
    "    on_topic: TopicCallable, prefix: str = \"on_\"\n",
    ") -> str:\n",
    "    topic = on_topic.__name__\n",
    "    if not topic.startswith(prefix) or len(topic) <= len(prefix):\n",
    "        raise ValueError(f\"Function name '{topic}' must start with {prefix}\")\n",
    "    topic = topic[len(prefix) :]\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_topic_name_1():\n",
    "    pass\n",
    "\n",
    "\n",
    "assert _get_topic_name(on_topic_name_1) == \"topic_name_1\"\n",
    "\n",
    "assert _get_topic_name(on_topic_name_1, prefix=\"on_topic_\") == \"name_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c37353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FastKafkaAPI(FastAPI):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        title: str = \"FastKafkaAPI\",\n",
    "        contact: Optional[Dict[str, Union[str, Any]]] = None,\n",
    "        kafka_brokers: Optional[Dict[str, Any]] = None,\n",
    "        kafka_config: Dict[str, Any],\n",
    "        root_path: Optional[Union[Path, str]] = None,\n",
    "        num_partitions: Optional[int] = None,\n",
    "        replication_factor: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self._kafka_config = kafka_config\n",
    "        self.num_partitions = num_partitions\n",
    "        self.replication_factor = replication_factor\n",
    "\n",
    "        if root_path is None:\n",
    "            root_path = Path(\".\")\n",
    "        self._root_path = Path(root_path)\n",
    "\n",
    "        if kafka_brokers is None:\n",
    "            kafka_brokers = {\n",
    "                \"localhost\": KafkaBroker(\n",
    "                    url=\"https://localhost\",\n",
    "                    description=\"Local (dev) Kafka broker\",\n",
    "                    port=\"9092\",\n",
    "                )\n",
    "            }\n",
    "        if contact is None:\n",
    "            contact = dict(\n",
    "                name=\"author\", url=\"https://www.google.com\", email=\"noreply@gmail.com\"\n",
    "            )\n",
    "\n",
    "        super().__init__(title=title, contact=contact, **kwargs)\n",
    "\n",
    "        self._store: Dict[str, Dict[str, Tuple[Union[TopicCallable, AIOKafkaProducer], Dict[str, Any]]],] = {\n",
    "            \"consumers\": {},\n",
    "            \"producers\": {},\n",
    "        }\n",
    "        self._on_error_topic: Optional[str] = None\n",
    "\n",
    "        contact_info = ContactInfo(**contact)  # type: ignore\n",
    "        self._kafka_service_info = KafkaServiceInfo(\n",
    "            title=self.title,\n",
    "            version=self.version,\n",
    "            description=self.description,\n",
    "            contact=contact_info,\n",
    "        )\n",
    "        self._kafka_brokers = KafkaBrokers(brokers=kafka_brokers)\n",
    "\n",
    "        self._confluent_producer: Optional[AIOProducer] = None\n",
    "\n",
    "        self._asyncapi_path = self._root_path / \"asyncapi\"\n",
    "        (self._asyncapi_path / \"docs\").mkdir(exist_ok=True, parents=True)\n",
    "        (self._asyncapi_path / \"spec\").mkdir(exist_ok=True, parents=True)\n",
    "        self.mount(\n",
    "            \"/asyncapi\",\n",
    "            StaticFiles(directory=self._asyncapi_path / \"docs\"),\n",
    "            name=\"asyncapi\",\n",
    "        )\n",
    "\n",
    "        self._is_shutting_down: bool = False\n",
    "        self._kafka_consumer_tasks: List[asyncio.Task[Any]] = []\n",
    "        self._kafka_producer_tasks: List[asyncio.Task[Any]] = []\n",
    "\n",
    "        @self.get(\"/\", include_in_schema=False)\n",
    "        def redirect_root_to_asyncapi():\n",
    "            return RedirectResponse(\"/asyncapi\")\n",
    "\n",
    "        @self.get(\"/asyncapi\", include_in_schema=False)\n",
    "        async def redirect_asyncapi_docs():\n",
    "            return RedirectResponse(\"/asyncapi/index.html\")\n",
    "\n",
    "        @self.get(\"/asyncapi.yml\", include_in_schema=False)\n",
    "        async def download_asyncapi_yml():\n",
    "            return FileResponse(self._asyncapi_path / \"spec\" / \"asyncapi.yml\")\n",
    "\n",
    "        @self.on_event(\"startup\")\n",
    "        async def __on_startup(app=self):\n",
    "            app._on_startup()\n",
    "\n",
    "        @self.on_event(\"shutdown\")\n",
    "        async def __on_shutdown(app=self):\n",
    "            await app._on_shutdown()\n",
    "\n",
    "    async def _on_startup(self) -> None:\n",
    "        raise NotImplemented\n",
    "\n",
    "    async def _on_shutdown(self) -> None:\n",
    "        raise NotImplemented\n",
    "\n",
    "    def _add_topic(\n",
    "        self,\n",
    "        *,\n",
    "        store_key: str,\n",
    "        topic: str,\n",
    "        f: Callable[[KafkaMessage], Any],\n",
    "        on_error: bool,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Stores function `f` under key `topic` in `store`\n",
    "\n",
    "        Params:\n",
    "            store_key: either `consumers` or `producers`\n",
    "            topic: the name of the topic\n",
    "            f: callback function called on receiving a message for consumers or on delivery report for producers\n",
    "            on_error: True for at most one producer topic used for outputting errors\n",
    "\n",
    "        Raises:\n",
    "            ValueError:\n",
    "                - if store_key not one of either `consumers` or `producers`,\n",
    "                - if key `topic` is already in `self._store[store_key]`, or\n",
    "                - if `on_error` is already set\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _register_kafka_callback(\n",
    "        self,\n",
    "        *,\n",
    "        store_key: str,\n",
    "        topic: Optional[str] = None,\n",
    "        prefix: str = \"on_\",\n",
    "        on_error: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> TopicCallable:\n",
    "        \"\"\" \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def consumes(\n",
    "        self,\n",
    "        topic: Optional[str] = None,\n",
    "        prefix: str = \"on_\",\n",
    "        **kwargs,\n",
    "    ) -> TopicCallable:\n",
    "        \"\"\"Decorator registering the callback called when a message is received in a topic.\n",
    "\n",
    "        This function decorator is also responsible for registering topics for AsyncAPI specificiation and documentation.\n",
    "\n",
    "        Params:\n",
    "            topic: todo\n",
    "\n",
    "        Returns:\n",
    "            A function returning the same function\n",
    "\n",
    "        \"\"\"\n",
    "        return self._register_kafka_callback(\n",
    "            store_key=\"consumers\", topic=topic, prefix=prefix, on_error=False, **kwargs\n",
    "        )\n",
    "\n",
    "    def produces(\n",
    "        self,\n",
    "        topic: Optional[str] = None,\n",
    "        prefix: str = \"on_\",\n",
    "        on_error: bool = False,\n",
    "        **kwargs,\n",
    "    ) -> Callable[[KafkaMessage], None]:\n",
    "        \"\"\"Decorator registering the callback called when delivery report for a produced message is received\n",
    "\n",
    "        This function decorator is also responsible for registering topics for AsyncAPI specificiation and documentation.\n",
    "\n",
    "        Params:\n",
    "            topic: TODO\n",
    "\n",
    "        Returns:\n",
    "            A function returning the same function\n",
    "\n",
    "        \"\"\"\n",
    "        return self._register_kafka_callback(\n",
    "            store_key=\"producers\",\n",
    "            topic=topic,\n",
    "            prefix=prefix,\n",
    "            on_error=on_error,\n",
    "            produces=True,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def produces_on_error(\n",
    "        self,\n",
    "        topic: Optional[str] = None,\n",
    "        prefix: str = \"on_\",\n",
    "        **kwargs,\n",
    "    ) -> Callable[[KafkaMessage], None]:\n",
    "        return self._register_kafka_callback(\n",
    "            store_key=\"producers\", topic=topic, prefix=prefix, on_error=True, **kwargs\n",
    "        )\n",
    "\n",
    "    def produce(\n",
    "        self,\n",
    "        topic: str,\n",
    "        msg: KafkaMessage,\n",
    "        on_delivery: Optional[Callable[[KafkaMessage, Message], None]] = None,\n",
    "    ):\n",
    "        return self.produce_raw(\n",
    "            topic=topic, raw_msg=msg.json().encode(\"utf-8\"), on_delivery=on_delivery\n",
    "        )\n",
    "\n",
    "    def produce_raw(\n",
    "        self,\n",
    "        topic: str,\n",
    "        raw_msg: Union[str, bytes],\n",
    "        on_delivery: Optional[Callable[[KafkaMessage, Message], None]] = None,\n",
    "    ) -> \"asyncio.Future[Any]\":\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "    \"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    \"group.id\": f\"{kafka_server_url}:{kafka_server_port}_group\",  # ToDo: Figure out msg deletion from kafka after consuming once\n",
    "    \"auto.offset.reset\": \"earliest\",\n",
    "}\n",
    "\n",
    "\n",
    "def create_testing_app():\n",
    "    app = FastKafkaAPI(\n",
    "        kafka_brokers={\n",
    "            \"local\": {\n",
    "                \"url\": \"kafka\",\n",
    "                \"name\": \"development\",\n",
    "                \"description\": \"Local (dev) Kafka broker\",\n",
    "                \"port\": 9092,\n",
    "            }\n",
    "        },\n",
    "        kafka_config=kafka_config,\n",
    "        root_path=\"/tmp/000_FastKafkaAPI\",\n",
    "    )\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66237424",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_testing_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13ba2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def _add_topic(\n",
    "    self: FastKafkaAPI,\n",
    "    *,\n",
    "    store_key: str,\n",
    "    topic: str,\n",
    "    f: Callable[[KafkaMessage], Any],\n",
    "    on_error: bool = False,\n",
    "    **kwargs\n",
    "):\n",
    "    if store_key not in [\"consumers\", \"producers\"]:\n",
    "        raise ValueError(\n",
    "            f\"store_key must be one of 'consumers', 'producers', it is '{store_key}' instead\"\n",
    "        )\n",
    "    if on_error:\n",
    "        if store_key == \"consumers\":\n",
    "            raise ValueError(\n",
    "                \"`on_error` can be true only when `store_key` is `producers`\"\n",
    "            )\n",
    "        if self._on_error_topic is not None:\n",
    "            raise ValueError(\n",
    "                f\"`on_error` must be unique, it is already set to '{self._on_error_topic}'\"\n",
    "            )\n",
    "        self._on_error_topic = topic\n",
    "\n",
    "    if topic in self._store[\"consumers\"].keys():\n",
    "        raise ValueError(f\"Topic '{topic}' is already in consumers.\")\n",
    "    if topic in self._store[\"producers\"].keys():\n",
    "        raise ValueError(f\"Topic '{topic}' is already in producers.\")\n",
    "    self._store[store_key][topic] = (f, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd267ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_testing_app()\n",
    "\n",
    "\n",
    "def f(KafkaMessage):\n",
    "    pass\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    app._add_topic(store_key=\"random_thing\", topic=\"topic_name_1\", f=f, on_error=False)\n",
    "assert (\n",
    "    str(e.value)\n",
    "    == \"store_key must be one of 'consumers', 'producers', it is 'random_thing' instead\"\n",
    "), str(e.value)\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    app._add_topic(store_key=\"consumers\", topic=\"topic_name_1\", f=f, on_error=True)\n",
    "assert (\n",
    "    str(e.value) == \"`on_error` can be true only when `store_key` is `producers`\"\n",
    "), str(e.value)\n",
    "\n",
    "app._add_topic(store_key=\"producers\", topic=\"topic_name_1\", f=f, on_error=True)\n",
    "assert app._store[\"producers\"][\"topic_name_1\"] == (f, {})\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    app._add_topic(store_key=\"producers\", topic=\"topic_name_2\", f=f, on_error=True)\n",
    "assert (\n",
    "    str(e.value) == \"`on_error` must be unique, it is already set to 'topic_name_1'\"\n",
    "), str(e.value)\n",
    "\n",
    "app._add_topic(store_key=\"producers\", topic=\"topic_name_2\", f=f, on_error=False, servers=\"servers\")\n",
    "assert app._store[\"producers\"][\"topic_name_2\"] == (f, dict(servers=\"servers\"))\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    app._add_topic(store_key=\"producers\", topic=\"topic_name_2\", f=f, on_error=False)\n",
    "assert str(e.value) == \"Topic 'topic_name_2' is already in producers.\", str(e.value)\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    app._add_topic(store_key=\"consumers\", topic=\"topic_name_2\", f=f, on_error=False)\n",
    "assert str(e.value) == \"Topic 'topic_name_2' is already in producers.\", str(e.value)\n",
    "\n",
    "app._add_topic(store_key=\"consumers\", topic=\"topic_name_3\", f=f, on_error=False, my_param=42)\n",
    "assert app._store[\"consumers\"][\"topic_name_3\"] == (f, {\"my_param\": 42})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f823c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _get_first_func_arg_type(f: Callable[[Any], Any]) -> Type[Any]:\n",
    "    return list(get_type_hints(f).values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_f(x: str):\n",
    "    pass\n",
    "\n",
    "\n",
    "actual = _get_first_func_arg_type(some_f)\n",
    "assert actual == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(self, topic, func):\n",
    "    async def _produce(*args, **kwargs):\n",
    "        return_val = func(*args, **kwargs)\n",
    "        logger.debug(f\"Producing msg {return_val}\")\n",
    "        logger.debug(f\"{self._store}\")\n",
    "        producer, _ = self._store[\"producers\"][topic]\n",
    "        fut = await producer.send(topic, return_val.json().encode(\"utf-8\"))\n",
    "        msg = await fut\n",
    "        return return_val\n",
    "    return _produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be925f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "@patch\n",
    "def _register_kafka_callback(\n",
    "    self: FastKafkaAPI,\n",
    "    *,\n",
    "    store_key: str,\n",
    "    topic: Optional[str] = None,\n",
    "    prefix: str = \"on_\",\n",
    "    on_error: bool = False,\n",
    "    produces: bool = False,\n",
    "    **kwargs,\n",
    ") -> Callable[[KafkaMessage, Callable[[str, KafkaMessage], None]], None]:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def _decorator(\n",
    "        on_topic: Callable[[KafkaMessage, Callable[[str, KafkaMessage], None]], None],\n",
    "        store_key: str = store_key,\n",
    "        topic: str = topic,\n",
    "        on_error: bool = on_error,\n",
    "        kwargs=kwargs\n",
    "    ) -> Callable[[KafkaMessage, Callable[[str, KafkaMessage], None]], None]:\n",
    "        if topic is None:\n",
    "            topic = _get_topic_name(on_topic=on_topic, prefix=prefix)\n",
    "\n",
    "        first_arg_type = _get_first_func_arg_type(on_topic)\n",
    "        if on_error and first_arg_type != KafkaErrorMsg:\n",
    "            raise ValueError(\n",
    "                f\"The first argument of a decorator handling errors must be KafkaErrorMsg, it is '{first_arg_type}' instead\"\n",
    "            )\n",
    "        self._add_topic(\n",
    "            store_key=store_key, topic=topic, f=on_topic, on_error=on_error, **kwargs\n",
    "        )\n",
    "        \n",
    "        \n",
    "        return produce(self, topic, on_topic) if produces else on_topic\n",
    "\n",
    "    return _decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de929ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_testing_app()\n",
    "\n",
    "\n",
    "@app._register_kafka_callback(store_key=\"consumers\", server=\"server\")\n",
    "def on_topic_1(msg: KafkaMessage):\n",
    "    pass\n",
    "assert app._store[\"consumers\"][\"topic_1\"] == (on_topic_1, {\"server\": \"server\"}), app._store\n",
    "\n",
    "@app._register_kafka_callback(store_key=\"consumers\", topic=\"topic_2\")\n",
    "def some_callback(msg: KafkaMessage):\n",
    "    pass\n",
    "\n",
    "assert app._store[\"consumers\"][\"topic_2\"] == (some_callback, {}), app._store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e107bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInfo(KafkaMessage):\n",
    "    mobile: str = Field(..., example=\"+385987654321\")\n",
    "    name: str = Field(..., example=\"James Bond\")\n",
    "\n",
    "\n",
    "class MyMsgUrl(KafkaMessage):\n",
    "    info: MyInfo = Field(..., example=dict(mobile=\"+385987654321\", name=\"James Bond\"))\n",
    "    url: HttpUrl = Field(..., example=\"https://sis.gov.uk/agents/007\")\n",
    "\n",
    "\n",
    "class MyMsgEmail(KafkaMessage):\n",
    "    msg_url: MyMsgUrl = Field(\n",
    "        ...,\n",
    "        example=dict(\n",
    "            info=dict(mobile=\"+385987654321\", name=\"James Bond\"),\n",
    "            url=\"https://sis.gov.uk/agents/007\",\n",
    "        ),\n",
    "    )\n",
    "    email: EmailStr = Field(..., example=\"agent-007@sis.gov.uk\")\n",
    "\n",
    "\n",
    "def setup_testing_app():\n",
    "    app = create_testing_app()\n",
    "\n",
    "    @app.consumes(\"my_topic_1\")\n",
    "    def on_my_topic_one(msg: MyMsgUrl):\n",
    "        logger.debug(f\"on_my_topic_one(msg={msg},)\")\n",
    "\n",
    "    @app.consumes()\n",
    "    async def on_my_topic_2(msg: MyMsgEmail):\n",
    "        logger.debug(f\"on_my_topic_2(msg={msg},)\")\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "\n",
    "        @app.consumes()\n",
    "        def my_topic_3(msg: MyMsgEmail):\n",
    "            raise NotImplemented\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "\n",
    "        @app.produces()\n",
    "        async def on_my_topic_1(msg: MyMsgUrl, kafka_msg: Message):\n",
    "            pass\n",
    "\n",
    "    @app.produces()\n",
    "    def on_my_topic_3(msg: MyMsgUrl, kafka_msg: Message):\n",
    "        logger.debug(f\"on_my_topic_3(msg={msg},, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces()\n",
    "    def on_my_topic_4(msg: MyMsgEmail, kafka_msg: Message):\n",
    "        logger.debug(f\"on_my_topic_4(msg={msg},, kafka_msg={kafka_msg})\")\n",
    "\n",
    "    @app.produces_on_error()\n",
    "    async def on_my_topic_error(raw_msg: KafkaErrorMsg, kafka_err: KafkaError):\n",
    "        logger.warning(f\"on_error(raw_msg={raw_msg}, kafka_err={kafka_err},)\")\n",
    "        \n",
    "    @app.produces()\n",
    "    def on_my_topic_test(msg: MyMsgUrl):\n",
    "            logger.debug(f\"on_topic_test(msg={msg})\")\n",
    "            return msg\n",
    "\n",
    "    return app, on_my_topic_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a945425",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, _= setup_testing_app()\n",
    "\n",
    "pprint(app._store)\n",
    "assert set(app._store[\"consumers\"].keys()) == set([\"my_topic_1\", \"my_topic_2\"])\n",
    "assert set(app._store[\"producers\"].keys()) == set(\n",
    "    [\"my_topic_3\", \"my_topic_4\", \"my_topic_error\", \"my_topic_test\"]\n",
    "), set(app._store[\"producers\"].keys())\n",
    "\n",
    "print(f\"app._kafka_service_info={app._kafka_service_info}\")\n",
    "\n",
    "print(f\"app._kafka_brokers={app._kafka_brokers}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f14b349",
   "metadata": {},
   "source": [
    "producer = AIOProducer()\n",
    "\n",
    "@app.produces(topic=\"topic_5\", producer=producer)\n",
    "async def f5(addr: str, port: int) -> ProduceMessage[MyMsgUrl]:\n",
    "    response = ProduceMessage(msg=MyMsgUrl(url=f\"https://{addr}:{port}\"), key=addr)\n",
    "    return response\n",
    "\n",
    "@app.produces(topic=\"topic_6\", producer=producer)\n",
    "async def f6(addr: str, port: int) -> ProduceMessage[MyMsgUrl]:\n",
    "    response = ProduceMessage(msg=MyMsgUrl(url=f\"https://{addr}:{port}\"), key=port)\n",
    "    return response\n",
    "\n",
    "@app.produces_on_error(topic=\"error_topic\", producer=producer)\n",
    "async def ferr(err: Exception) -> ProduceMessage[MyMsgUrl]:\n",
    "    response = ProduceMessage(err)\n",
    "    return response\n",
    "\n",
    "@app.consumes(topic=\"topic_7\"):\n",
    "async def g(msg: MyMsgUrl, produce: ProduceCallable):\n",
    "    addr = msg.url\n",
    "    port = 8000\n",
    "    await produce(topic=\"topic_6\", addr=addr, port=port)\n",
    "    \n",
    "@app.consumes(topic=\"topic_7\"):\n",
    "async def g(msg: MyMsgUrl):\n",
    "    addr = msg.url\n",
    "    port = 8000\n",
    "    await f6(addr, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ea338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def populate_consumers(\n",
    "    *,\n",
    "    app: FastKafkaAPI,\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    ") -> List[asyncio.Task]:\n",
    "    config: Dict[str, Any] = app._kafka_config\n",
    "    tx = [\n",
    "        asyncio.create_task(\n",
    "            aiokafka_consumer_loop(\n",
    "                topics=[topic],\n",
    "#                 bootstrap_servers=configuration.get(\"bootstrap.servers\",config[\"bootstrap.servers\"]),\n",
    "#                 auto_offset_reset=configuration.get(\"auto_offset_reset\", config[\"auto_offset_reset\"]),\n",
    "#                 max_poll_records=configuration.get(\"max_poll_records\", config[\"max_poll_records\"]),\n",
    "#                 max_buffer_size=configuration.get(\"max_buffer_size\", config[\"max_buffer_size\"]),\n",
    "                bootstrap_servers=config[\"bootstrap.servers\"],\n",
    "                auto_offset_reset=\"earliest\",\n",
    "                max_poll_records=100,\n",
    "                max_buffer_size=100,\n",
    "                callbacks={topic: consumer},\n",
    "                msg_types={topic: signature(consumer).parameters['msg'].annotation},\n",
    "                is_shutting_down_f=is_shutting_down_f,\n",
    "            )\n",
    "        )\n",
    "        for topic, (consumer, configuration) in app._store[\"consumers\"].items()\n",
    "    ]\n",
    "\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_producers(\n",
    "    *,\n",
    "    app: FastKafkaAPI\n",
    ") -> None:\n",
    "    config: Dict[str, Any] = app._kafka_config\n",
    "    print(app._store[\"producers\"])\n",
    "    for topic, (_, configuration) in app._store[\"producers\"].items():\n",
    "        producer = AIOKafkaProducer(\n",
    "            bootstrap_servers=config[\"bootstrap.servers\"]\n",
    "        )\n",
    "        asyncio.create_task(producer.start())\n",
    "        app._store[\"producers\"][topic] = (producer, configuration)\n",
    "    print(app._store[\"producers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def _on_startup(self: FastKafkaAPI) -> None:\n",
    "#     export_async_spec(\n",
    "#         consumers=self._store[\"consumers\"],  # type: ignore\n",
    "#         producers=self._store[\"producers\"],  # type: ignore\n",
    "#         kafka_brokers=self._kafka_brokers,\n",
    "#         kafka_service_info=self._kafka_service_info,\n",
    "#         asyncapi_path=self._asyncapi_path,\n",
    "#     )\n",
    "\n",
    "    self._is_shutting_down = False\n",
    "\n",
    "    def is_shutting_down_f(self: FastKafkaAPI = self) -> bool:\n",
    "        return self._is_shutting_down\n",
    "\n",
    "    self._kafka_consumer_tasks = populate_consumers(\n",
    "        app=self,\n",
    "        is_shutting_down_f=is_shutting_down_f,\n",
    "    )\n",
    "    \n",
    "    populate_producers(app=self)\n",
    "\n",
    "    self._confluent_producer = AIOProducer(self._kafka_config)\n",
    "    logger.info(\"AIOProducer created.\")\n",
    "\n",
    "\n",
    "@patch\n",
    "async def _on_shutdown(self: FastKafkaAPI) -> None:\n",
    "    self._is_shutting_down = True\n",
    "    await asyncio.wait(self._kafka_consumer_tasks)\n",
    "    self._confluent_producer.close()  # type: ignore\n",
    "    [await producer.stop() for producer, _ in self._store[\"producers\"].values()]\n",
    "    logger.info(\"AIOProducer closed.\")\n",
    "\n",
    "    self._is_shutting_down = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def start_test_app():\n",
    "    app, test_produce_function = setup_testing_app()\n",
    "    try:\n",
    "        app._on_startup()\n",
    "        yield app, test_produce_function\n",
    "    finally:\n",
    "        await app._on_shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = \"\"\"asyncapi: 2.5.0\n",
    "info:\n",
    "  title: FastKafkaAPI\n",
    "  version: 0.1.0\n",
    "  description: ''\n",
    "  contact:\n",
    "    name: author\n",
    "    url: https://www.google.com\n",
    "    email: noreply@gmail.com\n",
    "servers:\n",
    "  local:\n",
    "    url: kafka\n",
    "    description: Local (dev) Kafka broker\n",
    "    protocol: kafka\n",
    "    variables:\n",
    "      port:\n",
    "        default: '9092'\n",
    "channels:\n",
    "  my_topic_1:\n",
    "    subscribe:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgUrl'\n",
    "  my_topic_2:\n",
    "    subscribe:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgEmail'\n",
    "  my_topic_3:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgUrl'\n",
    "  my_topic_4:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/MyMsgEmail'\n",
    "  my_topic_error:\n",
    "    publish:\n",
    "      message:\n",
    "        $ref: '#/components/messages/KafkaErrorMsg'\n",
    "components:\n",
    "  messages:\n",
    "    MyMsgUrl:\n",
    "      payload:\n",
    "        title: MyMsgUrl\n",
    "        type: object\n",
    "        properties:\n",
    "          info:\n",
    "            title: Info\n",
    "            example:\n",
    "              mobile: '+385987654321'\n",
    "              name: James Bond\n",
    "            allOf:\n",
    "            - $ref: '#/components/schemas/MyInfo'\n",
    "          url:\n",
    "            title: Url\n",
    "            example: https://sis.gov.uk/agents/007\n",
    "            minLength: 1\n",
    "            maxLength: 2083\n",
    "            format: uri\n",
    "            type: string\n",
    "        required:\n",
    "        - info\n",
    "        - url\n",
    "        example:\n",
    "          info:\n",
    "            mobile: '+385987654321'\n",
    "            name: James Bond\n",
    "          url: https://sis.gov.uk/agents/007\n",
    "    MyMsgEmail:\n",
    "      payload:\n",
    "        title: MyMsgEmail\n",
    "        type: object\n",
    "        properties:\n",
    "          msg_url:\n",
    "            title: Msg Url\n",
    "            example:\n",
    "              info:\n",
    "                mobile: '+385987654321'\n",
    "                name: James Bond\n",
    "              url: https://sis.gov.uk/agents/007\n",
    "            allOf:\n",
    "            - $ref: '#/components/messages/MyMsgUrl'\n",
    "          email:\n",
    "            title: Email\n",
    "            example: agent-007@sis.gov.uk\n",
    "            type: string\n",
    "            format: email\n",
    "        required:\n",
    "        - msg_url\n",
    "        - email\n",
    "        example:\n",
    "          msg_url:\n",
    "            info:\n",
    "              mobile: '+385987654321'\n",
    "              name: James Bond\n",
    "            url: https://sis.gov.uk/agents/007\n",
    "          email: agent-007@sis.gov.uk\n",
    "    KafkaErrorMsg:\n",
    "      payload:\n",
    "        title: KafkaErrorMsg\n",
    "        type: object\n",
    "        properties:\n",
    "          topic:\n",
    "            title: Topic\n",
    "            description: topic where exception occurred\n",
    "            type: string\n",
    "          raw_msg:\n",
    "            title: Raw Msg\n",
    "            description: raw message string\n",
    "            format: binary\n",
    "            type: string\n",
    "          error:\n",
    "            title: Error\n",
    "            description: exception triggered by the message\n",
    "            type: string\n",
    "        required:\n",
    "        - topic\n",
    "        - error\n",
    "  schemas:\n",
    "    MyInfo:\n",
    "      payload:\n",
    "        title: MyInfo\n",
    "        type: object\n",
    "        properties:\n",
    "          mobile:\n",
    "            title: Mobile\n",
    "            example: '+385987654321'\n",
    "            type: string\n",
    "          name:\n",
    "            title: Name\n",
    "            example: James Bond\n",
    "            type: string\n",
    "        required:\n",
    "        - mobile\n",
    "        - name\n",
    "  securitySchemes: {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef04db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_me():\n",
    "    async with start_test_app() as (app, test_produce_function):\n",
    "        client = TestClient(app)\n",
    "        response = client.get(\"/asyncapi.yml\")\n",
    "        assert response.status_code == 200\n",
    "        assert yaml.safe_load(response.text) == yaml.safe_load(\n",
    "            expected\n",
    "        ), f\"{yaml.safe_load(response.text)} != {yaml.safe_load(expected)}\"\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        await test_produce_function(msg=MyMsgUrl(info=dict(mobile=\"+385987654321\", name=\"James Bond\"), url=\"https://sis.gov.uk/agents/007\"))\n",
    "\n",
    "asyncio.run(test_me())\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce822c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def produce_raw(\n",
    "    self: FastKafkaAPI,\n",
    "    topic: str,\n",
    "    raw_msg: Union[str, bytes],\n",
    "    on_delivery: Optional[Callable[[KafkaMessage, Message], None]] = None,\n",
    ") -> \"asyncio.Future[Any]\":\n",
    "\n",
    "    if isinstance(raw_msg, str):\n",
    "        raw_msg = raw_msg.encode(\"utf-8\")\n",
    "\n",
    "    if on_delivery is None:\n",
    "        on_delivery = self._store[\"producers\"][topic]  # type: ignore\n",
    "\n",
    "    if iscoroutinefunction(on_delivery):\n",
    "        raise ValueError(\"coroutines not supported for callbacks yet\")\n",
    "\n",
    "    p: AIOProducer = self._confluent_producer  # type: ignore\n",
    "\n",
    "    def _delivery_report(\n",
    "        kafka_err: KafkaError,\n",
    "        kafka_msg: Message,\n",
    "        self=self,\n",
    "        topic=topic,\n",
    "        raw_msg=raw_msg,\n",
    "        on_delivery=on_delivery,\n",
    "    ):\n",
    "        msg_cls: KafkaMessage\n",
    "        if kafka_err is not None:\n",
    "            logger.info(f\"produce_raw() topic={topic} raw_msg={raw_msg} delivery error\")\n",
    "            if self._on_error_topic is not None:\n",
    "                on_error = self._store[\"producers\"][self._on_error_topic]\n",
    "                msg_cls = _get_msg_cls_for_method(on_error)\n",
    "                on_error(\n",
    "                    msg_cls(\"Message delivery failed: {}\".format(kafka_err)), kafka_err  # type: ignore\n",
    "                )\n",
    "        else:\n",
    "            logger.info(f\"produce_raw() topic={topic} raw_msg={raw_msg} delivered\")\n",
    "            msg_cls = _get_msg_cls_for_method(on_delivery)\n",
    "            on_delivery(msg_cls.parse_raw(raw_msg), kafka_msg)\n",
    "\n",
    "    return p.produce(topic, raw_msg, on_delivery=_delivery_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_msg = (\n",
    "    MyMsgUrl(\n",
    "        info=dict(mobile=\"+385987654321\", name=\"James Bond\"),\n",
    "        url=\"https://sis.gov.uk/agents/007\",\n",
    "    )\n",
    "    .json()\n",
    "    .encode(\"utf-8\")\n",
    ")\n",
    "\n",
    "\n",
    "async def test_me():\n",
    "    async with start_test_app() as (app, _):\n",
    "        await app.produce_raw(\"my_topic_3\", raw_msg)\n",
    "\n",
    "        def _on_delivery(msg: KafkaMessage, *args):\n",
    "            logger.warning(\"me so cool\")\n",
    "\n",
    "        # we don't need to wait for it\n",
    "        app.produce_raw(\"my_topic_3\", raw_msg, on_delivery=_on_delivery)\n",
    "\n",
    "\n",
    "asyncio.run(test_me())\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c17161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "@patch\n",
    "def test_run(self: FastKafkaAPI, f: Callable[[], Any], timeout: int = 30):\n",
    "    async def _loop(app: FastKafkaAPI = self, f: Callable[[], Any] = f):\n",
    "        logger.info(f\"test_run(): starting\")\n",
    "        try:\n",
    "            async with anyio.create_task_group() as tg:\n",
    "                with anyio.move_on_after(timeout) as scope:\n",
    "                    app._on_startup()  # type: ignore\n",
    "\n",
    "                    if iscoroutinefunction(f):\n",
    "                        logger.info(f\"test_run(app={app}, f={f}): Calling coroutine {f}\")\n",
    "                        retval = await f()\n",
    "                    else:\n",
    "                        logger.info(f\"test_run(app={app}, f={f}): Calling function {f}\")\n",
    "                        retval = await asyncer.asyncify(f)()\n",
    "\n",
    "                return retval\n",
    "        except Exception as e:\n",
    "            logger.error(f\"test_run(): exception caugth {e}\")\n",
    "            raise e\n",
    "        finally:\n",
    "            logger.info(f\"test_run(app={app}, f={f}): shutting down the app\")\n",
    "            await app._on_shutdown()\n",
    "            logger.info(f\"test_run(app={app}, f={f}): finished\")\n",
    "\n",
    "    return asyncer.runnify(_loop)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retval = app.test_run(lambda: print(\"Hello world\"))\n",
    "print(f\"retval={retval},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33dc733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "@patch\n",
    "@asynccontextmanager\n",
    "async def testing_ctx(self: FastKafkaAPI, timeout: int = 30):\n",
    "    logger.info(f\"test_context(): starting\")\n",
    "    try:\n",
    "        async with anyio.create_task_group() as tg:\n",
    "            with anyio.move_on_after(timeout) as scope:\n",
    "                self._on_startup()  # type: ignore\n",
    "\n",
    "                yield\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"test_context(): exception caugth {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        logger.info(f\"test_context(self={self}): shutting down the app\")\n",
    "        await self._on_shutdown()\n",
    "        logger.info(f\"test_context(self={self}): finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2da7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.testing_ctx():\n",
    "    print(\"app is up and running\")\n",
    "    await anyio.sleep(2)\n",
    "print(\"app is shut down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with app.testing_ctx(timeout=3):\n",
    "    print(\"app is up and running\")\n",
    "    await anyio.sleep(1000)\n",
    "print(\"app is shut down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d919ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f345e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4416c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd52e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6da7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# uvicorn.run(app, host=\"0.0.0.0\", port=6006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5aa1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
