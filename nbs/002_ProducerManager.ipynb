{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41796226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_producer_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import *\n",
    "\n",
    "import anyio\n",
    "from aiokafka import AIOKafkaProducer\n",
    "from anyio.streams.memory import MemoryObjectReceiveStream\n",
    "\n",
    "from fastkafka._components.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9671c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest.mock\n",
    "from os import environ\n",
    "\n",
    "from fastkafka._components.logger import supress_timestamps\n",
    "from fastkafka.testing import (\n",
    "    create_and_fill_testing_topic,\n",
    "    nb_safe_seed,\n",
    "    true_after,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = nb_safe_seed(\"_components.aiokafka_producer_loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aded0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe6652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=1)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1146f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def _aiokafka_producer_manager(  # type: ignore\n",
    "    producer: AIOKafkaProducer, *, max_buffer_size: int = 10_000\n",
    "):\n",
    "    \"\"\"Write docs\n",
    "\n",
    "    Todo: add batch size if needed\n",
    "    \"\"\"\n",
    "\n",
    "    logger.info(\"_aiokafka_producer_manager(): Starting...\")\n",
    "\n",
    "    async def send_message(receive_stream: MemoryObjectReceiveStream) -> Any:\n",
    "        async with receive_stream:\n",
    "            async for topic, msg in receive_stream:\n",
    "                fut = await producer.send(topic, msg)\n",
    "                msg = await fut\n",
    "\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "        max_buffer_size=max_buffer_size\n",
    "    )\n",
    "\n",
    "    logger.info(\"_aiokafka_producer_manager(): Starting task group\")\n",
    "    async with anyio.create_task_group() as task_group:\n",
    "        logger.info(\"_aiokafka_producer_manager(): Starting send_stream\")\n",
    "        task_group.start_soon(send_message, receive_stream)\n",
    "        async with send_stream:\n",
    "            yield send_stream\n",
    "            logger.info(\"_aiokafka_producer_manager(): Exiting send_stream\")\n",
    "        logger.info(\"_aiokafka_producer_manager(): Exiting task group\")\n",
    "    logger.info(\"_aiokafka_producer_manager(): Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce58e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def mock_AIOKafkaProducer_send():\n",
    "    with unittest.mock.patch(\"__main__.AIOKafkaProducer.send\") as mock:\n",
    "\n",
    "        async def _f():\n",
    "            pass\n",
    "\n",
    "        mock.return_value = asyncio.create_task(_f())\n",
    "\n",
    "        yield mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c07d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Starting send_stream\n",
      "[DEBUG] aiokafka.producer.producer: The Kafka producer has closed.\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Exiting task group\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Finished.\n"
     ]
    }
   ],
   "source": [
    "num_msgs = 15\n",
    "topic = \"topic\"\n",
    "msg = b\"msg\"\n",
    "msgs = [(topic, msg) for _ in range(num_msgs)]\n",
    "calls = [unittest.mock.call(topic, msg) for _ in range(num_msgs)]\n",
    "\n",
    "with mock_AIOKafkaProducer_send() as send_mock:\n",
    "    producer = AIOKafkaProducer()\n",
    "    async with _aiokafka_producer_manager(producer) as send_stream:\n",
    "        for msg in msgs:\n",
    "            send_stream.send_nowait(msg)\n",
    "\n",
    "        await producer.stop()\n",
    "    #     await producer_loop_generator.__aexit__(None, None, None)\n",
    "\n",
    "    send_mock.assert_has_calls(calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class AIOKafkaProducerManager:\n",
    "    def __init__(self, producer: AIOKafkaProducer, *, max_buffer_size: int = 1_000):  # type: ignore\n",
    "        self.producer = producer\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "\n",
    "    async def start(self) -> None:\n",
    "        logger.info(\"AIOKafkaProducerManager.start(): Entering...\")\n",
    "        await self.producer.start()\n",
    "        self.producer_manager_generator = _aiokafka_producer_manager(self.producer)\n",
    "        self.send_stream = await self.producer_manager_generator.__aenter__()\n",
    "        logger.info(\"AIOKafkaProducerManager.start(): Finished.\")\n",
    "\n",
    "    async def stop(self) -> None:\n",
    "        # todo: try to flush messages before you exit\n",
    "        logger.info(\"AIOKafkaProducerManager.stop(): Entering...\")\n",
    "        await self.producer_manager_generator.__aexit__(None, None, None)\n",
    "        logger.info(\"AIOKafkaProducerManager.stop(): Stoping producer...\")\n",
    "        await self.producer.stop()\n",
    "        logger.info(\"AIOKafkaProducerManager.stop(): Finished\")\n",
    "\n",
    "    def send(self, topic: str, msg: bytes) -> None:\n",
    "        self.send_stream.send_nowait((topic, msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff250ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: AIOKafkaProducerManager.start(): Entering...\n",
      "[DEBUG] aiokafka.producer.producer: Starting the Kafka producer\n",
      "[DEBUG] aiokafka: Attempting to bootstrap via node at tvrtko-fast-kafka-api-kafka-1:9092\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=tvrtko-fast-kafka-api-kafka-1 port=9092> Request 1: MetadataRequest_v0(topics=[])\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=tvrtko-fast-kafka-api-kafka-1 port=9092> Response 1: MetadataResponse_v0(brokers=[(node_id=1001, host='75d5a1be66b3', port=9092), (node_id=1003, host='40c27daf393d', port=9092), (node_id=1002, host='681f4568022c', port=9092)], topics=[(error_code=0, topic='my_topic_1', partitions=[(error_code=0, partition=0, leader=1003, replicas=[1003], isr=[1003])]), (error_code=0, topic='my_test_topic_2', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002], isr=[1002])]), (error_code=0, topic='training_status', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=5, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=4, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=1, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=2, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=3, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002])]), (error_code=0, topic='prediction_request', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=5, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=1, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=4, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=2, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=3, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001])]), (error_code=0, topic='my_topic_2', partitions=[(error_code=0, partition=0, leader=1003, replicas=[1003], isr=[1003])]), (error_code=0, topic='training_data', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='topic', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='prediction_status', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=5, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=1, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=4, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=2, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=3, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003])]), (error_code=0, topic='realitime_data', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='training_request', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=5, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=1, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=4, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=2, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=3, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003])])])\n",
      "[DEBUG] aiokafka.cluster: Updated cluster metadata to ClusterMetadata(brokers: 3, topics: 10, groups: 0)\n",
      "[DEBUG] aiokafka.conn: Closing connection at tvrtko-fast-kafka-api-kafka-1:9092\n",
      "[DEBUG] aiokafka: Received cluster metadata: ClusterMetadata(brokers: 3, topics: 10, groups: 0)\n",
      "[DEBUG] aiokafka: Initiating connection to node 1003 at 40c27daf393d:9092\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=40c27daf393d port=9092> Request 1: ApiVersionRequest_v0()\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=40c27daf393d port=9092> Response 1: ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=12), (api_key=2, min_version=0, max_version=6), (api_key=3, min_version=0, max_version=11), (api_key=4, min_version=0, max_version=5), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=7), (api_key=10, min_version=0, max_version=3), (api_key=11, min_version=0, max_version=7), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=4), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=2), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=0), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0)])\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=40c27daf393d port=9092> Request 2: MetadataRequest_v0(topics=[])\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=40c27daf393d port=9092> Response 2: MetadataResponse_v0(brokers=[(node_id=1001, host='75d5a1be66b3', port=9092), (node_id=1003, host='40c27daf393d', port=9092), (node_id=1002, host='681f4568022c', port=9092)], topics=[(error_code=0, topic='my_topic_1', partitions=[(error_code=0, partition=0, leader=1003, replicas=[1003], isr=[1003])]), (error_code=0, topic='my_test_topic_2', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002], isr=[1002])]), (error_code=0, topic='training_status', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=5, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=4, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=1, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=2, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=3, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002])]), (error_code=0, topic='prediction_request', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=5, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=1, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=4, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=2, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=3, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001])]), (error_code=0, topic='my_topic_2', partitions=[(error_code=0, partition=0, leader=1003, replicas=[1003], isr=[1003])]), (error_code=0, topic='training_data', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='topic', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='prediction_status', partitions=[(error_code=0, partition=0, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=5, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=1, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=4, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=2, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003]), (error_code=0, partition=3, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003])]), (error_code=0, topic='realitime_data', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001], isr=[1001])]), (error_code=0, topic='training_request', partitions=[(error_code=0, partition=0, leader=1001, replicas=[1001, 1003, 1002], isr=[1001, 1003, 1002]), (error_code=0, partition=5, leader=1003, replicas=[1003, 1001, 1002], isr=[1003, 1001, 1002]), (error_code=0, partition=1, leader=1002, replicas=[1002, 1001, 1003], isr=[1002, 1001, 1003]), (error_code=0, partition=4, leader=1002, replicas=[1002, 1003, 1001], isr=[1002, 1003, 1001]), (error_code=0, partition=2, leader=1003, replicas=[1003, 1002, 1001], isr=[1003, 1002, 1001]), (error_code=0, partition=3, leader=1001, replicas=[1001, 1002, 1003], isr=[1001, 1002, 1003])])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] aiokafka.conn: Closing connection at 40c27daf393d:9092\n",
      "[DEBUG] aiokafka.producer.producer: Kafka producer started\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Starting...\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Starting task group\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Starting send_stream\n",
      "[INFO] __main__: AIOKafkaProducerManager.start(): Finished.\n",
      "[INFO] __main__: AIOKafkaProducerManager.stop(): Entering...\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Exiting send_stream\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Exiting task group\n",
      "[DEBUG] aiokafka.producer.producer: Sending (key=None value=b'msg') to TopicPartition(topic='topic', partition=0)\n",
      "[DEBUG] aiokafka: Initiating connection to node 1001 at 75d5a1be66b3:9092\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=75d5a1be66b3 port=9092> Request 1: ApiVersionRequest_v0()\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=75d5a1be66b3 port=9092> Response 1: ApiVersionResponse_v0(error_code=0, api_versions=[(api_key=0, min_version=0, max_version=9), (api_key=1, min_version=0, max_version=12), (api_key=2, min_version=0, max_version=6), (api_key=3, min_version=0, max_version=11), (api_key=4, min_version=0, max_version=5), (api_key=5, min_version=0, max_version=3), (api_key=6, min_version=0, max_version=7), (api_key=7, min_version=0, max_version=3), (api_key=8, min_version=0, max_version=8), (api_key=9, min_version=0, max_version=7), (api_key=10, min_version=0, max_version=3), (api_key=11, min_version=0, max_version=7), (api_key=12, min_version=0, max_version=4), (api_key=13, min_version=0, max_version=4), (api_key=14, min_version=0, max_version=5), (api_key=15, min_version=0, max_version=5), (api_key=16, min_version=0, max_version=4), (api_key=17, min_version=0, max_version=1), (api_key=18, min_version=0, max_version=3), (api_key=19, min_version=0, max_version=7), (api_key=20, min_version=0, max_version=6), (api_key=21, min_version=0, max_version=2), (api_key=22, min_version=0, max_version=4), (api_key=23, min_version=0, max_version=4), (api_key=24, min_version=0, max_version=3), (api_key=25, min_version=0, max_version=3), (api_key=26, min_version=0, max_version=3), (api_key=27, min_version=0, max_version=1), (api_key=28, min_version=0, max_version=3), (api_key=29, min_version=0, max_version=2), (api_key=30, min_version=0, max_version=2), (api_key=31, min_version=0, max_version=2), (api_key=32, min_version=0, max_version=4), (api_key=33, min_version=0, max_version=2), (api_key=34, min_version=0, max_version=2), (api_key=35, min_version=0, max_version=2), (api_key=36, min_version=0, max_version=2), (api_key=37, min_version=0, max_version=3), (api_key=38, min_version=0, max_version=2), (api_key=39, min_version=0, max_version=2), (api_key=40, min_version=0, max_version=2), (api_key=41, min_version=0, max_version=2), (api_key=42, min_version=0, max_version=2), (api_key=43, min_version=0, max_version=2), (api_key=44, min_version=0, max_version=1), (api_key=45, min_version=0, max_version=0), (api_key=46, min_version=0, max_version=0), (api_key=47, min_version=0, max_version=0), (api_key=48, min_version=0, max_version=1), (api_key=49, min_version=0, max_version=1), (api_key=50, min_version=0, max_version=0), (api_key=51, min_version=0, max_version=0), (api_key=56, min_version=0, max_version=0), (api_key=57, min_version=0, max_version=0), (api_key=60, min_version=0, max_version=0), (api_key=61, min_version=0, max_version=0)])\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=75d5a1be66b3 port=9092> Request 2: ProduceRequest_v7(transactional_id=None, required_acks=1, timeout=40000, topics=[(topic='topic', partitions=[(partition=0, messages=bytearray(b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00;\\xff\\xff\\xff\\xff\\x02\\xcbLP\\xf4\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x85{\\xe8\\x00.\\x00\\x00\\x01\\x85{\\xe8\\x00.\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x12\\x00\\x00\\x00\\x01\\x06msg\\x00'))])])\n",
      "[DEBUG] aiokafka.conn: <AIOKafkaConnection host=75d5a1be66b3 port=9092> Response 2: ProduceResponse_v7(topics=[(topic='topic', partitions=[(partition=0, error_code=0, offset=1, timestamp=-1, log_start_offset=0)])], throttle_time_ms=0)\n",
      "[INFO] __main__: _aiokafka_producer_manager(): Finished.\n",
      "[INFO] __main__: AIOKafkaProducerManager.stop(): Stoping producer...\n",
      "[DEBUG] aiokafka.conn: Closing connection at 40c27daf393d:9092\n",
      "[DEBUG] aiokafka.conn: Closing connection at 75d5a1be66b3:9092\n",
      "[DEBUG] aiokafka.producer.producer: The Kafka producer has closed.\n",
      "[INFO] __main__: AIOKafkaProducerManager.stop(): Finished\n",
      "[INFO] __main__: Stopped\n"
     ]
    }
   ],
   "source": [
    "producer = AIOKafkaProducer(bootstrap_servers=kafka_config[\"bootstrap.servers\"])\n",
    "manager = AIOKafkaProducerManager(producer)\n",
    "await manager.start()\n",
    "manager.send(\"topic\", b\"msg\")\n",
    "await manager.stop()\n",
    "logger.info(\"Stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9d3e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
