{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.asyncapi: ok\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "from typing import *\n",
    "\n",
    "from os import environ\n",
    "import asyncio\n",
    "import unittest.mock\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from aiokafka.structs import TopicPartition, ConsumerRecord\n",
    "from pydantic import BaseModel, HttpUrl, NonNegativeInt, Field\n",
    "import asyncer\n",
    "import anyio\n",
    "\n",
    "from fast_kafka_api.logger import get_logger, supress_timestamps\n",
    "from fast_kafka_api.testing import true_after, create_and_fill_testing_topic, nb_safe_seed\n",
    "from fast_kafka_api.asyncapi import KafkaMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a9f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = nb_safe_seed(\"_components.aiokafka_loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feb585",
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.debug(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a41c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "kafka_server_port = environ[\"KAFKA_PORT\"]\n",
    "\n",
    "kafka_config = {\n",
    "    \"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessage(BaseModel):\n",
    "    url: HttpUrl = Field(..., example=\"http://www.acme.com\", description=\"Url example\")\n",
    "    port: NonNegativeInt = Field(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178af400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def process_msgs(\n",
    "    *,\n",
    "    msgs: Dict[TopicPartition, List[ConsumerRecord]],\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[KafkaMessage, Callable[[str, BaseModel], None]], None]\n",
    "    ],\n",
    "    produce: Callable[[str, BaseModel], None],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    process_f: Callable[None, None] ## TODO, add correct typing\n",
    "):\n",
    "    for topic_partition, topic_msgs in msgs.items():\n",
    "        topic = topic_partition.topic\n",
    "        msg_type = msg_types[topic]\n",
    "        decoded_msgs = [\n",
    "            msg_type.parse_raw(msg.value.decode(\"utf-8\")) for msg in topic_msgs\n",
    "        ]\n",
    "        for msg in decoded_msgs:\n",
    "            await process_f((callbacks[topic], msg, produce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_part_0_0 = TopicPartition(\"topic_0\", 0)\n",
    "topic_part_0_1 = TopicPartition(\"topic_0\", 1)\n",
    "topic_part_1_0 = TopicPartition(\"topic_1\", 0)\n",
    "\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One msg, one topic, callback called once, produce and process_f called once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10589655",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two msg, two topics, each callback called once, produce and process_f called twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two msg, one topic, one callback called twice, other called nonce, produce and process_f called twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two msg, one topic, two partitions, one callback called twice, produce and process_f called twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def process_message_callback(receive_stream):\n",
    "    async with receive_stream:\n",
    "        async for callback, msg, produce in receive_stream:\n",
    "            await callback(msg, produce)\n",
    "            \n",
    "\n",
    "async def _aiokafka_consumer_loop(\n",
    "    *,\n",
    "    consumer,\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[KafkaMessage, Callable[[str, BaseModel], None]], None]\n",
    "    ],\n",
    "    produce: Callable[[str, BaseModel], None],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "):\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(process_message_callback, receive_stream)\n",
    "        async with send_stream:\n",
    "            while True:\n",
    "                msgs = await consumer.getmany(timeout_ms=100)\n",
    "                await process_msgs(\n",
    "                    msgs=msgs,\n",
    "                    callbacks=callbacks,\n",
    "                    produce=produce,\n",
    "                    msg_types=msg_types,\n",
    "                    process_f=send_stream.send,\n",
    "                )\n",
    "                if is_shutting_down_f():\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock consumer with messages in getmany\n",
    "# Check full combination of callbacks in the previous tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77397e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96203049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def aiokafka_consumer_loop(\n",
    "    topics: List[str],\n",
    "    *,\n",
    "    bootstrap_servers: str,\n",
    "    auto_offset_reset: str,\n",
    "    max_poll_records: int,\n",
    "    callbacks: Dict[\n",
    "        str, Callable[[KafkaMessage, Callable[[str, BaseModel], None]], None]\n",
    "    ],\n",
    "    produce: Callable[[str, BaseModel], None],\n",
    "    msg_types: Dict[str, Type[BaseModel]],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "):\n",
    "    consumer = AIOKafkaConsumer(\n",
    "        bootstrap_servers=bootstrap_servers,\n",
    "        auto_offset_reset=auto_offset_reset,\n",
    "        max_poll_records=max_poll_records,\n",
    "    )\n",
    "    logger.info(\"Consumer created.\")\n",
    "\n",
    "    await consumer.start()\n",
    "    logger.info(\"Consumer started.\")\n",
    "    consumer.subscribe(topics)\n",
    "    logger.info(\"Consumer subscribed.\")\n",
    "\n",
    "    try:\n",
    "        await _aiokafka_consumer_loop(\n",
    "            consumer=consumer,\n",
    "            callbacks=callbacks,\n",
    "            produce=produce,\n",
    "            msg_types=msg_types,\n",
    "            is_shutting_down_f=is_shutting_down_f,\n",
    "        )\n",
    "    finally:\n",
    "        await consumer.stop()\n",
    "        logger.info(f\"Consumer stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_928922829']): new_topics = [NewTopic(topic=my_topic_928922829,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stared.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=9178\n",
      "[INFO] __main__: Consumer created.\n",
      "[INFO] __main__: Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_928922829'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_928922829'}\n",
      "[INFO] __main__: Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_928922829': 3}. \n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=2000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=3000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=4000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=9000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=1000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=7000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=8000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=0 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=5000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=6000 for my_topic\n",
      "[INFO] __main__: Consumer stopped.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "async def count_msg(msg: MyMessage, produce):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    await produce(\"my_topic\", msg)\n",
    "    \n",
    "async def produce_print_msg(topic: str, msg: MyMessage):\n",
    "    if msg.port % 1000 == 0:\n",
    "        print(f\"Producing {msg} for {topic}\")\n",
    "\n",
    "async with create_and_fill_testing_topic(kafka_config=kafka_config, msgs=msgs, seed=seed(1)) as topic:\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics = [topic],\n",
    "        bootstrap_servers = kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        max_poll_records=100,\n",
    "        callbacks = {topic: count_msg},\n",
    "        produce = produce_print_msg,\n",
    "        msg_types= {topic: MyMessage},\n",
    "        is_shutting_down_f= true_after(5),\n",
    "    )\n",
    "\n",
    "assert msgs_sent == msgs_received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.testing: create_missing_topics(['my_topic_928922829']): new_topics = [NewTopic(topic=my_topic_928922829,num_partitions=3)]\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stared.\n",
      "[INFO] fast_kafka_api.testing: Sent messages: len(sent_msgs)=100000\n",
      "[INFO] __main__: Consumer created.\n",
      "[INFO] __main__: Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_928922829'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'my_topic_928922829'}\n",
      "[INFO] __main__: Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_928922829': 3}. \n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=20000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=10000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=0 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=30000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=40000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=50000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=60000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=70000 for my_topic\n",
      "Producing url=HttpUrl('http://www.ai.com', ) port=90000 for my_topic\n",
      "[INFO] __main__: Consumer stopped.\n",
      "Messages processed: 82,500\n",
      "Time              : 5.01 s\n",
      "Throughput.       : 16,483 msg/s\n",
      "[INFO] fast_kafka_api.testing: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "msgs_sent = 100000\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "async def count_msg(msg: MyMessage, produce):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    await produce(\"my_topic\", msg)\n",
    "    \n",
    "async def produce_print_msg(topic: str, msg: MyMessage):\n",
    "    if msg.port % 10000 == 0:\n",
    "        print(f\"Producing {msg} for {topic}\")\n",
    "\n",
    "async with create_and_fill_testing_topic(kafka_config=kafka_config, msgs=msgs, seed=seed(1)) as topic:\n",
    "    start = datetime.now()\n",
    "    await aiokafka_consumer_loop(\n",
    "        topics = [topic],\n",
    "        bootstrap_servers = kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        max_poll_records=100,\n",
    "        callbacks = {topic: count_msg},\n",
    "        produce = produce_print_msg,\n",
    "        msg_types= {topic: MyMessage},\n",
    "        is_shutting_down_f= true_after(5),\n",
    "    )\n",
    "    t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "    thrp = msgs_received / t\n",
    "    \n",
    "    print(f\"Messages processed: {msgs_received:,d}\")\n",
    "    print(f\"Time              : {t:.2f} s\")\n",
    "    print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bc3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
