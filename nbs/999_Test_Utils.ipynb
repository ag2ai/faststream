{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc959176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def in_notebook():\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "\n",
    "        if \"IPKernelApp\" not in get_ipython().config:\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9760c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bc80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "import contextlib\n",
    "import hashlib\n",
    "import os\n",
    "import random\n",
    "import shlex\n",
    "import textwrap\n",
    "\n",
    "# [B404:blacklist] Consider possible security implications associated with the subprocess module.\n",
    "import subprocess  # nosec\n",
    "import time\n",
    "import unittest\n",
    "import unittest.mock\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from fastcore.meta import delegates\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Any, Callable, Dict, Generator, List, Optional, Tuple, AsyncIterator, Union\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from aiokafka import AIOKafkaConsumer, AIOKafkaProducer\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "if in_notebook():\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "else:\n",
    "    from tqdm import tqdm, trange\n",
    "    \n",
    "from fast_kafka_api._components.logger import get_logger, supress_timestamps\n",
    "from fast_kafka_api._components.helpers import delegates_using_docstring\n",
    "from fast_kafka_api.helpers import create_admin_client, create_missing_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a1ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "import nest_asyncio\n",
    "from nbdev_mkdocs.docstring import run_examples_from_docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "# allows async calls in notebooks\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2eb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3eee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6902fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "kafka_server_url = (\n",
    "    os.environ[\"KAFKA_HOSTNAME\"] if \"KAFKA_HOSTNAME\" in os.environ else \"localhost\"\n",
    ")\n",
    "kafka_server_port = os.environ[\"KAFKA_PORT\"] if \"KAFKA_PORT\" in os.environ else \"9092\"\n",
    "\n",
    "kafka_config = {\n",
    "    \"bootstrap.servers\": f\"{kafka_server_url}:{kafka_server_port}\",\n",
    "    # \"group.id\": f\"{kafka_server_url}:{kafka_server_port}_group\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf46a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def true_after(seconds: float) -> Callable[[], bool]:\n",
    "    \"\"\"Function returning True after a given number of seconds\"\"\"\n",
    "    t = datetime.now()\n",
    "\n",
    "    def _true_after(seconds: float = seconds, t: datetime = t) -> bool:\n",
    "        return (datetime.now() - t) > timedelta(seconds=seconds)\n",
    "\n",
    "    return _true_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac939ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = true_after(1.1)\n",
    "assert not f()\n",
    "time.sleep(1)\n",
    "assert not f()\n",
    "time.sleep(0.1)\n",
    "assert f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed690d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "@delegates_using_docstring(create_missing_topics)\n",
    "def create_testing_topic(\n",
    "    topic_prefix: str, *, seed: Optional[int] = None, **kwargs: Dict[str, Any]\n",
    ") -> Generator[str, None, None]:\n",
    "    \"\"\"Create testing topic\n",
    "    \n",
    "    Args:\n",
    "        topic_prefix: topic name prefix which will be augumented with a randomly generated sufix\n",
    "        seed: seed used to generate radnom sufix\n",
    "        \n",
    "    Returns:\n",
    "        Generator returning the generated name of the created topic\n",
    "        \n",
    "    Example:\n",
    "        ```python\n",
    "        from os import environ\n",
    "        from fast_kafka_api.testing import create_testing_topic, create_admin_client\n",
    "        \n",
    "        kafka_server_url = environ[\"KAFKA_HOSTNAME\"]\n",
    "        kafka_config = {\"bootstrap.servers\": f\"{kafka_server_url}:9092\"}\n",
    "        \n",
    "        with create_testing_topic(\"my_topic_\", num_partitions=1, **aiokafka_config) as topic:\n",
    "            # Check if topic is created and exists in topic list\n",
    "            kafka_admin = create_admin_client(**aiokafka_config)\n",
    "            existing_topics = kafka_admin.list_topics().topics.keys()\n",
    "            assert topic in existing_topics\n",
    "\n",
    "        # Check if topic is deleted after exiting context\n",
    "        existing_topics = kafka_admin.list_topics().topics.keys()\n",
    "        assert topic not in existing_topics\n",
    "        ```\n",
    "    \"\"\"\n",
    "    # create random topic name\n",
    "    random.seed(seed)\n",
    "    # [B311:blacklist] Standard pseudo-random generators are not suitable for security/cryptographic purposes.\n",
    "    suffix = str(random.randint(0, 10**10))  # nosec\n",
    "\n",
    "    topic = topic_prefix + suffix.zfill(3)\n",
    "\n",
    "    # delete topic if it already exists\n",
    "    admin = create_admin_client(**kwargs)\n",
    "    existing_topics = admin.list_topics().topics.keys()\n",
    "    if topic in existing_topics:\n",
    "        logger.warning(f\"topic {topic} exists, deleting it...\")\n",
    "        fs = admin.delete_topics(topics=[topic])\n",
    "        results = {k: f.result() for k, f in fs.items()}\n",
    "        while topic in admin.list_topics().topics.keys():\n",
    "            time.sleep(1)\n",
    "    try:\n",
    "        # create topic if needed\n",
    "        create_missing_topics([topic], **kwargs)\n",
    "        while topic not in admin.list_topics().topics.keys():\n",
    "            time.sleep(1)\n",
    "        yield topic\n",
    "\n",
    "    finally:\n",
    "        pass\n",
    "        # cleanup if needed again\n",
    "        fs = admin.delete_topics(topics=[topic])\n",
    "        while topic in admin.list_topics().topics.keys():\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_examples_from_docstring(create_testing_topic, width=120, supress_stdout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.helpers: create_missing_topics(['my_topic_6334300722']): new_topics = [NewTopic(topic=my_topic_6334300722,num_partitions=1)]\n"
     ]
    }
   ],
   "source": [
    "kafka_server_url = os.environ[\"KAFKA_HOSTNAME\"]\n",
    "aiokafka_config = {\"bootstrap_servers\": f\"{kafka_server_url}:9092\"}\n",
    "\n",
    "with create_testing_topic(\"my_topic_\", num_partitions=1, **aiokafka_config) as topic:\n",
    "    # Check if topic is created and exists in topic list\n",
    "    kafka_admin = create_admin_client(**aiokafka_config)\n",
    "    existing_topics = kafka_admin.list_topics().topics.keys()\n",
    "    assert topic in existing_topics\n",
    "\n",
    "# Check if topic is deleted after exiting context\n",
    "existing_topics = kafka_admin.list_topics().topics.keys()\n",
    "assert topic not in existing_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "@delegates(create_testing_topic)\n",
    "@delegates_using_docstring(AIOKafkaProducer)\n",
    "async def create_and_fill_testing_topic(\n",
    "    msgs: List[bytes], *, seed: int, **kwargs: Dict[str, str]\n",
    ") -> AsyncIterator[str]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        msgs:\n",
    "        seed:\n",
    "    \"\"\"\n",
    "\n",
    "    with create_testing_topic(\"my_topic_\", seed=seed, **kwargs) as topic:\n",
    "\n",
    "        producer = AIOKafkaProducer(**kwargs)\n",
    "        logger.info(f\"Producer {producer} created.\")\n",
    "\n",
    "        await producer.start()\n",
    "        logger.info(f\"Producer {producer} started.\")\n",
    "        try:\n",
    "            fx = [\n",
    "                producer.send(\n",
    "                    topic,\n",
    "                    msg,\n",
    "                    key=f\"{i % 17}\".encode(\"utf-8\"),\n",
    "                )\n",
    "                for i, msg in enumerate(msgs)\n",
    "            ]\n",
    "            await producer.flush()\n",
    "            sent_msgs = [await f for f in fx]\n",
    "            msg_statuses = [await s for s in sent_msgs]\n",
    "            logger.info(f\"Sent messages: len(sent_msgs)={len(sent_msgs)}\")\n",
    "\n",
    "            yield topic\n",
    "        finally:\n",
    "            await producer.stop()\n",
    "            logger.info(f\"Producer {producer} stoped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00149fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.helpers: create_missing_topics(['my_topic_9167024629']): new_topics = [NewTopic(topic=my_topic_9167024629,num_partitions=3)]\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] __main__: Sent messages: len(sent_msgs)=317\n",
      "started\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "msgs_sent = 317\n",
    "msgs = [f\"Hello world {i:05d}\".encode(\"utf-8\") for i in range(msgs_sent)]\n",
    "\n",
    "async with create_and_fill_testing_topic(msgs, seed=1, **aiokafka_config) as topic:\n",
    "    print(\"started\")\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c37712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39231f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature(create_and_fill_testing_topic).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_and_fill_testing_topic.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c266d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ba5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc99ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391928a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb1cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2424896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fast_kafka_api.helpers: create_missing_topics(['my_topic_9167024629']): new_topics = [NewTopic(topic=my_topic_9167024629,num_partitions=3)]\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> created.\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> started.\n",
      "[INFO] __main__: Sent messages: len(sent_msgs)=317\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'my_topic_9167024629'})\n",
      "[INFO] __main__: Consumer <aiokafka.consumer.consumer.AIOKafkaConsumer object> created.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'my_topic_9167024629': 3}. \n",
      "[INFO] __main__: Consumer <aiokafka.consumer.consumer.AIOKafkaConsumer object> started.\n",
      "Total messages received: 317\n",
      "[INFO] __main__: Consumer <aiokafka.consumer.consumer.AIOKafkaConsumer object> stopped.\n",
      "[INFO] __main__: Producer <aiokafka.producer.producer.AIOKafkaProducer object> stoped.\n"
     ]
    }
   ],
   "source": [
    "msgs_sent = 317\n",
    "msgs = [f\"Hello world {i:05d}\".encode(\"utf-8\") for i in range(msgs_sent)]\n",
    "\n",
    "async with create_and_fill_testing_topic(msgs, seed=1, **aiokafka_config) as topic:\n",
    "    consumer = AIOKafkaConsumer(\n",
    "        topic,\n",
    "        bootstrap_servers=kafka_config[\"bootstrap.servers\"],\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        max_poll_records=100,\n",
    "    )\n",
    "    logger.info(f\"Consumer {consumer} created.\")\n",
    "    await consumer.start()\n",
    "    logger.info(f\"Consumer {consumer} started.\")\n",
    "    is_shutting_down_f = true_after(5)\n",
    "    msgs_received = 0\n",
    "    try:\n",
    "        while True:\n",
    "            msgs = await consumer.getmany(timeout_ms=100)\n",
    "            for k, v in msgs.items():\n",
    "                msgs_received = msgs_received + len(v)\n",
    "            if is_shutting_down_f():\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        assert msgs_received == msgs_sent\n",
    "        print(f\"Total messages received: {msgs_received}\")\n",
    "        await consumer.stop()\n",
    "        logger.info(f\"Consumer {consumer} stopped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853414f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ad4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beae046",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Send repeatedly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f69103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def nb_safe_seed(s: str) -> Callable[[int], int]:\n",
    "    \"\"\"Gets a unique seed function for a notebook\n",
    "\n",
    "    Params:\n",
    "        s: name of the notebook used to initialize the seed function\n",
    "\n",
    "    Returns:\n",
    "        A unique seed function\n",
    "    \"\"\"\n",
    "    init_seed = int(hashlib.sha256(s.encode(\"utf-8\")).hexdigest(), 16) % (10**8)\n",
    "\n",
    "    def _get_seed(x: int = 0, *, init_seed: int = init_seed) -> int:\n",
    "        return init_seed + x\n",
    "\n",
    "    return _get_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = nb_safe_seed(\"999_test_utils\")\n",
    "\n",
    "assert seed() == seed(0)\n",
    "assert seed() + 1 == seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def mock_AIOKafkaProducer_send() -> Generator[unittest.mock.Mock, None, None]:\n",
    "    \"\"\"Mocks **send** method of **AIOKafkaProducer**\"\"\"\n",
    "    with unittest.mock.patch(\"__main__.AIOKafkaProducer.send\") as mock:\n",
    "\n",
    "        async def _f():\n",
    "            pass\n",
    "\n",
    "        mock.return_value = asyncio.create_task(_f())\n",
    "\n",
    "        yield mock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def change_dir(d: str) -> Generator[None, None, None]:\n",
    "    curdir = os.getcwd()\n",
    "    os.chdir(d)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1eac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tests\n",
    "with TemporaryDirectory() as d:\n",
    "    original_wd = os.getcwd()\n",
    "    assert original_wd != d\n",
    "    with change_dir(d):\n",
    "        assert os.getcwd() == d\n",
    "    assert os.getcwd() == original_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a031f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def run_script_and_cancel(\n",
    "    *, script: str, script_file: str, cmd: str, cancel_after: int\n",
    ") -> Tuple[int, bytes]:\n",
    "    with TemporaryDirectory() as d:\n",
    "        consumer_script = Path(d) / script_file\n",
    "\n",
    "        with open(consumer_script, \"a+\") as file:\n",
    "            file.write(script)\n",
    "\n",
    "        # os.chdir(d)\n",
    "        with change_dir(d):\n",
    "            proc = subprocess.Popen(  # nosec: [B603:subprocess_without_shell_equals_true] subprocess call - check for execution of untrusted input.\n",
    "                shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT\n",
    "            )\n",
    "            time.sleep(cancel_after)\n",
    "            proc.terminate()\n",
    "            output, _ = proc.communicate()\n",
    "\n",
    "        return (proc.returncode, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f359e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"python3 -m test.py\"\n",
    "\n",
    "# Check exit code 0\n",
    "script = \"exit(0)\"\n",
    "\n",
    "exit_code, output = run_script_and_cancel(\n",
    "    script=script, script_file=\"test.py\", cmd=cmd, cancel_after=1\n",
    ")\n",
    "\n",
    "assert exit_code == 0\n",
    "assert output.decode(\"utf-8\") == \"\"\n",
    "\n",
    "\n",
    "# Check exit code 1\n",
    "script = \"exit(1)\"\n",
    "\n",
    "exit_code, output = run_script_and_cancel(\n",
    "    script=script, script_file=\"test.py\", cmd=cmd, cancel_after=1\n",
    ")\n",
    "\n",
    "assert exit_code == 1\n",
    "assert output.decode(\"utf-8\") == \"\"\n",
    "\n",
    "\n",
    "# Check exit code 0 and output to stdout and stderr\n",
    "script = \"\"\"\n",
    "import sys\n",
    "sys.stderr.write(\"hello from stderr\\\\n\")\n",
    "sys.stderr.flush()\n",
    "print(\"hello, exiting with exit code 0\")\n",
    "exit(0)\n",
    "\"\"\"\n",
    "\n",
    "exit_code, output = run_script_and_cancel(\n",
    "    script=script, script_file=\"test.py\", cmd=cmd, cancel_after=1\n",
    ")\n",
    "\n",
    "assert exit_code == 0, exit_code\n",
    "assert output.decode(\"utf-8\") == \"hello from stderr\\nhello, exiting with exit code 0\\n\", output.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Check random exit code and output\n",
    "script = \"\"\"\n",
    "print(\"hello\\\\nexiting with exit code 143\")\n",
    "exit(143)\n",
    "\"\"\"\n",
    "\n",
    "exit_code, output = run_script_and_cancel(\n",
    "    script=script, script_file=\"test.py\", cmd=cmd, cancel_after=1\n",
    ")\n",
    "\n",
    "assert exit_code == 143\n",
    "assert output.decode(\"utf-8\") == \"hello\\nexiting with exit code 143\\n\"\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be219d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
