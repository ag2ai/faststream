{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.producer_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "import functools\n",
    "import json\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "\n",
    "import nest_asyncio\n",
    "from aiokafka import AIOKafkaProducer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from fastkafka._components.meta import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from contextlib import asynccontextmanager\n",
    "from unittest.mock import Mock\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from fastkafka._testing.apache_kafka_broker import ApacheKafkaBroker\n",
    "from fastkafka._testing.test_utils import mock_AIOKafkaProducer_send\n",
    "from fastkafka.encoder import avro_encoder, json_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "BaseSubmodel = TypeVar(\"BaseSubmodel\", bound=BaseModel)\n",
    "BaseSubmodel\n",
    "\n",
    "\n",
    "@dataclass\n",
    "@export(\"fastkafka\")\n",
    "class KafkaEvent(Generic[BaseSubmodel]):\n",
    "    \"\"\"\n",
    "    A generic class for representing Kafka events. Based on BaseSubmodel, bound to pydantic.BaseModel\n",
    "\n",
    "    Attributes:\n",
    "        message (BaseSubmodel): The message contained in the Kafka event, can be of type pydantic.BaseModel.\n",
    "        key (bytes, optional): The optional key used to identify the Kafka event.\n",
    "    \"\"\"\n",
    "\n",
    "    message: BaseSubmodel\n",
    "    key: Optional[bytes] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = KafkaEvent(\"Some message\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == None\n",
    "\n",
    "event = KafkaEvent(\"Some message\", b\"123\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d981cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "ProduceReturnTypes = Union[\n",
    "    BaseModel, KafkaEvent[BaseModel], List[BaseModel], KafkaEvent[List[BaseModel]]\n",
    "]\n",
    "\n",
    "ProduceCallable = Union[\n",
    "    Callable[..., ProduceReturnTypes], Callable[..., Awaitable[ProduceReturnTypes]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | export\n",
    "\n",
    "\n",
    "# def _to_json_utf8(o: Any) -> bytes:\n",
    "#     \"\"\"Converts to JSON and then encodes with UTF-8\"\"\"\n",
    "#     if hasattr(o, \"json\"):\n",
    "#         return o.json().encode(\"utf-8\")  # type: ignore\n",
    "#     else:\n",
    "#         return json.dumps(o).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert _to_json_utf8({\"a\": 1, \"b\": [2, 3]}) == b'{\"a\": 1, \"b\": [2, 3]}'\n",
    "\n",
    "\n",
    "class A(BaseModel):\n",
    "    name: str = Field()\n",
    "    age: int\n",
    "\n",
    "\n",
    "# assert _to_json_utf8(A(name=\"Davor\", age=12)) == b'{\"name\": \"Davor\", \"age\": 12}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _wrap_in_event(message: Union[BaseModel, KafkaEvent]) -> KafkaEvent:\n",
    "    return message if type(message) == KafkaEvent else KafkaEvent(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cab521",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = A(name=\"Davor\", age=12)\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message\n",
    "assert wrapped.key == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = KafkaEvent(A(name=\"Davor\", age=12), b\"123\")\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message.message\n",
    "assert wrapped.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1950038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_loop() -> asyncio.AbstractEventLoop:\n",
    "    try:\n",
    "        loop: asyncio.AbstractEventLoop = asyncio.get_event_loop()\n",
    "    except RuntimeError as e:\n",
    "        loop = asyncio.new_event_loop()\n",
    "\n",
    "    if loop.is_running():\n",
    "        nest_asyncio.apply(loop)\n",
    "\n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01201b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = get_loop()\n",
    "\n",
    "assert isinstance(loop, asyncio.AbstractEventLoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def release_callback(fut: asyncio.Future) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def produce_single(\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[BaseModel],\n",
    ") -> ProduceReturnTypes:\n",
    "    fut = await producer.send(\n",
    "        topic, encoder_fn(wrapped_val.message), key=wrapped_val.key\n",
    "    )\n",
    "    fut.add_done_callback(release_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_single(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=A(name=\"Davor\", age=12), key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def send_batch(producer, topic, batch, key):\n",
    "    partitions = await producer.partitions_for(topic)\n",
    "    if key == None:\n",
    "        partition = random.choice(tuple(partitions))\n",
    "    else:\n",
    "        partition = producer._partition(topic, None, None, None, key, None)\n",
    "    await producer.send_batch(batch, topic, partition=partition)\n",
    "\n",
    "\n",
    "async def produce_batch(\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[List[BaseModel]],\n",
    ") -> ProduceReturnTypes:\n",
    "    batch = producer.create_batch()\n",
    "\n",
    "    for message in wrapped_val.message:\n",
    "        metadata = batch.append(\n",
    "            key=wrapped_val.key, value=encoder_fn(message), timestamp=None\n",
    "        )\n",
    "        if metadata == None:\n",
    "            # send batch\n",
    "            await send_batch(producer, topic, batch, wrapped_val.key)\n",
    "            # create new batch\n",
    "            batch = producer.create_batch()\n",
    "            batch.append(key=None, value=encoder_fn(message), timestamp=None)\n",
    "    \n",
    "    await send_batch(producer, topic, batch, wrapped_val.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [A(name=\"Davor\", age=12) for _ in range(500)]\n",
    "\n",
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_batch(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=msgs, key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f60d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def producer_decorator(\n",
    "    producer_store: Dict[str, Any],\n",
    "    func: ProduceCallable,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    ") -> ProduceCallable:\n",
    "    \"\"\"todo: write documentation\"\"\"\n",
    "\n",
    "    loop = get_loop()\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    async def _produce_async(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., Awaitable[ProduceReturnTypes]] = func,  # type: ignore\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = await f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            await produce_batch(producer, wrapped_val)\n",
    "        else:\n",
    "            await produce_single(producer, wrapped_val)\n",
    "        return return_val\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def _produce_sync(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., ProduceReturnTypes] = func,  # type: ignore\n",
    "        loop: asyncio.AbstractEventLoop = loop,\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            loop.run_until_complete(\n",
    "                produce_batch(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        else:\n",
    "            loop.run_until_complete(\n",
    "                produce_single(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        return return_val\n",
    "\n",
    "    return _produce_async if iscoroutinefunction(func) else _produce_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76940b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockMsg(BaseModel):\n",
    "    name: str = \"Micky Mouse\"\n",
    "    id: int = 123\n",
    "\n",
    "\n",
    "mock_msg = MockMsg()\n",
    "\n",
    "topic = \"test_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def mock_producer_env(\n",
    "    is_sync: bool,\n",
    ") -> AsyncGenerator[Tuple[Mock, AIOKafkaProducer], None]:\n",
    "    try:\n",
    "        with mock_AIOKafkaProducer_send() as send_mock:\n",
    "            async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "                producer = AIOKafkaProducer(bootstrap_servers=bootstrap_server)\n",
    "                await producer.start()\n",
    "                yield send_mock, producer\n",
    "    finally:\n",
    "        await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def func(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=json_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, mock_msg.json().encode(\"utf-8\"), key=None)\n",
    "\n",
    "    assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with avro_encoder\n",
    "async def func(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=avro_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, avro_encoder(mock_msg), key=None)\n",
    "\n",
    "    assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795635f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=True) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=json_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == False\n",
    "\n",
    "    value = test_func(mock_msg)\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, mock_msg.json().encode(\"utf-8\"), key=None)\n",
    "\n",
    "    assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with avro_encoder\n",
    "def func(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=True) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=avro_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == False\n",
    "\n",
    "    value = test_func(mock_msg)\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, avro_encoder(mock_msg), key=None)\n",
    "\n",
    "    assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359e2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_key = b\"some_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def func(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, key=test_key)\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=json_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(\n",
    "        topic, mock_msg.json().encode(\"utf-8\"), key=test_key\n",
    "    )\n",
    "\n",
    "    assert value == KafkaEvent(mock_msg, key=test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with avro_encoder\n",
    "\n",
    "\n",
    "async def func(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, key=test_key)\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=avro_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, avro_encoder(mock_msg), key=test_key)\n",
    "\n",
    "    assert value == KafkaEvent(mock_msg, key=test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def func(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, key=test_key)\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=json_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(\n",
    "        topic, mock_msg.json().encode(\"utf-8\"), key=test_key\n",
    "    )\n",
    "\n",
    "    assert value == KafkaEvent(mock_msg, key=test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with avro_encoder\n",
    "\n",
    "\n",
    "async def func(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, key=test_key)\n",
    "\n",
    "\n",
    "async with mock_producer_env(is_sync=False) as (send_mock, producer):\n",
    "    test_func = producer_decorator(\n",
    "        {topic: (None, producer, None)}, func, topic, encoder_fn=avro_encoder\n",
    "    )\n",
    "\n",
    "    assert iscoroutinefunction(test_func) == True\n",
    "\n",
    "    value = await test_func(mock_msg)\n",
    "\n",
    "    send_mock.assert_called_once_with(topic, avro_encoder(mock_msg), key=test_key)\n",
    "\n",
    "    assert value == KafkaEvent(mock_msg, key=test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_async [True, False], encoder [json_encoder, avro_encoder], key [None, b\"some_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e77fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for is_async, encoder, key in zip(\n",
    "    [True, False], [json_encoder, avro_encoder], [None, b\"some_key\"]\n",
    "):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
