{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.producer_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import random\n",
    "import asyncio\n",
    "import functools\n",
    "import json\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "\n",
    "import nest_asyncio\n",
    "from aiokafka import AIOKafkaProducer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from fastkafka._components.meta import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from contextlib import asynccontextmanager\n",
    "import unittest\n",
    "from unittest.mock import Mock\n",
    "from itertools import product\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from fastkafka._testing.apache_kafka_broker import ApacheKafkaBroker\n",
    "from fastkafka._testing.test_utils import mock_AIOKafkaProducer_send\n",
    "from fastkafka.encoder import avro_encoder, json_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "BaseSubmodel = TypeVar(\"BaseSubmodel\", bound=BaseModel)\n",
    "BaseSubmodel\n",
    "\n",
    "\n",
    "@dataclass\n",
    "@export(\"fastkafka\")\n",
    "class KafkaEvent(Generic[BaseSubmodel]):\n",
    "    \"\"\"\n",
    "    A generic class for representing Kafka events. Based on BaseSubmodel, bound to pydantic.BaseModel\n",
    "\n",
    "    Attributes:\n",
    "        message (BaseSubmodel): The message contained in the Kafka event, can be of type pydantic.BaseModel.\n",
    "        key (bytes, optional): The optional key used to identify the Kafka event.\n",
    "    \"\"\"\n",
    "\n",
    "    message: BaseSubmodel\n",
    "    key: Optional[bytes] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = KafkaEvent(\"Some message\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == None\n",
    "\n",
    "event = KafkaEvent(\"Some message\", b\"123\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d981cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "ProduceReturnTypes = Union[\n",
    "    BaseModel, KafkaEvent[BaseModel], List[BaseModel], KafkaEvent[List[BaseModel]]\n",
    "]\n",
    "\n",
    "ProduceCallable = Union[\n",
    "    Callable[..., ProduceReturnTypes], Callable[..., Awaitable[ProduceReturnTypes]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | export\n",
    "\n",
    "\n",
    "# def _to_json_utf8(o: Any) -> bytes:\n",
    "#     \"\"\"Converts to JSON and then encodes with UTF-8\"\"\"\n",
    "#     if hasattr(o, \"json\"):\n",
    "#         return o.json().encode(\"utf-8\")  # type: ignore\n",
    "#     else:\n",
    "#         return json.dumps(o).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert _to_json_utf8({\"a\": 1, \"b\": [2, 3]}) == b'{\"a\": 1, \"b\": [2, 3]}'\n",
    "\n",
    "\n",
    "class A(BaseModel):\n",
    "    name: str = Field()\n",
    "    age: int\n",
    "\n",
    "\n",
    "# assert _to_json_utf8(A(name=\"Davor\", age=12)) == b'{\"name\": \"Davor\", \"age\": 12}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _wrap_in_event(message: Union[BaseModel, KafkaEvent]) -> KafkaEvent:\n",
    "    return message if type(message) == KafkaEvent else KafkaEvent(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cab521",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = A(name=\"Davor\", age=12)\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message\n",
    "assert wrapped.key == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = KafkaEvent(A(name=\"Davor\", age=12), b\"123\")\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message.message\n",
    "assert wrapped.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1950038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_loop() -> asyncio.AbstractEventLoop:\n",
    "    try:\n",
    "        loop: asyncio.AbstractEventLoop = asyncio.get_event_loop()\n",
    "    except RuntimeError as e:\n",
    "        loop = asyncio.new_event_loop()\n",
    "\n",
    "    if loop.is_running():\n",
    "        nest_asyncio.apply(loop)\n",
    "\n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01201b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = get_loop()\n",
    "\n",
    "assert isinstance(loop, asyncio.AbstractEventLoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def release_callback(fut: asyncio.Future) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def produce_single(\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[BaseModel],\n",
    ") -> ProduceReturnTypes:\n",
    "    fut = await producer.send(\n",
    "        topic, encoder_fn(wrapped_val.message), key=wrapped_val.key\n",
    "    )\n",
    "    fut.add_done_callback(release_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb54e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 1563...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 1563 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 1183...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 1183 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_single(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=A(name=\"Davor\", age=12), key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def send_batch(producer, topic, batch, key):\n",
    "    partitions = await producer.partitions_for(topic)\n",
    "    if key == None:\n",
    "        partition = random.choice(tuple(partitions))\n",
    "    else:\n",
    "        partition = producer._partition(topic, None, None, None, key, None)\n",
    "    await producer.send_batch(batch, topic, partition=partition)\n",
    "\n",
    "\n",
    "async def produce_batch(\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[List[BaseModel]],\n",
    ") -> ProduceReturnTypes:\n",
    "    batch = producer.create_batch()\n",
    "\n",
    "    for message in wrapped_val.message:\n",
    "        metadata = batch.append(\n",
    "            key=wrapped_val.key, value=encoder_fn(message), timestamp=None\n",
    "        )\n",
    "        if metadata == None:\n",
    "            # send batch\n",
    "            await send_batch(producer, topic, batch, wrapped_val.key)\n",
    "            # create new batch\n",
    "            batch = producer.create_batch()\n",
    "            batch.append(key=None, value=encoder_fn(message), timestamp=None)\n",
    "    \n",
    "    await send_batch(producer, topic, batch, wrapped_val.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 2935...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 2935 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 2556...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 2556 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "msgs = [A(name=\"Davor\", age=12) for _ in range(500)]\n",
    "\n",
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_batch(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=msgs, key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f60d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def producer_decorator(\n",
    "    producer_store: Dict[str, Any],\n",
    "    func: ProduceCallable,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    ") -> ProduceCallable:\n",
    "    \"\"\"todo: write documentation\"\"\"\n",
    "\n",
    "    loop = get_loop()\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    async def _produce_async(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., Awaitable[ProduceReturnTypes]] = func,  # type: ignore\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = await f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            await produce_batch(producer, topic, encoder_fn, wrapped_val)\n",
    "        else:\n",
    "            await produce_single(producer, topic, encoder_fn, wrapped_val)\n",
    "        return return_val\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def _produce_sync(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., ProduceReturnTypes] = func,  # type: ignore\n",
    "        loop: asyncio.AbstractEventLoop = loop,\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            loop.run_until_complete(\n",
    "                produce_batch(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        else:\n",
    "            loop.run_until_complete(\n",
    "                produce_single(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        return return_val\n",
    "\n",
    "    return _produce_async if iscoroutinefunction(func) else _produce_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76940b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockMsg(BaseModel):\n",
    "    name: str = \"Micky Mouse\"\n",
    "    id: int = 123\n",
    "\n",
    "\n",
    "mock_msg = MockMsg()\n",
    "\n",
    "topic = \"test_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def mock_producer_env(\n",
    "    is_sync: bool,\n",
    ") -> AsyncGenerator[Tuple[Mock, AIOKafkaProducer], None]:\n",
    "    try:\n",
    "        with mock_AIOKafkaProducer_send() as send_mock, unittest.mock.patch(\n",
    "            \"__main__.AIOKafkaProducer.send_batch\"\n",
    "        ) as send_batch_mock, unittest.mock.patch(\n",
    "            \"__main__.AIOKafkaProducer.create_batch\"\n",
    "        ) as create_batch_mock:\n",
    "            batch_mock = Mock()\n",
    "            create_batch_mock.return_value = batch_mock\n",
    "            async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "                producer = AIOKafkaProducer(bootstrap_servers=bootstrap_server)\n",
    "                await producer.start()\n",
    "                yield send_mock, batch_mock, send_batch_mock, producer\n",
    "    finally:\n",
    "        await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e77fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 47692...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 47692 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 47313...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 47313 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 49043...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 49043 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 48664...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 48664 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 50399...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 50399 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 50019...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 50019 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 51750...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 51750 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 51372...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 51372 terminated.\n"
     ]
    }
   ],
   "source": [
    "async def func_async(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_env(is_sync=is_sync) as (send_mock, _, _, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        send_mock.assert_called_once_with(topic, encoder_fn(mock_msg), key=None)\n",
    "\n",
    "        assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 40916...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 40916 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 40537...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 40537 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 42271...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 42271 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 41892...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 41892 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 43628...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 43628 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 43248...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 43248 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 44980...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 44980 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 44601...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 44601 terminated.\n"
     ]
    }
   ],
   "source": [
    "test_key = b\"key\"\n",
    "\n",
    "async def func_async(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, test_key)\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, test_key)\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_env(is_sync=is_sync) as (send_mock, _, _, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        send_mock.assert_called_once_with(topic, encoder_fn(mock_msg), key=test_key)\n",
    "\n",
    "        assert value == KafkaEvent(mock_msg, test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df14a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 58524...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 58524 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 58145...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 58145 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 59878...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 59878 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 59499...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 59499 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 61230...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 61230 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 60851...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 60851 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 62581...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 62581 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 62202...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 62202 terminated.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 123\n",
    "\n",
    "async def func_async(mock_msg: MockMsg) -> List[MockMsg]:\n",
    "    return [mock_msg]*batch_size\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> List[MockMsg]:\n",
    "    return [mock_msg]*batch_size\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_env(is_sync=is_sync) as (_, batch_mock, send_batch_mock, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        send_batch_mock.assert_called_once_with(batch_mock, topic, partition=0)\n",
    "\n",
    "        assert value == [mock_msg]*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb344fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
