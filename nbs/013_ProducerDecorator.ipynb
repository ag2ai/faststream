{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.producer_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import random\n",
    "import asyncio\n",
    "import functools\n",
    "import json\n",
    "import time\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "from typing import *\n",
    "\n",
    "import nest_asyncio\n",
    "from aiokafka import AIOKafkaProducer\n",
    "from aiokafka.producer.message_accumulator import BatchBuilder\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from fastkafka._components.meta import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from contextlib import asynccontextmanager\n",
    "import unittest\n",
    "from unittest.mock import Mock, call, ANY\n",
    "from itertools import product\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from fastkafka._testing.apache_kafka_broker import ApacheKafkaBroker\n",
    "from fastkafka._testing.test_utils import mock_AIOKafkaProducer_send\n",
    "from fastkafka.encoder import avro_encoder, json_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b4e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "BaseSubmodel = TypeVar(\"BaseSubmodel\", bound=Union[List[BaseModel], BaseModel])\n",
    "BaseSubmodel\n",
    "\n",
    "\n",
    "@dataclass\n",
    "@export(\"fastkafka\")\n",
    "class KafkaEvent(Generic[BaseSubmodel]):\n",
    "    \"\"\"\n",
    "    A generic class for representing Kafka events. Based on BaseSubmodel, bound to pydantic.BaseModel\n",
    "\n",
    "    Attributes:\n",
    "        message (BaseSubmodel): The message contained in the Kafka event, can be of type pydantic.BaseModel.\n",
    "        key (bytes, optional): The optional key used to identify the Kafka event.\n",
    "    \"\"\"\n",
    "\n",
    "    message: BaseSubmodel\n",
    "    key: Optional[bytes] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = KafkaEvent(\"Some message\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == None\n",
    "\n",
    "event = KafkaEvent(\"Some message\", b\"123\")\n",
    "assert event.message == \"Some message\"\n",
    "assert event.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d981cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "ProduceReturnTypes = Union[\n",
    "    BaseModel, KafkaEvent[BaseModel], List[BaseModel], KafkaEvent[List[BaseModel]]\n",
    "]\n",
    "\n",
    "ProduceCallable = Union[\n",
    "    Callable[..., ProduceReturnTypes], Callable[..., Awaitable[ProduceReturnTypes]]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | export\n",
    "\n",
    "\n",
    "# def _to_json_utf8(o: Any) -> bytes:\n",
    "#     \"\"\"Converts to JSON and then encodes with UTF-8\"\"\"\n",
    "#     if hasattr(o, \"json\"):\n",
    "#         return o.json().encode(\"utf-8\")  # type: ignore\n",
    "#     else:\n",
    "#         return json.dumps(o).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd6af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert _to_json_utf8({\"a\": 1, \"b\": [2, 3]}) == b'{\"a\": 1, \"b\": [2, 3]}'\n",
    "\n",
    "\n",
    "class A(BaseModel):\n",
    "    name: str = Field()\n",
    "    age: int\n",
    "\n",
    "\n",
    "# assert _to_json_utf8(A(name=\"Davor\", age=12)) == b'{\"name\": \"Davor\", \"age\": 12}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _wrap_in_event(message: Union[BaseModel, List[BaseModel], KafkaEvent]) -> KafkaEvent:\n",
    "    return message if type(message) == KafkaEvent else KafkaEvent(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cab521",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = A(name=\"Davor\", age=12)\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message\n",
    "assert wrapped.key == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = KafkaEvent(A(name=\"Davor\", age=12), b\"123\")\n",
    "wrapped = _wrap_in_event(message)\n",
    "\n",
    "assert type(wrapped) == KafkaEvent\n",
    "assert wrapped.message == message.message\n",
    "assert wrapped.key == b\"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1950038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_loop() -> asyncio.AbstractEventLoop:\n",
    "    try:\n",
    "        loop: asyncio.AbstractEventLoop = asyncio.get_event_loop()\n",
    "    except RuntimeError as e:\n",
    "        loop = asyncio.new_event_loop()\n",
    "\n",
    "    if loop.is_running():\n",
    "        nest_asyncio.apply(loop)\n",
    "\n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01201b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = get_loop()\n",
    "\n",
    "assert isinstance(loop, asyncio.AbstractEventLoop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def release_callback(fut: asyncio.Future) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def produce_single( # type: ignore\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[BaseModel],\n",
    ") -> ProduceReturnTypes:\n",
    "    fut = await producer.send(\n",
    "        topic, encoder_fn(wrapped_val.message), key=wrapped_val.key\n",
    "    )\n",
    "    fut.add_done_callback(release_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb54e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 299567...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 299567 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 299207...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 299207 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_single(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=A(name=\"Davor\", age=12), key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def send_batch(  # type: ignore\n",
    "    producer: AIOKafkaProducer, topic: str, batch: BatchBuilder, key: Optional[bytes]\n",
    ") -> None:\n",
    "    partitions = await producer.partitions_for(topic)\n",
    "    if key == None:\n",
    "        partition = random.choice(tuple(partitions)) #nosec\n",
    "    else:\n",
    "        partition = producer._partition(topic, None, None, None, key, None)\n",
    "    await producer.send_batch(batch, topic, partition=partition)\n",
    "\n",
    "\n",
    "async def produce_batch(  # type: ignore\n",
    "    producer: AIOKafkaProducer,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    "    wrapped_val: KafkaEvent[List[BaseModel]],\n",
    ") -> ProduceReturnTypes:\n",
    "    batch = producer.create_batch()\n",
    "\n",
    "    for message in wrapped_val.message:\n",
    "        metadata = batch.append(\n",
    "            key=wrapped_val.key,\n",
    "            value=encoder_fn(message),\n",
    "            timestamp=int(time.time() * 1000),\n",
    "        )\n",
    "        if metadata == None:\n",
    "            # send batch\n",
    "            await send_batch(producer, topic, batch, wrapped_val.key)\n",
    "            # create new batch\n",
    "            batch = producer.create_batch()\n",
    "            batch.append(\n",
    "                key=None, value=encoder_fn(message), timestamp=int(time.time() * 1000)\n",
    "            )\n",
    "\n",
    "    await send_batch(producer, topic, batch, wrapped_val.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b2b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): entering...\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): (<_UnixSelectorEventLoop running=True closed=False debug=False>) is already running!\n",
      "[WARNING] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): calling nest_asyncio.apply()\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: <class 'fastkafka.testing.ApacheKafkaBroker'>.start(): returning 127.0.0.1:9092\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.start(): exited.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): entering...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 110151...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 110151 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 109791...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 109791 terminated.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: ApacheKafkaBroker.stop(): exited.\n"
     ]
    }
   ],
   "source": [
    "msgs = [A(name=\"Davor\", age=12) for _ in range(500)]\n",
    "\n",
    "with ApacheKafkaBroker(topics=[\"test_topic\"], apply_nest_asyncio=True) as broker:\n",
    "    producer = AIOKafkaProducer(bootstrap_servers=broker)\n",
    "    await producer.start()\n",
    "\n",
    "    await produce_batch(\n",
    "        producer,\n",
    "        topic=\"test_topic\",\n",
    "        encoder_fn=json_encoder,\n",
    "        wrapped_val=KafkaEvent(message=msgs, key=b\"test\"),\n",
    "    )\n",
    "    \n",
    "    await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f60d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def producer_decorator(\n",
    "    producer_store: Dict[str, Any],\n",
    "    func: ProduceCallable,\n",
    "    topic: str,\n",
    "    encoder_fn: Callable[[BaseModel], bytes],\n",
    ") -> ProduceCallable:\n",
    "    \"\"\"todo: write documentation\"\"\"\n",
    "\n",
    "    loop = get_loop()\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    async def _produce_async(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., Awaitable[ProduceReturnTypes]] = func,  # type: ignore\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = await f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            await produce_batch(producer, topic, encoder_fn, wrapped_val)\n",
    "        else:\n",
    "            await produce_single(producer, topic, encoder_fn, wrapped_val)\n",
    "        return return_val\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def _produce_sync(\n",
    "        *args: List[Any],\n",
    "        topic: str = topic,\n",
    "        encoder_fn: Callable[[BaseModel], bytes] = encoder_fn,\n",
    "        producer_store: Dict[str, Any] = producer_store,\n",
    "        f: Callable[..., ProduceReturnTypes] = func,  # type: ignore\n",
    "        loop: asyncio.AbstractEventLoop = loop,\n",
    "        **kwargs: Any\n",
    "    ) -> ProduceReturnTypes:\n",
    "        return_val = f(*args, **kwargs)\n",
    "        wrapped_val = _wrap_in_event(return_val)\n",
    "        _, producer, _ = producer_store[topic]\n",
    "        if isinstance(wrapped_val.message, list):\n",
    "            loop.run_until_complete(\n",
    "                produce_batch(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        else:\n",
    "            loop.run_until_complete(\n",
    "                produce_single(producer, topic, encoder_fn, wrapped_val)\n",
    "            )\n",
    "        return return_val\n",
    "\n",
    "    return _produce_async if iscoroutinefunction(func) else _produce_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76940b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockMsg(BaseModel):\n",
    "    name: str = \"Micky Mouse\"\n",
    "    id: int = 123\n",
    "\n",
    "\n",
    "mock_msg = MockMsg()\n",
    "\n",
    "topic = \"test_topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def mock_producer_send_env() -> AsyncGenerator[\n",
    "    Tuple[Mock, AIOKafkaProducer], None\n",
    "]:\n",
    "    try:\n",
    "        with mock_AIOKafkaProducer_send() as send_mock:\n",
    "            async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "                producer = AIOKafkaProducer(bootstrap_servers=bootstrap_server)\n",
    "                await producer.start()\n",
    "                yield send_mock, producer\n",
    "    finally:\n",
    "        await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e06f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@asynccontextmanager\n",
    "async def mock_producer_batch_env() -> AsyncGenerator[\n",
    "    Tuple[Mock, AIOKafkaProducer], None\n",
    "]:\n",
    "    try:\n",
    "        with unittest.mock.patch(\n",
    "            \"__main__.AIOKafkaProducer.send_batch\"\n",
    "        ) as send_batch_mock, unittest.mock.patch(\n",
    "            \"__main__.AIOKafkaProducer.create_batch\"\n",
    "        ) as create_batch_mock:\n",
    "            batch_mock = Mock()\n",
    "            create_batch_mock.return_value = batch_mock\n",
    "            async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "                producer = AIOKafkaProducer(bootstrap_servers=bootstrap_server)\n",
    "                await producer.start()\n",
    "                yield batch_mock, send_batch_mock, producer\n",
    "    finally:\n",
    "        await producer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e77fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 111291...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 111291 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 110930...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 110930 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 112462...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 112462 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 112098...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 112098 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "stdout=, stderr=, returncode=1\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: kafka startup falied, generating a new port and retrying...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: port=43361\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:43361\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 115132...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 115132 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 113754...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 113754 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 117403...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 117403 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 117001...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 117001 terminated.\n"
     ]
    }
   ],
   "source": [
    "async def func_async(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> MockMsg:\n",
    "    return mock_msg\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_send_env() as (send_mock, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        send_mock.assert_called_once_with(topic, encoder_fn(mock_msg), key=None)\n",
    "\n",
    "        assert value == mock_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec5c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 119700...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 119700 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 119302...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 119302 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 121993...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 121993 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 121615...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 121615 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 124294...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 124294 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 123920...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 123920 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "stdout=, stderr=, returncode=1\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: kafka startup falied, generating a new port and retrying...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: port=57781\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:57781\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 126963...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 126963 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 126211...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 126211 terminated.\n"
     ]
    }
   ],
   "source": [
    "test_key = b\"key\"\n",
    "\n",
    "async def func_async(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, test_key)\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> KafkaEvent[MockMsg]:\n",
    "    return KafkaEvent(mock_msg, test_key)\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_send_env() as (send_mock, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        send_mock.assert_called_once_with(topic, encoder_fn(mock_msg), key=test_key)\n",
    "\n",
    "        assert value == KafkaEvent(mock_msg, test_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df14a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 129249...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 129249 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 128874...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 128874 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 130424...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 130424 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 130064...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 130064 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 132306...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 132306 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 131602...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 131602 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 134900...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 134900 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 134537...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 134537 terminated.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 123\n",
    "\n",
    "\n",
    "async def func_async(mock_msg: MockMsg) -> List[MockMsg]:\n",
    "    return [mock_msg] * batch_size\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> List[MockMsg]:\n",
    "    return [mock_msg] * batch_size\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_batch_env() as (\n",
    "        batch_mock,\n",
    "        send_batch_mock,\n",
    "        producer,\n",
    "    ):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        batch_mock.append.assert_has_calls(\n",
    "            [call(key=None, value=encoder_fn(mock_msg), timestamp=ANY)] * batch_size\n",
    "        )\n",
    "        send_batch_mock.assert_called_once_with(batch_mock, topic, partition=0)\n",
    "\n",
    "        assert value == [mock_msg] * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb344fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: is_sync=True , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 136055...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 136055 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 135694...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 135694 terminated.\n",
      "Testing with: is_sync=True , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 137195...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 137195 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 136835...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 136835 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function json_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 139803...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 139803 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 139435...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 139435 terminated.\n",
      "Testing with: is_sync=False , encoder_fn=<function avro_encoder>\n",
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 140961...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 140961 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 140599...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 140599 terminated.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 123\n",
    "test_key = b\"key\"\n",
    "\n",
    "\n",
    "async def func_async(mock_msg: MockMsg) -> KafkaEvent[List[MockMsg]]:\n",
    "    return KafkaEvent([mock_msg] * batch_size, test_key)\n",
    "\n",
    "\n",
    "def func_sync(mock_msg: MockMsg) -> KafkaEvent[List[MockMsg]]:\n",
    "    return KafkaEvent([mock_msg] * batch_size, test_key)\n",
    "\n",
    "\n",
    "for is_sync, encoder_fn in product([True, False], [json_encoder, avro_encoder]):\n",
    "    print(f\"Testing with: {is_sync=} , {encoder_fn=}\")\n",
    "    async with mock_producer_batch_env() as (batch_mock, send_batch_mock, producer):\n",
    "        test_func = producer_decorator(\n",
    "            {topic: (None, producer, None)},\n",
    "            func_sync if is_sync else func_async,\n",
    "            topic,\n",
    "            encoder_fn=encoder_fn,\n",
    "        )\n",
    "\n",
    "        assert iscoroutinefunction(test_func) != is_sync\n",
    "\n",
    "        value = test_func(mock_msg) if is_sync else await test_func(mock_msg)\n",
    "\n",
    "        batch_mock.append.assert_has_calls(\n",
    "            [call(key=test_key, value=encoder_fn(mock_msg), timestamp=ANY)] * batch_size\n",
    "        )\n",
    "\n",
    "        send_batch_mock.assert_called_once_with(batch_mock, topic, partition=0)\n",
    "\n",
    "        assert value == KafkaEvent([mock_msg] * batch_size, test_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
