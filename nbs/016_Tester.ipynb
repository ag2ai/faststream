{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609bc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _application.tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72449ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import asyncio\n",
    "import collections\n",
    "import inspect\n",
    "from unittest.mock import AsyncMock, MagicMock\n",
    "import json\n",
    "from contextlib import asynccontextmanager\n",
    "from itertools import groupby\n",
    "from typing import *\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from fastkafka import KafkaEvent\n",
    "from fastkafka._application.app import FastKafka, AwaitedMock, _get_kafka_brokers\n",
    "from fastkafka._components.asyncapi import KafkaBroker, KafkaBrokers\n",
    "from fastkafka._components.helpers import unwrap_list_type\n",
    "from fastkafka._components.meta import delegates, export, patch\n",
    "from fastkafka._components.producer_decorator import unwrap_from_kafka_event\n",
    "from fastkafka._testing.apache_kafka_broker import ApacheKafkaBroker\n",
    "from fastkafka._testing.in_memory_broker import InMemoryBroker\n",
    "from fastkafka._testing.local_redpanda_broker import LocalRedpandaBroker\n",
    "from fastkafka._components.helpers import remove_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee08fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from pydantic import Field\n",
    "\n",
    "from fastkafka import EventMetadata\n",
    "from fastkafka._components.logger import get_logger, supress_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d75f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14650b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83484244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca915b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _get_broker_spec(bootstrap_server: str) -> KafkaBroker:\n",
    "    url = bootstrap_server.split(\":\")[0]\n",
    "    port = bootstrap_server.split(\":\")[1]\n",
    "    return KafkaBroker(url=url, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ff67b",
   "metadata": {},
   "source": [
    "## Fastkafka Tester class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@export(\"fastkafka.testing\")\n",
    "class Tester(FastKafka):\n",
    "    __test__ = False\n",
    "\n",
    "    @delegates(ApacheKafkaBroker.__init__)\n",
    "    def __init__(\n",
    "        self,\n",
    "        app: Union[FastKafka, List[FastKafka]],\n",
    "        *,\n",
    "        broker: Optional[\n",
    "            Union[ApacheKafkaBroker, LocalRedpandaBroker, InMemoryBroker]\n",
    "        ] = None,\n",
    "    ):\n",
    "        \"\"\"Mirror-like object for testing a FastFafka application\n",
    "\n",
    "        Can be used as context manager\n",
    "\n",
    "        \"\"\"\n",
    "        self.apps = app if isinstance(app, list) else [app]\n",
    "\n",
    "        for app in self.apps:\n",
    "            app.create_mocks()\n",
    "        \n",
    "        super().__init__()\n",
    "        self.mirrors: Dict[Any, Any] = {}\n",
    "        self.create_mirrors()\n",
    "        self.create_mocks()\n",
    "        self.arrange_mirrors()\n",
    "        self.broker = broker\n",
    "        \n",
    "        unique_broker_configs = []\n",
    "        for app in self.apps:\n",
    "            for broker_config in app._override_brokers:\n",
    "                if broker_config not in unique_broker_configs:\n",
    "                    unique_broker_configs.append(broker_config)\n",
    "        self.num_brokers = len(unique_broker_configs)\n",
    "        \n",
    "        self.overriden_brokers: List[Union[ApacheKafkaBroker, LocalRedpandaBroker]] = []\n",
    "\n",
    "    @delegates(LocalRedpandaBroker.__init__)\n",
    "    def using_local_redpanda(self, **kwargs: Any) -> \"Tester\":\n",
    "        \"\"\"Starts local Redpanda broker used by the Tester instance\n",
    "\n",
    "        Args:\n",
    "            listener_port: Port on which the clients (producers and consumers) can connect\n",
    "            tag: Tag of Redpanda image to use to start container\n",
    "            seastar_core: Core(s) to use byt Seastar (the framework Redpanda uses under the hood)\n",
    "            memory: The amount of memory to make available to Redpanda\n",
    "            mode: Mode to use to load configuration properties in container\n",
    "            default_log_level: Log levels to use for Redpanda\n",
    "            topics: List of topics to create after sucessfull redpanda broker startup\n",
    "            retries: Number of retries to create redpanda service\n",
    "            apply_nest_asyncio: set to True if running in notebook\n",
    "            port allocation if the requested port was taken\n",
    "\n",
    "        Returns:\n",
    "            An instance of tester with Redpanda as broker\n",
    "        \"\"\"\n",
    "        topics = set().union(*(app.get_topics() for app in self.apps))\n",
    "        kwargs[\"topics\"] = (\n",
    "            topics.union(kwargs[\"topics\"]) if \"topics\" in kwargs else topics\n",
    "        )\n",
    "        self.broker = LocalRedpandaBroker(**kwargs)\n",
    "        self.overriden_brokers = [\n",
    "            LocalRedpandaBroker(**kwargs) for _ in range(self.num_brokers)\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    @delegates(ApacheKafkaBroker.__init__)\n",
    "    def using_local_kafka(self, **kwargs: Any) -> \"Tester\":\n",
    "        \"\"\"Starts local Kafka broker used by the Tester instance\n",
    "\n",
    "        Args:\n",
    "            data_dir: Path to the directory where the zookeepeer instance will save data\n",
    "            zookeeper_port: Port for clients (Kafka brokes) to connect\n",
    "            listener_port: Port on which the clients (producers and consumers) can connect\n",
    "            topics: List of topics to create after sucessfull Kafka broker startup\n",
    "            retries: Number of retries to create kafka and zookeeper services using random\n",
    "            apply_nest_asyncio: set to True if running in notebook\n",
    "            port allocation if the requested port was taken\n",
    "\n",
    "        Returns:\n",
    "            An instance of tester with Kafka as broker\n",
    "        \"\"\"\n",
    "        topics = set().union(*(app.get_topics() for app in self.apps))\n",
    "        kwargs[\"topics\"] = (\n",
    "            topics.union(kwargs[\"topics\"]) if \"topics\" in kwargs else topics\n",
    "        )\n",
    "        self.broker = ApacheKafkaBroker(**kwargs)\n",
    "        self.overriden_brokers = [\n",
    "            ApacheKafkaBroker(**kwargs) for _ in range(self.num_brokers)\n",
    "        ]\n",
    "\n",
    "        return self\n",
    "\n",
    "    async def _start_tester(self) -> None:\n",
    "        \"\"\"Starts the Tester\"\"\"\n",
    "        for app in self.apps:\n",
    "            await app.__aenter__()\n",
    "        await super().__aenter__()\n",
    "        await asyncio.sleep(3)\n",
    "\n",
    "    async def _stop_tester(self) -> None:\n",
    "        \"\"\"Shuts down the Tester\"\"\"\n",
    "        await super().__aexit__(None, None, None)\n",
    "        for app in self.apps[::-1]:\n",
    "            await app.__aexit__(None, None, None)\n",
    "\n",
    "    def create_mirrors(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def arrange_mirrors(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @asynccontextmanager\n",
    "    async def _create_ctx(self) -> AsyncGenerator[\"Tester\", None]:\n",
    "        if self.broker is None:\n",
    "            topics = set().union(*(app.get_topics() for app in self.apps))\n",
    "            self.broker = InMemoryBroker()\n",
    "\n",
    "        broker_spec = _get_broker_spec(await self.broker._start())\n",
    "\n",
    "        try:\n",
    "            if isinstance(self.broker, (ApacheKafkaBroker, LocalRedpandaBroker)):\n",
    "                override_broker_configs = [\n",
    "                    list(grp)\n",
    "                    for k, grp in groupby(\n",
    "                        [\n",
    "                            broker_config\n",
    "                            for app in self.apps + [self]\n",
    "                            for broker_config in app._override_brokers\n",
    "                        ]\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "                for override_brokers_config_groups, broker in zip(\n",
    "                    override_broker_configs, self.overriden_brokers\n",
    "                ):\n",
    "                    b_s = _get_broker_spec(await broker._start())\n",
    "                    for override_broker_config in override_brokers_config_groups:\n",
    "                        override_broker_config[\"fastkafka_tester_broker\"] = b_s\n",
    "\n",
    "                for app in self.apps + [self]:\n",
    "                    app._kafka_brokers.brokers[\"fastkafka_tester_broker\"] = broker_spec\n",
    "                    app.set_kafka_broker(\"fastkafka_tester_broker\")\n",
    "            await self._start_tester()\n",
    "            try:\n",
    "                yield self\n",
    "            finally:\n",
    "                await self._stop_tester()\n",
    "        finally:\n",
    "            await self.broker._stop()\n",
    "            for broker in self.overriden_brokers:\n",
    "                await broker._stop()\n",
    "\n",
    "    async def __aenter__(self) -> \"Tester\":\n",
    "        self._ctx = self._create_ctx()\n",
    "        return await self._ctx.__aenter__()\n",
    "\n",
    "    async def __aexit__(self, *args: Any) -> None:\n",
    "        await self._ctx.__aexit__(*args)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02d68085",
   "metadata": {},
   "source": [
    "for _ in range(2):\n",
    "    with pytest.raises(RuntimeError) as e:\n",
    "        async with Tester(app) as tester:\n",
    "            assert tester.broker.is_started\n",
    "            assert tester.is_started\n",
    "            raise RuntimeError(\"ok\")\n",
    "\n",
    "    print(e)\n",
    "    assert not tester.broker.is_started\n",
    "    assert not tester.is_started"
   ]
  },
  {
   "cell_type": "raw",
   "id": "506835e9",
   "metadata": {},
   "source": [
    "tester_with_redpanda = Tester(app).using_local_redpanda(tag=\"v22.3.15\")\n",
    "assert isinstance(tester_with_redpanda.broker, LocalRedpandaBroker)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "215d3232",
   "metadata": {},
   "source": [
    "tester = Tester(app)\n",
    "\n",
    "\n",
    "@tester.produces()\n",
    "async def to_preprocessed_signals(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "\n",
    "@tester.consumes(auto_offset_reset=\"latest\")\n",
    "async def on_predictions(msg: TestMsg):\n",
    "    pass\n",
    "\n",
    "\n",
    "async with tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    tester.mocks.on_predictions.assert_called()\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "669581fe",
   "metadata": {},
   "source": [
    "tester = Tester(app).using_local_kafka(zookeeper_port=9998, listener_port=9788)\n",
    "\n",
    "\n",
    "@tester.produces()\n",
    "async def to_preprocessed_signals(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "\n",
    "@tester.consumes(auto_offset_reset=\"latest\")\n",
    "async def on_predictions(msg: TestMsg):\n",
    "    pass\n",
    "\n",
    "\n",
    "async with tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    tester.mocks.on_predictions.assert_called()\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e5f89",
   "metadata": {},
   "source": [
    "## Test overriding brokers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbb8371f",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals_overriden(msg: TestMsg):\n",
    "    print(f\"Overriden:  {msg=}\")\n",
    "\n",
    "\n",
    "@overriden_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"Original:  {msg=}\")\n",
    "\n",
    "\n",
    "tester = Tester(overriden_app)\n",
    "\n",
    "\n",
    "@tester.produces(brokers=kafka_brokers)\n",
    "async def to_preprocessed_signals(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "async with tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals_overriden.assert_called(\n",
    "        timeout=5\n",
    "    )\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals.assert_not_called(\n",
    "        timeout=5\n",
    "    )\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f1c6ce1",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals_overriden(msg: TestMsg):\n",
    "    print(f\"Overriden:  {msg=}\")\n",
    "\n",
    "\n",
    "@overriden_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"Original:  {msg=}\")\n",
    "\n",
    "\n",
    "tester = Tester(overriden_app).using_local_kafka()\n",
    "\n",
    "\n",
    "@tester.produces(brokers=kafka_brokers)\n",
    "async def to_preprocessed_signals(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "async with tester:\n",
    "    print(overriden_app._override_brokers)\n",
    "    print(tester._override_brokers)\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals_overriden.assert_called(\n",
    "        timeout=5\n",
    "    )\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals.assert_not_called(\n",
    "        timeout=5\n",
    "    )\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cfe64c9",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals_overriden(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "tester = Tester(overriden_app)\n",
    "\n",
    "\n",
    "@tester.produces(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def to_preprocessed_signals_test_override(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "@tester.consumes(auto_offset_reset=\"earliest\")\n",
    "async def on_predictions(msg: TestMsg):\n",
    "    print(f\"tester: {msg=}\")\n",
    "    pass\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "async with tester:\n",
    "    await tester.to_preprocessed_signals_test_override(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals_overriden.assert_called(\n",
    "        timeout=5\n",
    "    )\n",
    "    await tester.awaited_mocks.on_predictions.assert_called(timeout=5)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb9f44ea",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals_overriden(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "tester = Tester(overriden_app).using_local_kafka()\n",
    "\n",
    "\n",
    "@tester.produces(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def to_preprocessed_signals_test_override(msg: TestMsg) -> TestMsg:\n",
    "    print(f\"Producing msg {msg}\")\n",
    "    return msg\n",
    "\n",
    "\n",
    "@tester.consumes(auto_offset_reset=\"earliest\")\n",
    "async def on_predictions(msg: TestMsg):\n",
    "    print(f\"tester: {msg=}\")\n",
    "    pass\n",
    "\n",
    "\n",
    "tester.to_preprocessed_signals = to_preprocessed_signals\n",
    "\n",
    "async with tester:\n",
    "    await tester.to_preprocessed_signals_test_override(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals_overriden.assert_called(\n",
    "        timeout=5\n",
    "    )\n",
    "    await tester.awaited_mocks.on_predictions.assert_called(timeout=5)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8c473",
   "metadata": {},
   "source": [
    "## Mirroring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def mirror_producer(\n",
    "    topic: str, producer_f: Callable[..., Any], brokers: KafkaBrokers\n",
    ") -> Callable[..., Any]:\n",
    "    msg_type = inspect.signature(producer_f).return_annotation\n",
    "\n",
    "    msg_type_unwrapped = unwrap_list_type(unwrap_from_kafka_event(msg_type))\n",
    "\n",
    "    async def skeleton_func(msg: BaseModel) -> None:\n",
    "        pass\n",
    "\n",
    "    mirror_func = skeleton_func\n",
    "    sig = inspect.signature(skeleton_func)\n",
    "\n",
    "    # adjust name, take into consideration the origin app and brokers \n",
    "    # configuration so that we can differentiate those two\n",
    "    mirror_func.__name__ = (\n",
    "        f\"mirror_{id(app)}_on_{remove_suffix(topic).replace('.', '_')}_{abs(hash(brokers))}\"\n",
    "    )\n",
    "\n",
    "    # adjust arg and return val\n",
    "    sig = sig.replace(\n",
    "        parameters=[\n",
    "            inspect.Parameter(\n",
    "                name=\"msg\",\n",
    "                annotation=msg_type_unwrapped,\n",
    "                kind=inspect.Parameter.POSITIONAL_OR_KEYWORD,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    mirror_func.__signature__ = sig  # type: ignore\n",
    "\n",
    "    return mirror_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@app.produces()\n",
    "async def to_topic1() -> TestMsg:\n",
    "    pass\n",
    "\n",
    "\n",
    "@app.produces(topic=\"topic2\")\n",
    "async def some_log(in_var: int) -> TestMsg:\n",
    "    pass\n",
    "\n",
    "\n",
    "@app.produces(topic=\"topic2\", brokers=dict(localhost=dict(url=\"localhost\", port=9093)))\n",
    "async def some_log_1(in_var: int) -> TestMsg:\n",
    "    pass\n",
    "\n",
    "\n",
    "@app.produces(topic=\"topic2\", brokers=dict(localhost=dict(url=\"localhost\", port=9093)))\n",
    "async def some_log_2(in_var: int) -> TestMsg:\n",
    "    pass\n",
    "\n",
    "\n",
    "for topic, (producer_f, _, brokers, _) in app._producers_store.items():\n",
    "    mirror = mirror_producer(\n",
    "        topic,\n",
    "        producer_f,\n",
    "        brokers.json() if brokers is not None else app._kafka_brokers.json(),\n",
    "    )\n",
    "    assert \"_\".join(mirror.__name__.split(\"_\")[2:-1]) == \"on_\" + remove_suffix(topic)\n",
    "    assert (\n",
    "        inspect.signature(mirror).parameters[\"msg\"].annotation.__name__\n",
    "        == inspect.Parameter(\n",
    "            name=\"msg\",\n",
    "            annotation=TestMsg,\n",
    "            kind=inspect.Parameter.POSITIONAL_OR_KEYWORD,\n",
    "        ).annotation.__name__\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42afadc7",
   "metadata": {},
   "source": [
    "app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "@app.produces()\n",
    "async def to_topic1() -> TestMsg:\n",
    "    pass\n",
    "\n",
    "\n",
    "@app.produces(topic=\"topic2\")\n",
    "async def some_log(in_var: int) -> KafkaEvent[List[TestMsg]]:\n",
    "    pass\n",
    "\n",
    "\n",
    "for topic, (producer_f, _, brokers, _) in app._producers_store.items():\n",
    "    mirror = mirror_producer(\n",
    "        topic,\n",
    "        producer_f,\n",
    "        brokers.json() if brokers is not None else app._kafka_brokers.json(),\n",
    "    )\n",
    "    assert \"_\".join(mirror.__name__.split(\"_\")[2:-1]) == \"on_\" + remove_suffix(topic)\n",
    "    assert inspect.signature(mirror).parameters[\"msg\"].annotation.__name__ == \"TestMsg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d23ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def mirror_consumer(\n",
    "    topic: str, consumer_f: Callable[..., Any], brokers: KafkaBrokers\n",
    ") -> Callable[..., Any]:\n",
    "    msg_type = inspect.signature(consumer_f).parameters[\"msg\"]\n",
    "\n",
    "    msg_type_unwrapped = unwrap_list_type(msg_type)\n",
    "\n",
    "    async def skeleton_func(msg: BaseModel) -> BaseModel:\n",
    "        return msg\n",
    "\n",
    "    mirror_func = skeleton_func\n",
    "    sig = inspect.signature(skeleton_func)\n",
    "\n",
    "    # adjust name, take into consideration the origin app and brokers\n",
    "    # configuration so that we can differentiate those two\n",
    "    mirror_func.__name__ = f\"mirror_{id(app)}_to_{remove_suffix(topic).replace('.', '_')}_{abs(hash(brokers))}\"\n",
    "\n",
    "    # adjust arg and return val\n",
    "    sig = sig.replace(\n",
    "        parameters=[msg_type], return_annotation=msg_type_unwrapped.annotation\n",
    "    )\n",
    "\n",
    "    mirror_func.__signature__ = sig  # type: ignore\n",
    "    return mirror_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, (consumer_f, _, _, brokers, _) in app._consumers_store.items():\n",
    "    mirror = mirror_consumer(\n",
    "        topic,\n",
    "        consumer_f,\n",
    "        brokers.json() if brokers is not None else app._kafka_brokers.json(),\n",
    "    )\n",
    "    assert \"_\".join(mirror.__name__.split(\"_\")[3:-1]) == \"to_\" + remove_suffix(topic)\n",
    "    assert (\n",
    "        inspect.signature(mirror).return_annotation.__name__ == TestMsg.__name__\n",
    "    ), inspect.signature(mirror).return_annotation.__name__\n",
    "    assert (\n",
    "        inspect.signature(mirror).parameters[\"msg\"].annotation.__name__\n",
    "        == inspect.Parameter(\n",
    "            name=\"msg\",\n",
    "            annotation=TestMsg,\n",
    "            kind=inspect.Parameter.POSITIONAL_OR_KEYWORD,\n",
    "        ).annotation.__name__\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def create_mirrors(self: Tester) -> None:\n",
    "    for app in self.apps:\n",
    "        for topic, (consumer_f, _, _, brokers, _) in app._consumers_store.items():\n",
    "            mirror_f = mirror_consumer(\n",
    "                topic,\n",
    "                consumer_f,\n",
    "                brokers.json() if brokers is not None else app._kafka_brokers.json(),\n",
    "            )\n",
    "            mirror_f = self.produces(  # type: ignore\n",
    "                topic=remove_suffix(topic),\n",
    "                brokers=brokers,\n",
    "            )(mirror_f)\n",
    "            self.mirrors[consumer_f] = mirror_f\n",
    "            setattr(self, mirror_f.__name__, mirror_f)\n",
    "        for topic, (producer_f, _, brokers, _) in app._producers_store.items():\n",
    "            mirror_f = mirror_producer(\n",
    "                topic,\n",
    "                producer_f,\n",
    "                brokers.json() if brokers is not None else app._kafka_brokers.json(),\n",
    "            )\n",
    "            mirror_f = self.consumes(  # type: ignore\n",
    "                topic=remove_suffix(topic),\n",
    "                brokers=brokers,\n",
    "            )(mirror_f)\n",
    "            self.mirrors[producer_f] = mirror_f\n",
    "            setattr(self, mirror_f.__name__, mirror_f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e236c551",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "tester = Tester(overriden_app)\n",
    "\n",
    "assert hasattr(\n",
    "    tester,\n",
    "    f\"mirror_{id(app)}_to_preprocessed_signals_{abs(hash(_get_kafka_brokers(kafka_brokers).json()))}\",\n",
    ")\n",
    "\n",
    "assert hasattr(\n",
    "    tester,\n",
    "    f\"mirror_{id(app)}_on_predictions_{abs(hash(_get_kafka_brokers(app._kafka_brokers).json()))}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d95e6a6e",
   "metadata": {},
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "async with Tester(overriden_app).using_local_kafka() as tester:\n",
    "    await getattr(\n",
    "        tester,\n",
    "        f\"mirror_{id(app)}_to_preprocessed_signals_{abs(hash(_get_kafka_brokers(kafka_brokers).json()))}\",\n",
    "    )(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals.assert_called(timeout=5)\n",
    "    await getattr(\n",
    "        tester.awaited_mocks,\n",
    "        f\"mirror_{id(app)}_on_predictions_{abs(hash(_get_kafka_brokers(app._kafka_brokers).json()))}\",\n",
    "    ).assert_called(timeout=5)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90f34f59",
   "metadata": {},
   "source": [
    "# Test mirroring with \".\" in topic names\n",
    "\n",
    "\n",
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "second_app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@second_app.consumes(topic=\"this.should_work.now\")\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@second_app.produces(topic=\"some.dots.my_topic\")\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return [prediction]\n",
    "\n",
    "\n",
    "async with Tester(second_app) as tester:\n",
    "    await getattr(\n",
    "        tester,\n",
    "        f\"mirror_{id(app)}_to_this_should_work_now_{abs(hash(_get_kafka_brokers(app._kafka_brokers).json()))}\",\n",
    "    )(TestMsg(msg=\"signal\"))\n",
    "    await getattr(\n",
    "        tester.awaited_mocks,\n",
    "        f\"mirror_{id(app)}_on_some_dots_my_topic_{abs(hash(_get_kafka_brokers(app._kafka_brokers).json()))}\",\n",
    "    ).assert_called(timeout=5)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2c251",
   "metadata": {},
   "source": [
    "## Mirrors dict and syntax sugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class ambigious_warning:\n",
    "    \n",
    "    def __getattribute__(self, attr) -> Any:\n",
    "        raise Exception(\n",
    "            \"Ambigious topic, please use Tester.mirrors[app.function] to find your topic\"\n",
    "        )\n",
    "        \n",
    "    def __call__(self, *args, **kwargs) -> Any:\n",
    "        raise Exception(\n",
    "            \"Ambigious topic, please use Tester.mirrors[app.function] to find your topic\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pytest.raises(Exception) as e:\n",
    "    ambigious_warning()(TestMsg(msg=\"signal\"))\n",
    "assert e.value.args[0] == 'Ambigious topic, please use Tester.mirrors[app.function] to find your topic'\n",
    "\n",
    "with pytest.raises(Exception) as e:\n",
    "    ambigious_warning().assert_called(timeout=5)\n",
    "assert e.value.args[0] == 'Ambigious topic, please use Tester.mirrors[app.function] to find your topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a841f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def set_sugar(\n",
    "    *,\n",
    "    tester: Tester,\n",
    "    prefix: str,\n",
    "    topic_brokers: Dict[str, str],\n",
    "    topic: str,\n",
    "    brokers: str,\n",
    "    function,\n",
    ") -> None:\n",
    "    brokers_for_topic = topic_brokers.get(topic, [])\n",
    "    if brokers not in brokers_for_topic:\n",
    "        brokers_for_topic.append(brokers)\n",
    "        topic_brokers[topic] = brokers_for_topic\n",
    "    if len(brokers_for_topic) == 1:\n",
    "        setattr(tester, f\"{prefix}{topic}\", function)\n",
    "    else:\n",
    "        setattr(tester, f\"{prefix}{topic}\", ambigious_warning())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8480ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch\n",
    "def arrange_mirrors(self: Tester) -> None:\n",
    "    topic_brokers = {}\n",
    "    mocks = {}\n",
    "    awaited_mocks = {}\n",
    "    for app in self.apps:\n",
    "        for topic, (consumer_f, _, _, brokers, _) in app._consumers_store.items():\n",
    "            mirror_f = self.mirrors[consumer_f]\n",
    "            self.mirrors[getattr(app, consumer_f.__name__)] = mirror_f\n",
    "            #             delattr(self, mirror_f.__name__)   Do we delete the function from tester to not create noise?\n",
    "            set_sugar(\n",
    "                tester=self,\n",
    "                prefix=\"to_\",\n",
    "                topic_brokers=topic_brokers,\n",
    "                topic=remove_suffix(topic),\n",
    "                brokers=brokers.json()\n",
    "                if brokers is not None\n",
    "                else app._kafka_brokers.json(),\n",
    "                function=mirror_f,\n",
    "            )\n",
    "            \n",
    "            mocks[f\"to_{remove_suffix(topic)}\"] = getattr(self.mocks, mirror_f.__name__)\n",
    "            awaited_mocks[f\"to_{remove_suffix(topic)}\"] = getattr(self.awaited_mocks, mirror_f.__name__)\n",
    "\n",
    "        for topic, (producer_f, _, brokers, _) in app._producers_store.items():\n",
    "            mirror_f = self.mirrors[producer_f]\n",
    "            self.mirrors[getattr(app, producer_f.__name__)] = getattr(\n",
    "                self.awaited_mocks, mirror_f.__name__\n",
    "            )\n",
    "            set_sugar(\n",
    "                tester=self,\n",
    "                prefix=\"on_\",\n",
    "                topic_brokers=topic_brokers,\n",
    "                topic=remove_suffix(topic),\n",
    "                brokers=brokers.json()\n",
    "                if brokers is not None\n",
    "                else app._kafka_brokers.json(),\n",
    "                function=getattr(self.awaited_mocks, mirror_f.__name__),\n",
    "            )\n",
    "            mocks[f\"on_{remove_suffix(topic)}\"] = getattr(self.mocks, mirror_f.__name__)\n",
    "            awaited_mocks[f\"on_{remove_suffix(topic)}\"] = getattr(self.awaited_mocks, mirror_f.__name__)\n",
    "\n",
    "    AppMocks = collections.namedtuple(  # type: ignore\n",
    "        f\"{self.__class__.__name__}Mocks\", [f_name for f_name in mocks]\n",
    "    )\n",
    "    setattr(self, \"mocks\", AppMocks(**mocks))\n",
    "    setattr(self, \"awaited_mocks\", AppMocks(**awaited_mocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d84884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test batch mirroring\n",
    "\n",
    "\n",
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "second_app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@second_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg, meta: EventMetadata):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@second_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> List[TestMsg]:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return [prediction]\n",
    "\n",
    "\n",
    "async with Tester(second_app) as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await tester.awaited_mocks.on_predictions.assert_called(timeout=5)\n",
    "    tester.mocks.on_predictions.assert_called()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2800b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "async with Tester(overriden_app).using_local_kafka() as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await asyncio.sleep(5)\n",
    "    await overriden_app.awaited_mocks.on_preprocessed_signals.assert_called(timeout=5)\n",
    "    await tester.on_predictions.assert_called(timeout=5)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@overriden_app.consumes(topic=\"preprocessed_signals\", brokers=kafka_brokers)\n",
    "async def on_preprocessed_signals_overriden(msg: TestMsg):\n",
    "    print(f\"{msg=}\")\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "async with Tester(overriden_app) as tester:\n",
    "    with pytest.raises(Exception) as exception_produce:\n",
    "        await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    assert (\n",
    "        exception_produce.value.args[0]\n",
    "        == \"Ambigious topic, please use Tester.mirrors[app.function] to find your topic\"\n",
    "    )\n",
    "    await tester.mirrors[on_preprocessed_signals](TestMsg(msg=\"signal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63606cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers = dict(localhost=[dict(url=\"some_server\", port=9092)])\n",
    "\n",
    "overriden_app = FastKafka(\n",
    "    kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092))\n",
    ")\n",
    "\n",
    "\n",
    "@overriden_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "@overriden_app.produces(topic=\"predictions\", brokers=kafka_brokers)\n",
    "async def to_predictions_overriden(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "async with Tester(overriden_app) as tester:\n",
    "    with pytest.raises(Exception) as exception_consume:\n",
    "        await tester.on_predictions.assert_called(timeout=5)\n",
    "    assert (\n",
    "        exception_consume.value.args[0]\n",
    "        == \"Ambigious topic, please use Tester.mirrors[app.function] to find your topic\"\n",
    "    )\n",
    "    await tester.mirrors[overriden_app.to_predictions].assert_not_called(timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ea363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test KafkaEvent mirroring and consumer batching\n",
    "\n",
    "\n",
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "second_app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@second_app.consumes()\n",
    "async def on_preprocessed_signals(msg: List[TestMsg]):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@second_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> KafkaEvent[TestMsg]:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return KafkaEvent(message=prediction, key=b\"123\")\n",
    "\n",
    "\n",
    "async with Tester(second_app) as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await tester.on_predictions.assert_called(timeout=5)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate tester with two apps\n",
    "\n",
    "\n",
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "second_app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@second_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@second_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "async with Tester([app, second_app]) as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await tester.on_predictions.assert_called(timeout=5)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate tester with two apps\n",
    "\n",
    "\n",
    "class TestMsg(BaseModel):\n",
    "    msg: str = Field(...)\n",
    "\n",
    "\n",
    "second_app = FastKafka(kafka_brokers=dict(localhost=dict(url=\"localhost\", port=9092)))\n",
    "\n",
    "\n",
    "@second_app.consumes()\n",
    "async def on_preprocessed_signals(msg: TestMsg):\n",
    "    await to_predictions(TestMsg(msg=\"prediction\"))\n",
    "\n",
    "\n",
    "@second_app.produces()\n",
    "async def to_predictions(prediction: TestMsg) -> TestMsg:\n",
    "    print(f\"Sending prediction: {prediction}\")\n",
    "    return prediction\n",
    "\n",
    "\n",
    "async with Tester([app, second_app]).using_local_kafka() as tester:\n",
    "    await tester.to_preprocessed_signals(TestMsg(msg=\"signal\"))\n",
    "    await tester.on_predictions.assert_called(timeout=5)\n",
    "print(\"ok\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
