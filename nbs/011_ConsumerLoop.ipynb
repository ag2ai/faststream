{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.aiokafka_consumer_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from asyncio import iscoroutinefunction  # do not use the version from inspect\n",
    "from typing import *\n",
    "from functools import wraps, partial\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import anyio\n",
    "import asyncer\n",
    "from aiokafka import AIOKafkaConsumer\n",
    "from aiokafka.structs import ConsumerRecord, TopicPartition\n",
    "from anyio.streams.memory import MemoryObjectReceiveStream\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main import ModelMetaclass\n",
    "\n",
    "from fastkafka._components.logger import get_logger\n",
    "from fastkafka._components.meta import delegates, export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pytest\n",
    "from datetime import datetime, timedelta\n",
    "from unittest.mock import AsyncMock, MagicMock, Mock, call, patch, create_autospec\n",
    "\n",
    "from pydantic import Field, HttpUrl, NonNegativeInt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fastkafka._components.helpers import true_after\n",
    "from fastkafka._components.logger import supress_timestamps\n",
    "from fastkafka._helpers import produce_messages\n",
    "from fastkafka.encoder import avro_decoder, avro_encoder, json_decoder\n",
    "from fastkafka.testing import ApacheKafkaBroker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e9e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "# allows async calls in notebooks\n",
    "\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53542175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92feb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMessage(BaseModel):\n",
    "    url: HttpUrl = Field(..., example=\"http://www.acme.com\", description=\"Url example\")\n",
    "    port: NonNegativeInt = Field(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@dataclass\n",
    "@export(\"fastkafka\")\n",
    "class EventMetadata():\n",
    "    \"\"\"A class for encapsulating Kafka record metadata.\n",
    "\n",
    "    Args:\n",
    "        topic: The topic this record is received from\n",
    "        partition: The partition from which this record is received\n",
    "        offset: The position of this record in the corresponding Kafka partition\n",
    "        timestamp: The timestamp of this record\n",
    "        timestamp_type: The timestamp type of this record\n",
    "        key: The key (or `None` if no key is specified)\n",
    "        value: The value\n",
    "        serialized_key_size: The size of the serialized, uncompressed key in bytes\n",
    "        serialized_value_size: The size of the serialized, uncompressed value in bytes\n",
    "        headers: The headers\n",
    "    \"\"\"\n",
    "    topic: str\n",
    "    partition: int\n",
    "    offset: int\n",
    "    timestamp: int\n",
    "    timestamp_type: int\n",
    "    key: Optional[bytes]\n",
    "    value: Optional[bytes]\n",
    "    checksum: int\n",
    "    serialized_key_size: int\n",
    "    serialized_value_size: int\n",
    "    headers: Sequence[Tuple[str, bytes]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb76fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "AsyncConsume = Callable[[BaseModel], Awaitable[None]]\n",
    "AsyncConsumeMeta =  Callable[[BaseModel, EventMetadata], Awaitable[None]]\n",
    "SyncConsume = Callable[[BaseModel], None]\n",
    "SyncConsumeMeta =  Callable[[BaseModel, EventMetadata], None]\n",
    "\n",
    "ConsumeCallable = Union[\n",
    "    AsyncConsume, AsyncConsumeMeta, SyncConsume, SyncConsumeMeta\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f24d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _callback_parameters_wrapper(\n",
    "    callback: Union[AsyncConsume, AsyncConsumeMeta]\n",
    ") -> AsyncConsumeMeta:\n",
    "    \"\"\"Wraps an async callback and filters the arguments to pass based on if the function accepts EventMetadata as argument\n",
    "\n",
    "    Args:\n",
    "        callback: async callable that will be wrapped\n",
    "\n",
    "    Returns:\n",
    "        Wrapped callback with filtered params\n",
    "    \"\"\"\n",
    "    async def _params_wrap(\n",
    "        msg: BaseModel,\n",
    "        meta: EventMetadata,\n",
    "        callback: Union[AsyncConsume, AsyncConsumeMeta] = callback,\n",
    "    ) -> None:\n",
    "        types = list(get_type_hints(callback).values())\n",
    "        args: List[Union[BaseModel, EventMetadata]] = [msg]\n",
    "        if EventMetadata in types:\n",
    "            args.insert(types.index(EventMetadata), meta)\n",
    "        await callback(*args) # type: ignore\n",
    "\n",
    "    return _params_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def without_meta(msg: BaseModel):\n",
    "    assert msg == \"Example_msg\"\n",
    "\n",
    "with pytest.raises(TypeError) as e:\n",
    "    await without_meta(\"Example_msg\", \"Some_meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@_callback_parameters_wrapper\n",
    "async def without_meta(msg: BaseModel):\n",
    "    assert msg == \"Example_msg\"\n",
    "\n",
    "await without_meta(\"Example_msg\", \"Some_meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@_callback_parameters_wrapper\n",
    "async def with_meta(msg: BaseModel, meta: EventMetadata):\n",
    "    assert msg == \"Example_msg\"\n",
    "    assert meta == \"Some_meta\"\n",
    "\n",
    "await with_meta(\"Example_msg\", \"Some_meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _create_safe_callback(\n",
    "    callback: Union[AsyncConsume, AsyncConsumeMeta]\n",
    ") -> AsyncConsumeMeta:\n",
    "    \"\"\"Wraps an async callback into a safe callback that catches any Exception and loggs them as warnings\n",
    "\n",
    "    Args:\n",
    "        callback: async callable that will be wrapped into a safe callback\n",
    "\n",
    "    Returns:\n",
    "        Wrapped callback into a safe callback that handles exceptions\n",
    "    \"\"\"\n",
    "\n",
    "    async def _safe_callback(\n",
    "        msg: BaseModel,\n",
    "        meta: EventMetadata,\n",
    "        callback: Union[AsyncConsume, AsyncConsumeMeta] = callback,\n",
    "    ) -> None:\n",
    "        try:\n",
    "            await _callback_parameters_wrapper(callback)(msg, meta)\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"_safe_callback(): exception caugth {e.__repr__()} while awaiting '{callback}({msg})'\"\n",
    "            )\n",
    "\n",
    "    return _safe_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if parameters wrapper works\n",
    "\n",
    "async def func(msg: BaseModel):\n",
    "    pass\n",
    "\n",
    "example_msg = \"Example msg\"\n",
    "callback = create_autospec(func)\n",
    "safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "await safe_callback(f\"{example_msg}\", \"Some meta\")\n",
    "\n",
    "callback.assert_awaited_once_with(f\"{example_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def func(msg: BaseModel, meta: EventMetadata):\n",
    "    pass\n",
    "\n",
    "\n",
    "example_msg = \"Example msg\"\n",
    "callback = create_autospec(func)\n",
    "safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "with patch(\"__main__.get_type_hints\") as mock:\n",
    "    mock.return_value = {\"msg\": BaseModel, \"meta\": EventMetadata}\n",
    "    await safe_callback(f\"{example_msg}\", \"Some meta\")\n",
    "\n",
    "    callback.assert_awaited_once_with(f\"{example_msg}\", \"Some meta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b218a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if callback is called when wrapped\n",
    "\n",
    "example_msg = \"Example msg\"\n",
    "callback = AsyncMock()\n",
    "safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "with patch(\"__main__.get_type_hints\") as mock:\n",
    "    mock.return_value = {\"msg\": BaseModel}\n",
    "    await safe_callback(f\"{example_msg}\", \"Some meta\")\n",
    "\n",
    "    callback.assert_awaited_once_with(f\"{example_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if exception is caught and logged when callback is called and throws an exception\n",
    "\n",
    "with patch.object(logger, \"warning\") as mock:\n",
    "    example_msg = \"Example msg\"\n",
    "    exception = Exception(\"\")\n",
    "\n",
    "    callback = AsyncMock()\n",
    "    callback.side_effect = exception\n",
    "    safe_callback = _create_safe_callback(callback)\n",
    "\n",
    "    with patch(\"__main__.get_type_hints\") as type_mock:\n",
    "        type_mock.return_value = {\"msg\": BaseModel}\n",
    "        await safe_callback(f\"{example_msg}\", \"Some meta\")\n",
    "\n",
    "    callback.assert_awaited_once_with(f\"{example_msg}\")\n",
    "    mock.assert_called_once_with(\n",
    "        f\"_safe_callback(): exception caugth {exception.__repr__()} while awaiting '{callback}({example_msg})'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _prepare_callback(\n",
    "    callback: ConsumeCallable\n",
    ") -> AsyncConsumeMeta:\n",
    "    \"\"\"\n",
    "    Prepares a callback to be used in the consumer loop.\n",
    "        1. If callback is sync, asyncify it\n",
    "        2. Wrap the callback into a safe callback for exception handling\n",
    "\n",
    "    Params:\n",
    "        callback: async callable that will be prepared for use in consumer\n",
    "\n",
    "    Returns:\n",
    "        Prepared callback\n",
    "    \"\"\"\n",
    "    async_callback: Union[AsyncConsume, AsyncConsumeMeta] = (\n",
    "        callback if iscoroutinefunction(callback) else asyncer.asyncify(callback)  # type: ignore\n",
    "    )\n",
    "    return _create_safe_callback(async_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e996f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if callback is called when wrapped\n",
    "\n",
    "for is_async in [False, True]:\n",
    "    example_msg = \"Example msg\"\n",
    "    callback = AsyncMock() if is_async else Mock()\n",
    "    prepared_callback = _prepare_callback(callback)\n",
    "\n",
    "    with patch(\"__main__.get_type_hints\") as mock:\n",
    "        mock.return_value = {\"msg\": BaseModel}\n",
    "        await prepared_callback(f\"{example_msg}\", \"Some meta\")\n",
    "\n",
    "    callback.assert_called_once_with(f\"{example_msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0977bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def _stream_msgs(  # type: ignore\n",
    "    msgs: Dict[TopicPartition, bytes],\n",
    "    send_stream: anyio.streams.memory.MemoryObjectSendStream[Any],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Decodes and streams the message and topic to the send_stream.\n",
    "\n",
    "    Params:\n",
    "        msgs:\n",
    "        send_stream:\n",
    "    \"\"\"\n",
    "    for topic_partition, topic_msgs in msgs.items():\n",
    "        topic = topic_partition.topic\n",
    "        try:\n",
    "            await send_stream.send(topic_msgs)\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"_stream_msgs(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic_partition.topic}', partition='{topic_partition.partition}' and messages: {topic_msgs!r}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def _decode_streamed_msgs(  # type: ignore\n",
    "    msgs: List[ConsumerRecord], msg_type: BaseModel\n",
    ") -> List[BaseModel]:\n",
    "    decoded_msgs = [msg_type.parse_raw(msg.value.decode(\"utf-8\")) for msg in msgs]\n",
    "    return decoded_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumer_record(topic: str, partition: int, msg: BaseModel):\n",
    "    record = ConsumerRecord(\n",
    "        topic=topic,\n",
    "        partition=partition,\n",
    "        offset=0,\n",
    "        timestamp=0,\n",
    "        timestamp_type=0,\n",
    "        key=None,\n",
    "        value=msg.json().encode(\"utf-8\")\n",
    "        if hasattr(msg, \"json\")\n",
    "        else msg.encode(\"utf-8\"),\n",
    "        checksum=0,\n",
    "        serialized_key_size=0,\n",
    "        serialized_value_size=0,\n",
    "        headers=[],\n",
    "    )\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aa93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: one msg, one topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic = \"topic_0\"\n",
    "    partition = 0\n",
    "    topic_part_0_0 = TopicPartition(topic, partition)\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs={topic_part_0_0: [record]},\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_called_once()\n",
    "    mock.assert_has_calls([call([record])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ecc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check different topics\n",
    "\n",
    "# Two msg, two topics, send called twice with each topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0), (\"topic_1\", 0)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    assert mock.call_count == 2\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3fa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple msgs in same topic\n",
    "\n",
    "# Two msg, one topic, send called twice for same topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg),\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg),\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multiple partitions\n",
    "\n",
    "# Two msg, one topic, differenct partitions, send called twice for same topic\n",
    "\n",
    "with patch(\"anyio.streams.memory.MemoryObjectSendStream.send\") as mock:\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream()\n",
    "\n",
    "    topic_partitions = [(\"topic_0\", 0), (\"topic_0\", 1)]\n",
    "\n",
    "    msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "    msgs = {\n",
    "        TopicPartition(topic, partition): [\n",
    "            create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "        ]\n",
    "        for topic, partition in topic_partitions\n",
    "    }\n",
    "    record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "    await _stream_msgs(\n",
    "        msgs=msgs,\n",
    "        send_stream=send_stream,\n",
    "    )\n",
    "\n",
    "    mock.assert_has_calls([call(msg) for msg in msgs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df02ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def _streamed_records(\n",
    "    receive_stream: MemoryObjectReceiveStream,\n",
    ") -> AsyncGenerator[Any, Any]:\n",
    "    async for records_per_topic in receive_stream:\n",
    "        for records in records_per_topic:\n",
    "            for record in records:\n",
    "                yield record\n",
    "\n",
    "\n",
    "@delegates(AIOKafkaConsumer.getmany)\n",
    "async def _aiokafka_consumer_loop(  # type: ignore\n",
    "    consumer: AIOKafkaConsumer,\n",
    "    *,\n",
    "    topic: str,\n",
    "    decoder_fn: Callable[[bytes, ModelMetaclass], Any],\n",
    "    callback: ConsumeCallable,\n",
    "    max_buffer_size: int = 100_000,\n",
    "    msg_type: Type[BaseModel],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Consumer loop for infinite pooling of the AIOKafka consumer for new messages. Calls consumer.getmany()\n",
    "    and after the consumer return messages or times out, messages are decoded and streamed to defined callback.\n",
    "\n",
    "    Params:\n",
    "        topic: Topic to subscribe\n",
    "        decoder_fn: Function to decode the messages consumed from the topic\n",
    "        callbacks: Dict of callbacks mapped to their respective topics\n",
    "        timeout_ms: Time to timeut the getmany request by the consumer\n",
    "        max_buffer_size: Maximum number of unconsumed messages in the callback buffer\n",
    "        msg_types: Dict of message types mapped to their respective topics\n",
    "        is_shutting_down_f: Function for controlling the shutdown of consumer loop\n",
    "    \"\"\"\n",
    "\n",
    "    prepared_callback = _prepare_callback(callback)\n",
    "\n",
    "    async def process_message_callback(\n",
    "        receive_stream: MemoryObjectReceiveStream[Any],\n",
    "        callback: Callable[\n",
    "            [BaseModel, EventMetadata], Awaitable[None]\n",
    "        ] = prepared_callback,\n",
    "        msg_type: Type[BaseModel] = msg_type,\n",
    "        topic: str = topic,\n",
    "        decoder_fn: Callable[[bytes, ModelMetaclass], Any] = decoder_fn,\n",
    "    ) -> None:\n",
    "        async with receive_stream:\n",
    "            try:\n",
    "                async for record in _streamed_records(receive_stream):\n",
    "                    try:\n",
    "                        msg = record.value\n",
    "                        decoded_msg = decoder_fn(msg, msg_type)\n",
    "                        await callback(\n",
    "                            decoded_msg,\n",
    "                            EventMetadata(\n",
    "                                topic=record.topic,\n",
    "                                partition=record.partition,\n",
    "                                offset=record.offset,\n",
    "                                timestamp=record.timestamp,\n",
    "                                timestamp_type=record.timestamp_type,\n",
    "                                value=record.value,\n",
    "                                checksum=record.checksum,\n",
    "                                key=record.key,\n",
    "                                serialized_key_size=record.serialized_key_size,\n",
    "                                serialized_value_size=record.serialized_value_size,\n",
    "                                headers=record.headers\n",
    "                            ),\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        logger.warning(\n",
    "                            f\"process_message_callback(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic}' and message: {msg}\"\n",
    "                        )\n",
    "            except Exception as e:\n",
    "                logger.warning(\n",
    "                    f\"process_message_callback(): Unexpected exception '{e.__repr__()}' caught and ignored for topic='{topic}'\"\n",
    "                )\n",
    "\n",
    "    send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "        max_buffer_size=max_buffer_size\n",
    "    )\n",
    "\n",
    "    async with anyio.create_task_group() as tg:\n",
    "        tg.start_soon(process_message_callback, receive_stream)\n",
    "        async with send_stream:\n",
    "            while not is_shutting_down_f():\n",
    "                msgs = await consumer.getmany(**kwargs)\n",
    "                try:\n",
    "                    await send_stream.send(msgs.values())\n",
    "                except Exception as e:\n",
    "                    logger.warning(\n",
    "                        f\"_aiokafka_consumer_loop(): Unexpected exception '{e}' caught and ignored for messages: {msgs}\"\n",
    "                    )\n",
    "            logger.info(\n",
    "                f\"_aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a60f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shutting_down_f(mock_func: Mock, num_calls: int = 1) -> Callable[[], bool]:\n",
    "    def _is_shutting_down_f():\n",
    "        return mock_func.call_count == num_calls\n",
    "\n",
    "    return _is_shutting_down_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77397e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n"
     ]
    }
   ],
   "source": [
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [record]}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=10,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),\n",
    "    )\n",
    "\n",
    "    assert mock_consumer.getmany.call_count == 1\n",
    "    mock_callback.assert_called_once_with(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b9e6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n",
      "[WARNING] __main__: _safe_callback(): exception caugth Exception('') while awaiting '<function asyncify.<locals>.wrapper>(url=HttpUrl('http://www.acme.com', ) port=22)'\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: exception in callback recovery\n",
    "# Two msg, one topic, process_f called twice even tough it throws\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "\n",
    "num_msgs = 2\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [record, record]}\n",
    "\n",
    "f = asyncio.Future()\n",
    "f.set_result(msgs)\n",
    "\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "exception = Exception(\"\")\n",
    "mock_callback.side_effect = exception\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=1,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany, num_calls=1),\n",
    "    )\n",
    "\n",
    "    assert mock_callback.call_count == num_msgs, mock_callback.call_count\n",
    "    mock_callback.assert_has_calls([call(msg), call(msg)])\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: malformed msgs\n",
    "# One msg of wrong type, two normal msg, one topic, process_f called twice\n",
    "\n",
    "topic = \"topic_0\"\n",
    "partition = 0\n",
    "msg = MyMessage(url=\"http://www.acme.com\", port=22)\n",
    "correct_record = create_consumer_record(topic=topic, partition=partition, msg=msg)\n",
    "faulty_record = create_consumer_record(topic=topic, partition=partition, msg=\"Wrong!\")\n",
    "\n",
    "mock_consumer = MagicMock()\n",
    "msgs = {TopicPartition(topic, 0): [faulty_record, correct_record, correct_record]}\n",
    "\n",
    "mock_consumer.configure_mock(**{\"getmany.return_value\": f})\n",
    "mock_callback = Mock()\n",
    "\n",
    "exception = Exception(\"\")\n",
    "callback.side_effect = exception\n",
    "\n",
    "for is_async in [True, False]:\n",
    "    await _aiokafka_consumer_loop(\n",
    "        consumer=mock_consumer,\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        max_buffer_size=100,\n",
    "        timeout_ms=10,\n",
    "        callback=asyncer.asyncify(mock_callback) if is_async else mock_callback,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=is_shutting_down_f(mock_consumer.getmany),\n",
    "    )\n",
    "\n",
    "    assert mock_consumer.getmany.call_count == 1\n",
    "    mock_callback.assert_has_calls([call(msg), call(msg)])\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46031397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def sanitize_kafka_config(**kwargs: Any) -> Dict[str, Any]:\n",
    "    \"\"\"Sanitize Kafka config\"\"\"\n",
    "    return {k: \"*\" * len(v) if \"pass\" in k.lower() else v for k, v in kwargs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa2ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"bootstrap_servers\": \"whatever.cloud:9092\",\n",
    "    \"auto_offset_reset\": \"earliest\",\n",
    "    \"security_protocol\": \"SASL_SSL\",\n",
    "    \"sasl_mechanism\": \"PLAIN\",\n",
    "    \"sasl_plain_username\": \"username\",\n",
    "    \"sasl_plain_password\": \"password\",\n",
    "    \"ssl_context\": \"something\",\n",
    "}\n",
    "\n",
    "assert sanitize_kafka_config(**kwargs)[\"sasl_plain_password\"] == \"********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@delegates(AIOKafkaConsumer)\n",
    "@delegates(_aiokafka_consumer_loop, keep=True)\n",
    "async def aiokafka_consumer_loop(\n",
    "    topic: str,\n",
    "    decoder_fn: Callable[[bytes, ModelMetaclass], Any],\n",
    "    *,\n",
    "    timeout_ms: int = 100,\n",
    "    max_buffer_size: int = 100_000,\n",
    "    callback: ConsumeCallable,\n",
    "    msg_type: Type[BaseModel],\n",
    "    is_shutting_down_f: Callable[[], bool],\n",
    "    **kwargs: Any,\n",
    ") -> None:\n",
    "    \"\"\"Consumer loop for infinite pooling of the AIOKafka consumer for new messages. Creates and starts AIOKafkaConsumer\n",
    "    and runs _aio_kafka_consumer loop fo infinite poling of the consumer for new messages.\n",
    "\n",
    "    Args:\n",
    "        topic: name of the topic to subscribe to\n",
    "        decoder_fn: Function to decode the messages consumed from the topic\n",
    "        callback: callback function to be called after decoding and parsing a consumed message\n",
    "        timeout_ms: Time to timeut the getmany request by the consumer\n",
    "        max_buffer_size: Maximum number of unconsumed messages in the callback buffer\n",
    "        msg_type: Type with `parse_json` method used for parsing a decoded message\n",
    "        is_shutting_down_f: Function for controlling the shutdown of consumer loop\n",
    "    \"\"\"\n",
    "    logger.info(f\"aiokafka_consumer_loop() starting...\")\n",
    "    try:\n",
    "        consumer = AIOKafkaConsumer(\n",
    "            **kwargs,\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"aiokafka_consumer_loop(): Consumer created using the following parameters: {sanitize_kafka_config(**kwargs)}\"\n",
    "        )\n",
    "\n",
    "        await consumer.start()\n",
    "        logger.info(\"aiokafka_consumer_loop(): Consumer started.\")\n",
    "        consumer.subscribe([topic])\n",
    "        logger.info(\"aiokafka_consumer_loop(): Consumer subscribed.\")\n",
    "\n",
    "        try:\n",
    "            await _aiokafka_consumer_loop(\n",
    "                consumer=consumer,\n",
    "                topic=topic,\n",
    "                decoder_fn=decoder_fn,\n",
    "                max_buffer_size=max_buffer_size,\n",
    "                timeout_ms=timeout_ms,\n",
    "                callback=callback,\n",
    "                msg_type=msg_type,\n",
    "                is_shutting_down_f=is_shutting_down_f,\n",
    "            )\n",
    "        finally:\n",
    "            await consumer.stop()\n",
    "            logger.info(f\"aiokafka_consumer_loop(): Consumer stopped.\")\n",
    "            logger.info(f\"aiokafka_consumer_loop() finished.\")\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"aiokafka_consumer_loop(): unexpected exception raised: '{e.__repr__()}'\"\n",
    "        )\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89d47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._components.test_dependencies: But not exported to PATH, exporting...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ecd605988540f5a7916a215fa51e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 139938...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 139938 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 139560...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 139560 terminated.\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89cc93e77d44667b8db28eb738f6c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000, meta=EventMetadata(topic='test_topic', partition=0, offset=999, timestamp=1682498189300, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 999}', checksum=None, serialized_key_size=-1, serialized_value_size=41, headers=())\n",
      "[INFO] __main__: msgs_received=2000, meta=EventMetadata(topic='test_topic', partition=0, offset=1999, timestamp=1682498189315, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 1999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=3000, meta=EventMetadata(topic='test_topic', partition=0, offset=2999, timestamp=1682498189323, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 2999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=4000, meta=EventMetadata(topic='test_topic', partition=0, offset=3999, timestamp=1682498189331, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 3999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=5000, meta=EventMetadata(topic='test_topic', partition=0, offset=4999, timestamp=1682498189339, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 4999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=6000, meta=EventMetadata(topic='test_topic', partition=0, offset=5999, timestamp=1682498189347, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 5999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=7000, meta=EventMetadata(topic='test_topic', partition=0, offset=6999, timestamp=1682498189356, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 6999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=8000, meta=EventMetadata(topic='test_topic', partition=0, offset=7999, timestamp=1682498189364, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 7999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: msgs_received=9000, meta=EventMetadata(topic='test_topic', partition=0, offset=8999, timestamp=1682498189371, timestamp_type=0, key=None, value=b'{\"url\": \"http://www.ai.com\", \"port\": 8999}', checksum=None, serialized_key_size=-1, serialized_value_size=42, headers=())\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 144028...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 144028 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 143649...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 143649 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with meta\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "meta_samples = []\n",
    "\n",
    "async def count_msg(msg: MyMessage, meta: EventMetadata):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        meta_samples.append(meta)\n",
    "        logger.info(f\"{msgs_received=}, {meta=}\")\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=json_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\"\n",
    "    assert all(isinstance(meta, EventMetadata) for meta in meta_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6484e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fe3c9c4b514460b864e752bc6584d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 145387...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 145387 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 145008...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 145008 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with avro_decoder\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    avro_encoder(MyMessage(url=\"http://www.ai.com\", port=port))\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=avro_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea86a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed659e1b3184262bb198683fe8a036f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/9178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: msgs_received=1000\n",
      "[INFO] __main__: msgs_received=2000\n",
      "[INFO] __main__: msgs_received=3000\n",
      "[INFO] __main__: msgs_received=4000\n",
      "[INFO] __main__: msgs_received=5000\n",
      "[INFO] __main__: msgs_received=6000\n",
      "[INFO] __main__: msgs_received=7000\n",
      "[INFO] __main__: msgs_received=8000\n",
      "[INFO] __main__: msgs_received=9000\n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 148120...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 148120 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 147741...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 147741 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with avro_decoder and meta\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 9178\n",
    "msgs = [\n",
    "    avro_encoder(MyMessage(url=\"http://www.ai.com\", port=port))\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "msgs_received = 0\n",
    "meta_samples = []\n",
    "\n",
    "async def count_msg(msg: MyMessage, meta: EventMetadata):\n",
    "    global msgs_received\n",
    "    msgs_received = msgs_received + 1\n",
    "    if msgs_received % 1000 == 0:\n",
    "        logger.info(f\"{msgs_received=}\")\n",
    "        meta_samples.append(meta)\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    await aiokafka_consumer_loop(\n",
    "        topic=topic,\n",
    "        decoder_fn=avro_decoder,\n",
    "        auto_offset_reset=\"earliest\",\n",
    "        callback=count_msg,\n",
    "        msg_type=MyMessage,\n",
    "        is_shutting_down_f=true_after(2),\n",
    "        bootstrap_servers=bootstrap_server,\n",
    "    )\n",
    "\n",
    "    assert msgs_sent == msgs_received, f\"{msgs_sent} != {msgs_received}\"\n",
    "    assert all(isinstance(meta, EventMetadata) for meta in meta_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9d9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc93c93b302450a9918471ccd30cd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8281b59d3444cfa9b0fd412381a28d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "Messages processed: 50,000\n",
      "Time              : 1.38 s\n",
      "Throughput.       : 36,323 msg/s\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 149476...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 149476 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 149097...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 149097 terminated.\n"
     ]
    }
   ],
   "source": [
    "topic = \"test_topic\"\n",
    "msgs_sent = 500_00\n",
    "msgs = [\n",
    "    MyMessage(url=\"http://www.ai.com\", port=port).json().encode(\"utf-8\")\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    pbar.update(1)\n",
    "\n",
    "\n",
    "def _is_shutting_down_f():\n",
    "    return pbar.n >= pbar.total\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    with tqdm(total=msgs_sent, desc=\"consuming messages\") as _pbar:\n",
    "        global pbar\n",
    "        pbar = _pbar\n",
    "\n",
    "        start = datetime.now()\n",
    "        await aiokafka_consumer_loop(\n",
    "            topic=topic,\n",
    "            decoder_fn=json_decoder,\n",
    "            auto_offset_reset=\"earliest\",\n",
    "            callback=count_msg,\n",
    "            msg_type=MyMessage,\n",
    "            is_shutting_down_f=_is_shutting_down_f,\n",
    "            bootstrap_servers=bootstrap_server,\n",
    "        )\n",
    "        t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "        thrp = pbar.n / t\n",
    "\n",
    "        print(f\"Messages processed: {pbar.n:,d}\")\n",
    "        print(f\"Time              : {t:.2f} s\")\n",
    "        print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ada17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.test_dependencies: Java is already installed.\n",
      "[INFO] fastkafka._components.test_dependencies: Kafka is installed.\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting zookeeper...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Starting kafka...\n",
      "[INFO] fastkafka._testing.apache_kafka_broker: Local Kafka broker up and running on 127.0.0.1:9092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1444903020a24ddb8e1bfd4d87f8bf3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "producing to 'test_topic':   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8c6bc07c4d4c72bddfc7767da92aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "consuming messages:   0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: aiokafka_consumer_loop() starting...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer created using the following parameters: {'auto_offset_reset': 'earliest', 'bootstrap_servers': '127.0.0.1:9092'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'test_topic'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'test_topic'}\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'test_topic': 1}. \n",
      "[INFO] __main__: _aiokafka_consumer_loop(): Consumer loop shutting down, waiting for send_stream to drain...\n",
      "[INFO] __main__: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] __main__: aiokafka_consumer_loop() finished.\n",
      "Messages processed: 50,000\n",
      "Time              : 2.00 s\n",
      "Throughput.       : 24,966 msg/s\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 150835...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 150835 terminated.\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Terminating the process 150455...\n",
      "[INFO] fastkafka._components._subprocess: terminate_asyncio_process(): Process 150455 terminated.\n"
     ]
    }
   ],
   "source": [
    "# Test with avro_decoder\n",
    "\n",
    "topic = \"test_topic\"\n",
    "msgs_sent = 500_00\n",
    "msgs = [\n",
    "    avro_encoder(MyMessage(url=\"http://www.ai.com\", port=port))\n",
    "    for port in range(msgs_sent)\n",
    "]\n",
    "\n",
    "\n",
    "async def count_msg(msg: MyMessage):\n",
    "    pbar.update(1)\n",
    "\n",
    "\n",
    "def _is_shutting_down_f():\n",
    "    return pbar.n >= pbar.total\n",
    "\n",
    "\n",
    "async with ApacheKafkaBroker(topics=[topic]) as bootstrap_server:\n",
    "    await produce_messages(topic=topic, bootstrap_servers=bootstrap_server, msgs=msgs)\n",
    "    with tqdm(total=msgs_sent, desc=\"consuming messages\") as _pbar:\n",
    "        global pbar\n",
    "        pbar = _pbar\n",
    "\n",
    "        start = datetime.now()\n",
    "        await aiokafka_consumer_loop(\n",
    "            topic=topic,\n",
    "            decoder_fn=avro_decoder,\n",
    "            auto_offset_reset=\"earliest\",\n",
    "            callback=count_msg,\n",
    "            msg_type=MyMessage,\n",
    "            is_shutting_down_f=_is_shutting_down_f,\n",
    "            bootstrap_servers=bootstrap_server,\n",
    "        )\n",
    "        t = (datetime.now() - start) / timedelta(seconds=1)\n",
    "        thrp = pbar.n / t\n",
    "\n",
    "        print(f\"Messages processed: {pbar.n:,d}\")\n",
    "        print(f\"Time              : {t:.2f} s\")\n",
    "        print(f\"Throughput.       : {thrp:,.0f} msg/s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
