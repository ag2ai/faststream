{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.task_streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b86144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export \n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from asyncio import Task\n",
    "from contextlib import asynccontextmanager\n",
    "from typing import *\n",
    "\n",
    "import anyio\n",
    "from aiokafka import ConsumerRecord\n",
    "\n",
    "from logging import Logger\n",
    "from fastkafka._components.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777beaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "from anyio import create_task_group, create_memory_object_stream, ExceptionGroup\n",
    "from unittest.mock import Mock, MagicMock, AsyncMock\n",
    "\n",
    "import asyncer\n",
    "import pytest\n",
    "from aiokafka import ConsumerRecord, TopicPartition\n",
    "from pydantic import BaseModel, Field, HttpUrl, NonNegativeInt\n",
    "from tqdm.notebook import tqdm\n",
    "from types import CoroutineType\n",
    "\n",
    "from fastkafka._components.logger import supress_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c31bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "supress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8da6a8",
   "metadata": {},
   "source": [
    "## anyio stream is not running tasks in parallel\n",
    "> Memory object stream is buffering the messages but the messages are consumed one by one and a new one is consumed only after the last one is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80816012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575adcdde80d4140a9bcc072b0423333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3badf71946549ec8a37a94f69584400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_msgs = 5\n",
    "latency = 0.2\n",
    "\n",
    "receive_pbar = tqdm(total=num_msgs*2)\n",
    "\n",
    "async def latency_task():\n",
    "    receive_pbar.update(1)\n",
    "    await asyncio.sleep(latency)\n",
    "    receive_pbar.update(1)\n",
    "\n",
    "async def process_message_callback(\n",
    "        receive_stream,\n",
    ") -> None:\n",
    "    async with receive_stream:\n",
    "        async for task in receive_stream:\n",
    "            await task\n",
    "\n",
    "send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "    max_buffer_size=num_msgs\n",
    ")\n",
    "\n",
    "t0 = datetime.now()\n",
    "async with anyio.create_task_group() as tg:\n",
    "    tg.start_soon(process_message_callback, receive_stream)\n",
    "    async with send_stream:\n",
    "        for i in tqdm(range(num_msgs)):\n",
    "            await send_stream.send(latency_task())\n",
    "            \n",
    "assert datetime.now() - t0 >= timedelta(seconds=latency*num_msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a41e0a",
   "metadata": {},
   "source": [
    "To solve this, we can create tasks from coroutines and let them run in background while the receive_stream is spawning new tasks whithout being blocked by previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842893fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57db15b0430473992f7fb9930709d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982731621e094b88b2833061aa9fb9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "num_msgs = 10_000\n",
    "latency = 4.0\n",
    "\n",
    "receive_pbar = tqdm(total=num_msgs*2)\n",
    "\n",
    "async def latency_task():\n",
    "    receive_pbar.update(1)\n",
    "    await asyncio.sleep(latency)\n",
    "    receive_pbar.update(1)\n",
    "\n",
    "tasks = set()\n",
    "\n",
    "async def process_message_callback(\n",
    "        receive_stream,\n",
    ") -> None:\n",
    "    async with receive_stream:\n",
    "        async for f in receive_stream:\n",
    "            task: asyncio.Task = asyncio.create_task(f())\n",
    "            tasks.add(task)\n",
    "            task.add_done_callback(lambda task=task, tasks=tasks: tasks.remove(task))\n",
    "\n",
    "send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "    max_buffer_size=num_msgs\n",
    ")\n",
    "\n",
    "t0 = datetime.now()\n",
    "async with anyio.create_task_group() as tg:\n",
    "    tg.start_soon(process_message_callback, receive_stream)\n",
    "    async with send_stream:\n",
    "        for i in tqdm(range(num_msgs)):\n",
    "            await send_stream.send(latency_task)\n",
    "\n",
    "await asyncio.sleep(latency/2)\n",
    "receive_pbar.refresh()\n",
    "assert receive_pbar.n == num_msgs, receive_pbar.n\n",
    "\n",
    "while len(tasks) > 0:\n",
    "    await asyncio.sleep(0)\n",
    "await send_stream.aclose()\n",
    "    \n",
    "receive_pbar.close()\n",
    "assert datetime.now() - t0 <= timedelta(seconds=latency+5.0)\n",
    "assert receive_pbar.n == num_msgs*2, receive_pbar.n\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839cceba",
   "metadata": {},
   "source": [
    "## Keeping track of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b255e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class TaskPool:\n",
    "     \n",
    "    def __init__(\n",
    "        self,\n",
    "        size: int = 100_000,\n",
    "        on_error: Optional[Callable[[BaseException], None]] = None,\n",
    "    ):\n",
    "        self.size = size\n",
    "        self.pool: Set[Task] = set()\n",
    "        self.on_error = on_error\n",
    "        self.finished = False\n",
    "\n",
    "    async def add(self, item: Task) -> None:\n",
    "        while len(self.pool) >= self.size:\n",
    "            await asyncio.sleep(0)\n",
    "        self.pool.add(item)\n",
    "        item.add_done_callback(self.discard)\n",
    "\n",
    "    def discard(self, task: Task) -> None:\n",
    "        e = task.exception()\n",
    "        if e is not None and self.on_error is not None:\n",
    "            try:\n",
    "                self.on_error(e)\n",
    "            except Exception as ee:\n",
    "                logger.warning(\n",
    "                    f\"Exception {ee} raised when calling on_error() callback: {e}\"\n",
    "                )\n",
    "\n",
    "        self.pool.discard(task)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.pool)\n",
    "\n",
    "    async def __aenter__(self) -> \"TaskPool\":\n",
    "        self.finished = False\n",
    "        return self\n",
    "\n",
    "    async def __aexit__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        while len(self) > 0:\n",
    "            await asyncio.sleep(0)\n",
    "        self.finished = True\n",
    "\n",
    "    @staticmethod\n",
    "    def log_error(logger: Logger) -> Callable[[Exception], None]:\n",
    "        def _log_error(e: Exception, logger: Logger = logger) -> None:\n",
    "            logger.warning(f\"{e=}\")\n",
    "        return _log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with TaskPool() as tp:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0625abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def f():\n",
    "    await asyncio.sleep(2)\n",
    "\n",
    "pool = TaskPool()\n",
    "assert len(pool) == 0\n",
    "\n",
    "async with pool:\n",
    "    task = asyncio.create_task(f())\n",
    "    await pool.add(task)\n",
    "    assert len(pool) == 1\n",
    "\n",
    "assert len(pool) == 0, len(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] __main__: e=RuntimeError('funny error')\n"
     ]
    }
   ],
   "source": [
    "async def f():\n",
    "    raise RuntimeError(\"funny error\")\n",
    "\n",
    "        \n",
    "    return _log_error\n",
    "    \n",
    "pool = TaskPool(on_error=TaskPool.log_error(logger))\n",
    "\n",
    "async with pool:\n",
    "    task = asyncio.create_task(f())\n",
    "    await pool.add(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd66e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class ExceptionMonitor():\n",
    "    def __init__(self) -> None:\n",
    "        self.exceptions: List[Exception]= []\n",
    "        self.exception_found = False\n",
    "        \n",
    "    def on_error(self, e: Exception) -> None:\n",
    "        self.exceptions.append(e)\n",
    "        self.exception_found = True\n",
    "        \n",
    "    def _monitor_step(self) -> None:\n",
    "        if len(self.exceptions) > 0:\n",
    "            e = self.exceptions.pop(0)\n",
    "            raise e\n",
    "        \n",
    "    async def __aenter__(self) -> \"ExceptionMonitor\":\n",
    "        return self\n",
    "    \n",
    "    async def __aexit__(self, *args: Any, **kwargs: Any) -> None:\n",
    "        while len(self.exceptions) > 0:\n",
    "            self._monitor_step()\n",
    "            await asyncio.sleep(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16135fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e=<ExceptionInfo RuntimeError('very funny error.') tblen=4>\n"
     ]
    }
   ],
   "source": [
    "no_tasks = 1\n",
    "\n",
    "async def f():\n",
    "    raise RuntimeError(f\"very funny error.\")\n",
    "\n",
    "\n",
    "exception_monitor = ExceptionMonitor()\n",
    "pool = TaskPool(on_error=exception_monitor.on_error)\n",
    "\n",
    "async def create_tasks():\n",
    "    for _ in range(no_tasks):\n",
    "        task = asyncio.create_task(f())\n",
    "        await pool.add(task)\n",
    "        await asyncio.sleep(0.1) # otherwise the tasks get created before any of them throws an exception\n",
    "        if exception_monitor.exception_found:\n",
    "            break\n",
    "        \n",
    "with pytest.raises(RuntimeError) as e:\n",
    "    async with exception_monitor, pool:\n",
    "        async with asyncer.create_task_group() as tg:\n",
    "            tg.soonify(create_tasks)()\n",
    "            \n",
    "print(f\"{e=}\")\n",
    "assert exception_monitor.exceptions == [], len(exception_monitor.exceptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e1354",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class StreamExecutor(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    async def run( # type: ignore\n",
    "        self,\n",
    "        is_shutting_down_f: Callable[[], bool],\n",
    "        produce_func: Callable[[], Awaitable[ConsumerRecord]],\n",
    "        consume_func: Callable[[ConsumerRecord], Awaitable[None]],\n",
    "    ) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61503ef7",
   "metadata": {},
   "source": [
    "## Streaming tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock = Mock()\n",
    "async_mock = asyncer.asyncify(mock)\n",
    "\n",
    "async def process_items(receive_stream):\n",
    "    async with receive_stream:\n",
    "        async for item in receive_stream:\n",
    "            task = asyncio.create_task(async_mock(item))\n",
    "            await pool.add(task)\n",
    "\n",
    "send_stream, receive_stream = create_memory_object_stream()\n",
    "pool = TaskPool()\n",
    "\n",
    "async with pool:\n",
    "    async with create_task_group() as tg:\n",
    "        tg.start_soon(process_items, receive_stream)\n",
    "        async with send_stream:\n",
    "            await send_stream.send(f\"hi\")\n",
    "\n",
    "mock.assert_called()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _process_items_task( # type: ignore\n",
    "    consume_func: Callable[[ConsumerRecord], Awaitable[None]],\n",
    "    task_pool: TaskPool\n",
    ") -> Callable[\n",
    "    [\n",
    "        anyio.streams.memory.MemoryObjectReceiveStream,\n",
    "        Callable[[ConsumerRecord], Awaitable[None]],\n",
    "        bool,\n",
    "    ],\n",
    "    Coroutine[Any, Any, Awaitable[None]],\n",
    "]:\n",
    "    async def _process_items_wrapper(  # type: ignore\n",
    "        receive_stream: anyio.streams.memory.MemoryObjectReceiveStream,\n",
    "        consume_func: Callable[[ConsumerRecord], Awaitable[None]] = consume_func,\n",
    "        task_pool= task_pool,\n",
    "    ):\n",
    "        async with receive_stream:\n",
    "            async for msg in receive_stream:\n",
    "                task: asyncio.Task = asyncio.create_task(consume_func(msg))  # type: ignore\n",
    "                await task_pool.add(task)\n",
    "\n",
    "    return _process_items_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class DynamicTaskExecutor(StreamExecutor):\n",
    "    def __init__(  # type: ignore\n",
    "        self,\n",
    "        throw_exceptions: bool = False,\n",
    "        max_buffer_size=100_000,\n",
    "        size=100_000,\n",
    "    ):\n",
    "        self.throw_exceptions = throw_exceptions\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "        self.exception_monitor = ExceptionMonitor()\n",
    "        self.task_pool = TaskPool(\n",
    "            on_error=self.exception_monitor.on_error  # type: ignore\n",
    "            if throw_exceptions\n",
    "            else TaskPool.log_error(logger),\n",
    "            size=size,\n",
    "        )\n",
    "\n",
    "    async def run( # type: ignore\n",
    "        self,\n",
    "        is_shutting_down_f: Callable[[], bool],\n",
    "        produce_func: Callable[[], Awaitable[ConsumerRecord]],\n",
    "        consume_func: Callable[[ConsumerRecord], Awaitable[None]],\n",
    "    ) -> None:\n",
    "        send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "            max_buffer_size=self.max_buffer_size\n",
    "        )\n",
    "\n",
    "        async with self.exception_monitor, self.task_pool:\n",
    "            async with anyio.create_task_group() as tg:\n",
    "                tg.start_soon(_process_items_task(consume_func, self.task_pool), receive_stream)\n",
    "                async with send_stream:\n",
    "                    while not is_shutting_down_f():\n",
    "                        if (\n",
    "                            self.exception_monitor.exception_found\n",
    "                            and self.throw_exceptions\n",
    "                        ):\n",
    "                            break\n",
    "                        msgs = await produce_func()\n",
    "                        for msg in msgs:\n",
    "                            await send_stream.send(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc13156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_shutting_down_f(call_count:int = 1) -> Callable[[], bool]:\n",
    "    count = {\"count\": 0}\n",
    "    \n",
    "    def _is_shutting_down_f(count=count, call_count:int = call_count):\n",
    "        if count[\"count\"]>=call_count:\n",
    "            return True\n",
    "        else:\n",
    "            count[\"count\"] = count[\"count\"] + 1\n",
    "            return False\n",
    "        \n",
    "    return _is_shutting_down_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = is_shutting_down_f()\n",
    "assert f() == False\n",
    "assert f() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ce4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg\n"
     ]
    }
   ],
   "source": [
    "async def produce():\n",
    "    return [\"msg\"]\n",
    "\n",
    "\n",
    "async def consume(msg):\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "stream = DynamicTaskExecutor()\n",
    "\n",
    "await stream.run(\n",
    "    is_shutting_down_f(),\n",
    "    produce_func=produce,\n",
    "    consume_func=consume,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d82173",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "\n",
    "stream = DynamicTaskExecutor()\n",
    "\n",
    "await stream.run(\n",
    "    is_shutting_down_f(),\n",
    "    produce_func=mock_produce,\n",
    "    consume_func=mock_consume,\n",
    ")\n",
    "\n",
    "mock_produce.assert_awaited()\n",
    "mock_consume.assert_awaited_with(\"msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "\n",
    "stream = DynamicTaskExecutor()\n",
    "\n",
    "await stream.run(\n",
    "    is_shutting_down_f(),\n",
    "    produce_func=mock_produce,\n",
    "    consume_func=mock_consume,\n",
    ")\n",
    "\n",
    "mock_produce.assert_called()\n",
    "mock_consume.assert_called_with(\"msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ac8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_msgs = 13\n",
    "\n",
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "mock_consume.side_effect = RuntimeError()\n",
    "\n",
    "stream = DynamicTaskExecutor(throw_exceptions=True)\n",
    "\n",
    "with pytest.raises(RuntimeError) as e:\n",
    "    await stream.run(\n",
    "        is_shutting_down_f(num_msgs),\n",
    "        produce_func=mock_produce,\n",
    "        consume_func=mock_consume,\n",
    "    )\n",
    "\n",
    "mock_produce.assert_called()\n",
    "mock_consume.assert_awaited_with(\"msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd855e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n",
      "[WARNING] __main__: e=RuntimeError()\n"
     ]
    }
   ],
   "source": [
    "num_msgs = 13\n",
    "\n",
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "mock_consume.side_effect = RuntimeError()\n",
    "\n",
    "stream = DynamicTaskExecutor()\n",
    "\n",
    "await stream.run(\n",
    "    is_shutting_down_f(num_msgs),\n",
    "    produce_func=mock_produce,\n",
    "    consume_func=mock_consume,\n",
    ")\n",
    "\n",
    "mock_produce.assert_called()\n",
    "mock_consume.assert_awaited_with(\"msg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276db314",
   "metadata": {},
   "source": [
    "## Awaiting coroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _process_items_coro(  # type: ignore\n",
    "    consume_func: Callable[[ConsumerRecord], Awaitable[None]],\n",
    "    throw_exceptions: bool,\n",
    ") -> Callable[\n",
    "    [\n",
    "        anyio.streams.memory.MemoryObjectReceiveStream,\n",
    "        Callable[[ConsumerRecord], Awaitable[None]],\n",
    "        bool,\n",
    "    ],\n",
    "    Coroutine[Any, Any, Awaitable[None]],\n",
    "]:\n",
    "    async def _process_items_wrapper(  # type: ignore\n",
    "        receive_stream: anyio.streams.memory.MemoryObjectReceiveStream,\n",
    "        consume_func: Callable[[ConsumerRecord], Awaitable[None]] = consume_func,\n",
    "        throw_exceptions: bool = throw_exceptions,\n",
    "    ) -> Awaitable[None]:\n",
    "        async with receive_stream:\n",
    "            async for msg in receive_stream:\n",
    "                try:\n",
    "                    await consume_func(msg)\n",
    "                except Exception as e:\n",
    "                    if throw_exceptions:\n",
    "                        raise e\n",
    "                    else:\n",
    "                        logger.warning(f\"{e=}\")\n",
    "\n",
    "    return _process_items_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SequentialExecutor(StreamExecutor):\n",
    "    def __init__(  # type: ignore\n",
    "        self,\n",
    "        throw_exceptions: bool = False,\n",
    "        max_buffer_size=100_000,\n",
    "    ):\n",
    "        self.throw_exceptions = throw_exceptions\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "\n",
    "    async def run( # type: ignore\n",
    "        self,\n",
    "        is_shutting_down_f: Callable[[], bool],\n",
    "        produce_func: Callable[[], Awaitable[ConsumerRecord]],\n",
    "        consume_func: Callable[[ConsumerRecord], Awaitable[None]],\n",
    "    ) -> None:\n",
    "\n",
    "        send_stream, receive_stream = anyio.create_memory_object_stream(\n",
    "            max_buffer_size=self.max_buffer_size\n",
    "        )\n",
    "        \n",
    "        async with anyio.create_task_group() as tg:\n",
    "            tg.start_soon(_process_items_coro(consume_func, self.throw_exceptions), receive_stream)\n",
    "            async with send_stream:\n",
    "                while not is_shutting_down_f():\n",
    "                    msgs = await produce_func()\n",
    "                    for msg in msgs:\n",
    "                        await send_stream.send(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa058a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_msgs = 13\n",
    "\n",
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "mock_consume.side_effect = RuntimeError(\"Funny error\")\n",
    "\n",
    "stream = SequentialExecutor(throw_exceptions=True)\n",
    "\n",
    "with pytest.raises(ExceptionGroup) as e:\n",
    "    await stream.run(is_shutting_down_f(num_msgs), produce_func=mock_produce, consume_func=mock_consume)\n",
    "\n",
    "mock_produce.assert_called()\n",
    "mock_consume.assert_awaited_with(\"msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa60fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n",
      "[WARNING] __main__: e=RuntimeError('Funny error')\n"
     ]
    }
   ],
   "source": [
    "num_msgs = 13\n",
    "\n",
    "mock_produce = AsyncMock(spec=CoroutineType, return_value=[\"msg\"])\n",
    "mock_consume = AsyncMock(spec=CoroutineType)\n",
    "mock_consume.side_effect = RuntimeError(\"Funny error\")\n",
    "\n",
    "stream = SequentialExecutor()\n",
    "\n",
    "await stream.run(\n",
    "    is_shutting_down_f(num_msgs),\n",
    "    mock_produce,\n",
    "    mock_consume,\n",
    ")\n",
    "\n",
    "mock_produce.assert_called()\n",
    "mock_consume.assert_awaited_with(\"msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc03222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_executor(executor: Union[str, StreamExecutor, None] = None) -> StreamExecutor:\n",
    "    if isinstance(executor, StreamExecutor):\n",
    "        return executor\n",
    "    elif executor is None:\n",
    "        executor = \"SequentialExecutor\"\n",
    "    return getattr(sys.modules[\"fastkafka._components.task_streaming\"], executor)() # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab892f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for executor in [None, \"SequentialExecutor\", SequentialExecutor()]:\n",
    "    actual = get_executor(executor)\n",
    "    assert actual.__class__.__qualname__ == \"SequentialExecutor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba3526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for executor in [\"DynamicTaskExecutor\", DynamicTaskExecutor()]:\n",
    "    actual = get_executor(executor)\n",
    "    assert actual.__class__.__qualname__ == \"DynamicTaskExecutor\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
