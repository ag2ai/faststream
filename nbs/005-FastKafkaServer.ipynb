{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcc07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "import asyncio\n",
    "from typing import *\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import signal\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from fastkafka.application import FastKafka\n",
    "from fastkafka.testing import change_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ddd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager\n",
    "from tempfile import TemporaryDirectory\n",
    "from time import sleep\n",
    "\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eada96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_app_src(out_path: Union[Path, str]) -> None:\n",
    "    path = Path(\"099_Test_Service.ipynb\")\n",
    "    if not path.exists():\n",
    "        path = Path(\"..\") / \"099_Test_Service.ipynb\"\n",
    "    if not path.exists():\n",
    "        raise ValueError(f\"Path '{path.resolve()}' does not exists.\")\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        notebook = nbformat.reads(f.read(), nbformat.NO_CONVERT)\n",
    "        exporter = PythonExporter()\n",
    "        source, _ = exporter.from_notebook_node(notebook)\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91137f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\n",
      "drwx------ 2 tvrtko tvrtko  4096 Jan 30 16:47 .\n",
      "drwxrwxrwt 1 root   root    4096 Jan 30 16:47 ..\n",
      "-rw-rw-r-- 1 tvrtko tvrtko 10829 Jan 30 16:47 main.py\n",
      "    @kafka_app.consumes()  # type: ignore\n",
      "    @kafka_app.consumes()  # type: ignore\n",
      "    @kafka_app.produces()  # type: ignore\n",
      "    @kafka_app.produces()  # type: ignore\n",
      "    @kafka_app.produces()  # type: ignore\n",
      "    @kafka_app.produces()  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    generate_app_src((Path(d) / \"main.py\"))\n",
    "    !ls -al {d}\n",
    "    !cat {d}/main.py | grep @kafka_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ImportFromStringError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _import_from_string(import_str: str) -> Any:\n",
    "    \"\"\"Imports library from string\n",
    "\n",
    "    Note:\n",
    "        copied from https://github.com/encode/uvicorn/blob/master/uvicorn/importer.py\n",
    "\n",
    "    Args:\n",
    "        import_str: input string in form 'main:app'\n",
    "\n",
    "    \"\"\"\n",
    "    sys.path.append(\".\")\n",
    "\n",
    "    if not isinstance(import_str, str):\n",
    "        return import_str\n",
    "\n",
    "    module_str, _, attrs_str = import_str.partition(\":\")\n",
    "    if not module_str or not attrs_str:\n",
    "        message = (\n",
    "            'Import string \"{import_str}\" must be in format \"<module>:<attribute>\".'\n",
    "        )\n",
    "        typer.secho(f\"{message}\", err=True, fg=typer.colors.RED)\n",
    "        raise ImportFromStringError(message.format(import_str=import_str))\n",
    "\n",
    "    try:\n",
    "        # nosemgrep: python.lang.security.audit.non-literal-import.non-literal-import\n",
    "        module = importlib.import_module(module_str)\n",
    "    except ImportError as exc:\n",
    "        if exc.name != module_str:\n",
    "            raise exc from None\n",
    "        message = 'Could not import module \"{module_str}\".'\n",
    "        raise ImportFromStringError(message.format(module_str=module_str))\n",
    "\n",
    "    instance = module\n",
    "    try:\n",
    "        for attr_str in attrs_str.split(\".\"):\n",
    "            instance = getattr(instance, attr_str)\n",
    "    except AttributeError:\n",
    "        message = 'Attribute \"{attrs_str}\" not found in module \"{module_str}\".'\n",
    "        raise ImportFromStringError(\n",
    "            message.format(attrs_str=attrs_str, module_str=module_str)\n",
    "        )\n",
    "\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becabc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] main: check\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    src_path = Path(d) / \"main.py\"\n",
    "    generate_app_src(src_path)\n",
    "    with change_dir(d):\n",
    "        kafka_app = _import_from_string(f\"{src_path.stem}:kafka_app\")\n",
    "        assert isinstance(kafka_app, FastKafka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced70e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "class FastKafkaServer():\n",
    "    \n",
    "    def __init__(self, app: FastKafka):\n",
    "        self.app = app\n",
    "        self.should_exit = False\n",
    "    \n",
    "    \n",
    "    def run(self) -> None:\n",
    "        return asyncio.run(self._serve())\n",
    "\n",
    "    async def _serve(self) -> None:\n",
    "        self._install_signal_handlers()\n",
    "\n",
    "        await self.app.startup()\n",
    "        await self._main_loop()\n",
    "        await self.app.shutdown()\n",
    "\n",
    "    def _install_signal_handlers(self) -> None:\n",
    "        if threading.current_thread() is not threading.main_thread():\n",
    "            # Signals can only be listened to from the main thread.\n",
    "            return\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "\n",
    "        HANDLED_SIGNALS = (\n",
    "            signal.SIGINT,  # Unix signal 2. Sent by Ctrl+C.\n",
    "            signal.SIGTERM,  # Unix signal 15. Sent by `kill <pid>`.\n",
    "        )\n",
    "        \n",
    "        def handle_exit(sig: int) -> None:\n",
    "            self.should_exit = True\n",
    "        \n",
    "        for sig in HANDLED_SIGNALS:\n",
    "            loop.add_signal_handler(sig, handle_exit, sig)\n",
    "            \n",
    "            \n",
    "    async def _main_loop(self) -> None:\n",
    "        while not self.should_exit:\n",
    "            await asyncio.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8809f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    src_path = Path(d) / \"main.py\"\n",
    "    generate_app_src(src_path)\n",
    "    with change_dir(d):\n",
    "        import_str = f\"{src_path.stem}:kafka_app\"\n",
    "        app = _import_from_string(import_str)\n",
    "        # Patch _main_loop to last x seconds, patch fastkafka \n",
    "        # startup and shutdown and assert startup and shutdown called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f985e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@contextmanager\n",
    "def run_fastkafka_server(app: FastKafka) -> Generator[None, None, None]:\n",
    "    app = app\n",
    "    \n",
    "    def run(app=app):\n",
    "        server = FastKafkaServer(app=app)\n",
    "        server.run()\n",
    "        \n",
    "    p = multiprocessing.Process(target=run)\n",
    "    try:\n",
    "        p.start()\n",
    "        yield\n",
    "    except Exception as e:\n",
    "        print(f\"Exception raised {e=}\")\n",
    "    finally:\n",
    "        p.terminate()\n",
    "        p.join()\n",
    "        p.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e90f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] fastkafka._components.asyncapi: Old async specifications at '/tmp/tmplubdffvk/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fastkafka._components.asyncapi: Old async specifications at '/tmp/tmplubdffvk/asyncapi/spec/asyncapi.yml' does not exist.\n",
      "[INFO] fastkafka._components.asyncapi: New async specifications generated at: '/tmp/tmplubdffvk/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092', 'group_id': 'tvrtko-fastkafka-kafka-1:9092_group', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092', 'group_id': 'tvrtko-fastkafka-kafka-1:9092_group', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'realitime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'realitime_data'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'training_data'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.asyncapi: Keeping the old async specifications at: '/tmp/tmplubdffvk/asyncapi/spec/asyncapi.yml'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka.application: _create_producer() : created producer using the config: '{'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092'}'\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092', 'group_id': 'tvrtko-fastkafka-kafka-1:9092_group', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() starting...\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer created using the following parameters: {'bootstrap_servers': 'tvrtko-fastkafka-kafka-1:9092', 'group_id': 'tvrtko-fastkafka-kafka-1:9092_group', 'auto_offset_reset': 'earliest', 'max_poll_records': 100}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'realitime_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'realitime_data'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer started.\n",
      "[INFO] aiokafka.consumer.subscription_state: Updating subscribed topics to: frozenset({'training_data'})\n",
      "[INFO] aiokafka.consumer.consumer: Subscribed to topic(s): {'training_data'}\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer subscribed.\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Discovered coordinator 1001 for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Revoking previously assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: (Re-)joining group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fastkafka-kafka-1:9092_group' (generation 14) with member_id aiokafka-0.8.0-4ac26a21-de0b-4e17-8e81-3123bf1d6389\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fastkafka-kafka-1:9092_group' (generation 14) with member_id aiokafka-0.8.0-c1eaae08-bd0a-4f61-8d81-0e93394aac2a\n",
      "[INFO] aiokafka.consumer.group_coordinator: Elected group leader -- performing partition assignments using roundrobin\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fastkafka-kafka-1:9092_group' (generation 14) with member_id aiokafka-0.8.0-08ab7b95-0673-47fe-ae44-a446d0a111a8\n",
      "[INFO] aiokafka.consumer.group_coordinator: Joined group 'tvrtko-fastkafka-kafka-1:9092_group' (generation 14) with member_id aiokafka-0.8.0-b93e135d-691f-4548-8057-24bff5ed0510\n",
      "[INFO] aiokafka.consumer.group_coordinator: Metadata for topic has changed from {} to {'training_data': 1, 'realitime_data': 1}. \n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fastkafka-kafka-1:9092_group with generation 14\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fastkafka-kafka-1:9092_group with generation 14\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='realitime_data', partition=0)} for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fastkafka-kafka-1:9092_group with generation 14\n",
      "[INFO] aiokafka.consumer.group_coordinator: Successfully synced group tvrtko-fastkafka-kafka-1:9092_group with generation 14\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions {TopicPartition(topic='training_data', partition=0)} for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: Setting newly assigned partitions set() for group tvrtko-fastkafka-kafka-1:9092_group\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n",
      "[INFO] aiokafka.consumer.group_coordinator: LeaveGroup request succeeded\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop(): Consumer stopped.\n",
      "[INFO] fastkafka._components.aiokafka_consumer_loop: aiokafka_consumer_loop() finished.\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    src_path = Path(d) / \"main.py\"\n",
    "    generate_app_src(src_path)\n",
    "    with change_dir(d):\n",
    "        import_str = f\"{src_path.stem}:kafka_app\"\n",
    "        app = _import_from_string(import_str)\n",
    "        with run_fastkafka_server(app), run_fastkafka_server(app):\n",
    "            sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b4979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
